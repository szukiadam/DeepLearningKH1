{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hyperparam_opt_true.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInwElEVRxNS"
      },
      "source": [
        "This notebook is really similar to the one we saw in class.\n",
        "The github link for that notebook is the following: https://github.com/BME-SmartLab-Education/vitmav45/blob/master/12/hyperas_fashionmnist_pub.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLLtjd1UqAGS",
        "outputId": "4c367acf-5666-45ea-fd3d-fd8a1f584821"
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade tensorflow-gpu\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "!pip install keras-tuner\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4p3HwoGqJPD",
        "outputId": "f3c04e67-5fb8-4891-b07b-1b041d3d5670"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
            "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB9WEIrsq18b",
        "outputId": "3c939033-fa3d-412a-fce9-f6cb571cc500"
      },
      "source": [
        "!pip3 install hyperas\n",
        "!pip3 install hyperopt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.8)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (20.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O7lPP9FrEUn"
      },
      "source": [
        "# we know from the cifar10 documentation that it has 10 classes \n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk5wluLVrG21"
      },
      "source": [
        "# make the labels one-hot encoded\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMSMijgjrVGP"
      },
      "source": [
        "# reshape for FC-DNN\n",
        "#cifar10 pictures are in 32x32x3\n",
        "\n",
        "x_train = np.reshape(x_train,(-1,32*32*3)) # 28x28\n",
        "x_test = np.reshape(x_test,(-1,32*32*3))\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize, [0-1]\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwOxOy4nrz9L"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=1024*3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUqwZP72r5dt"
      },
      "source": [
        "\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRS033Ejr7Zd",
        "outputId": "811c112d-6423-4b8d-ac57-8ebc1dbe5b9b"
      },
      "source": [
        "result = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8799 - accuracy: 0.3247 - val_loss: 1.7211 - val_accuracy: 0.3904\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6872 - accuracy: 0.4007 - val_loss: 1.6207 - val_accuracy: 0.4256\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6059 - accuracy: 0.4309 - val_loss: 1.6311 - val_accuracy: 0.4215\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5468 - accuracy: 0.4536 - val_loss: 1.5613 - val_accuracy: 0.4429\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5007 - accuracy: 0.4710 - val_loss: 1.5016 - val_accuracy: 0.4630\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4655 - accuracy: 0.4820 - val_loss: 1.5150 - val_accuracy: 0.4586\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4306 - accuracy: 0.4948 - val_loss: 1.4883 - val_accuracy: 0.4685\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4027 - accuracy: 0.5028 - val_loss: 1.5856 - val_accuracy: 0.4505\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3780 - accuracy: 0.5132 - val_loss: 1.4224 - val_accuracy: 0.4989\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3554 - accuracy: 0.5194 - val_loss: 1.4143 - val_accuracy: 0.4897\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3321 - accuracy: 0.5311 - val_loss: 1.4160 - val_accuracy: 0.4921\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3093 - accuracy: 0.5372 - val_loss: 1.5094 - val_accuracy: 0.4668\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2918 - accuracy: 0.5412 - val_loss: 1.4900 - val_accuracy: 0.4774\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2713 - accuracy: 0.5494 - val_loss: 1.4421 - val_accuracy: 0.4965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YROOWDgrr8vZ",
        "outputId": "f7a0ee7a-d630-46ea-d6d6-21a64201a925"
      },
      "source": [
        "# choose the best one \n",
        "best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "print('legjobb val_acc:', best_val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "legjobb val_acc: 0.49889999628067017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J1jZ8Q-wyaZ"
      },
      "source": [
        "def data():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  \n",
        "  num_classes = 10 #in cifar10 we have 10 classes\n",
        "  \n",
        "  # make the y-labels one-hot encoded\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "  \n",
        "  # reshape the training data -> pictures in cifar10 are 32x32x3 \n",
        "  x_train = np.reshape(x_train,(-1,32*32*3)) \n",
        "  x_test = np.reshape(x_test,(-1,32*32*3))\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  # normalize, [0-1]\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgnvCynzw_xI"
      },
      "source": [
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "   \n",
        "    # define hyperparams\n",
        "\n",
        "    n_layer1 = {{choice([32,64,128, 256, 512])}}\n",
        "    n_layer2 = {{choice([32,64,128, 256, 512])}}\n",
        "    dropout_1 = {{uniform(0, 0.5)}}\n",
        "    dropout_2 = {{uniform(0, 0.5)}}\n",
        "    act = {{choice(['relu', 'leakyrelu'])}}\n",
        "    optim = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
        "    n_batch = {{choice([64, 128, 256])}}\n",
        "    print('hyperparams of model: ', n_layer1, n_layer2, dropout_1, dropout_2, act, optim, n_batch)\n",
        "    \n",
        "    \n",
        "    # string to activation \n",
        "    if act == 'relu':\n",
        "        activation = keras.layers.ReLU()\n",
        "    elif act == 'leakyrelu':\n",
        "        activation = keras.layers.LeakyReLU()\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(n_layer1, input_dim=32*32*3))\n",
        "    model.add(activation)\n",
        "    model.add(Dropout(dropout_1))\n",
        "    model.add(Dense(n_layer2))\n",
        "    model.add(activation)\n",
        "    model.add(Dropout(dropout_2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer=optim,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)]\n",
        "    \n",
        "    result = model.fit(x_train, y_train,\n",
        "              batch_size=n_batch,\n",
        "              epochs=100,\n",
        "              verbose=2,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)\n",
        "\n",
        "    \n",
        "    # save tghe highest validation accuracy\n",
        "    best_val_acc = np.amax(result.history['val_accuracy']) \n",
        "    print('best validation accuracy:', best_val_acc)\n",
        "    \n",
        "    # logging\n",
        "    with open('cifar10.csv', 'a') as csv_file:\n",
        "      csv_file.write(str(n_layer1) + ';')\n",
        "      csv_file.write(str(n_layer2) + ';')\n",
        "      csv_file.write(str(dropout_1) + ';')\n",
        "      csv_file.write(str(dropout_2) + ';')\n",
        "      csv_file.write(str(act) + ';')\n",
        "      csv_file.write(str(optim) + ';')\n",
        "      csv_file.write(str(n_batch) + ';')\n",
        "      csv_file.write(str(best_val_acc) + '\\n')\n",
        "\n",
        "\n",
        "    \n",
        "    return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZnjNDobxsit"
      },
      "source": [
        "# init of log file and header (columns)\n",
        "with open('cifar10.csv', 'w') as csv_file:\n",
        "  csv_file.write('n_layer1' + ';')\n",
        "  csv_file.write('n_layer2' + ';')\n",
        "  csv_file.write('dropout_1' + ';')\n",
        "  csv_file.write('dropout_2' + ';')\n",
        "  csv_file.write('act' + ';')\n",
        "  csv_file.write('optim' + ';')\n",
        "  csv_file.write('n_batch' + ';')\n",
        "  csv_file.write('best_val_acc' + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgQfBbpRxxC2"
      },
      "source": [
        "# after this i've downloaded the previous content as a .ipynb notebook\n",
        "# then uploaded it to this directory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggaC84wX4x07"
      },
      "source": [
        "import hyperas\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq8K2EXb4zr8",
        "outputId": "39c3a59c-5a29-46e8-e492-5a85ccc321df"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=130,\n",
        "                                          notebook_name='hyperparam_opt',\n",
        "                                          trials=Trials())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.3875 - accuracy: 0.5066 - val_loss: 1.3801 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.3807 - accuracy: 0.5070 - val_loss: 1.4005 - val_accuracy: 0.4976\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.3741 - accuracy: 0.5101 - val_loss: 1.3624 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.3639 - accuracy: 0.5139 - val_loss: 1.3756 - val_accuracy: 0.5117\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.3631 - accuracy: 0.5152 - val_loss: 1.4191 - val_accuracy: 0.4983\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.3489 - accuracy: 0.5238 - val_loss: 1.4018 - val_accuracy: 0.5006\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.3455 - accuracy: 0.5192 - val_loss: 1.3376 - val_accuracy: 0.5176\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.3404 - accuracy: 0.5243 - val_loss: 1.3808 - val_accuracy: 0.5095\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.3386 - accuracy: 0.5229 - val_loss: 1.3594 - val_accuracy: 0.5150\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.3351 - accuracy: 0.5256 - val_loss: 1.3518 - val_accuracy: 0.5157\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.3203 - accuracy: 0.5305 - val_loss: 1.3780 - val_accuracy: 0.5091\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.3208 - accuracy: 0.5299 - val_loss: 1.3409 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.3150 - accuracy: 0.5332 - val_loss: 1.3890 - val_accuracy: 0.5018\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.3100 - accuracy: 0.5345 - val_loss: 1.3452 - val_accuracy: 0.5245\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.3009 - accuracy: 0.5358 - val_loss: 1.3727 - val_accuracy: 0.5164\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.2967 - accuracy: 0.5395 - val_loss: 1.3573 - val_accuracy: 0.5169\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.2919 - accuracy: 0.5399 - val_loss: 1.3705 - val_accuracy: 0.5163\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.2922 - accuracy: 0.5406 - val_loss: 1.3503 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 1s - loss: 1.2920 - accuracy: 0.5395 - val_loss: 1.3441 - val_accuracy: 0.5225\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5245000123977661\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.23980147439371519\n",
            "0.27325459764534255\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9810 - accuracy: 0.2875 - val_loss: 1.8077 - val_accuracy: 0.3487\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8111 - accuracy: 0.3484 - val_loss: 1.6847 - val_accuracy: 0.4085\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7464 - accuracy: 0.3773 - val_loss: 1.6590 - val_accuracy: 0.4112\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6978 - accuracy: 0.3922 - val_loss: 1.6162 - val_accuracy: 0.4326\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6564 - accuracy: 0.4103 - val_loss: 1.5760 - val_accuracy: 0.4370\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6377 - accuracy: 0.4183 - val_loss: 1.5372 - val_accuracy: 0.4532\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6011 - accuracy: 0.4329 - val_loss: 1.5141 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5832 - accuracy: 0.4374 - val_loss: 1.5232 - val_accuracy: 0.4701\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5696 - accuracy: 0.4400 - val_loss: 1.5209 - val_accuracy: 0.4523\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5531 - accuracy: 0.4488 - val_loss: 1.4661 - val_accuracy: 0.4897\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5356 - accuracy: 0.4527 - val_loss: 1.4643 - val_accuracy: 0.4849\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5161 - accuracy: 0.4619 - val_loss: 1.4659 - val_accuracy: 0.4805\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5067 - accuracy: 0.4646 - val_loss: 1.4497 - val_accuracy: 0.4837\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5001 - accuracy: 0.4637 - val_loss: 1.4560 - val_accuracy: 0.4825\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4904 - accuracy: 0.4725 - val_loss: 1.4403 - val_accuracy: 0.4844\n",
            "\n",
            "legjobb val_acc:\n",
            "0.48969998955726624\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "512\n",
            "0.15629905847757408\n",
            "0.25214108918216865\n",
            "relu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1100 - accuracy: 0.2047 - val_loss: 2.0450 - val_accuracy: 0.2231\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9905 - accuracy: 0.2620 - val_loss: 1.9151 - val_accuracy: 0.3023\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9486 - accuracy: 0.2810 - val_loss: 1.8633 - val_accuracy: 0.3217\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9182 - accuracy: 0.2928 - val_loss: 1.9333 - val_accuracy: 0.2819\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8942 - accuracy: 0.3051 - val_loss: 1.8670 - val_accuracy: 0.3056\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8798 - accuracy: 0.3126 - val_loss: 1.8149 - val_accuracy: 0.3520\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8634 - accuracy: 0.3213 - val_loss: 1.8104 - val_accuracy: 0.3350\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.8527 - accuracy: 0.3247 - val_loss: 1.8192 - val_accuracy: 0.3379\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.8424 - accuracy: 0.3277 - val_loss: 1.8109 - val_accuracy: 0.3412\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.8354 - accuracy: 0.3332 - val_loss: 1.8062 - val_accuracy: 0.3514\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.8270 - accuracy: 0.3342 - val_loss: 1.7844 - val_accuracy: 0.3562\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.8192 - accuracy: 0.3373 - val_loss: 1.8026 - val_accuracy: 0.3517\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.8159 - accuracy: 0.3394 - val_loss: 1.7405 - val_accuracy: 0.3801\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.8069 - accuracy: 0.3429 - val_loss: 1.7985 - val_accuracy: 0.3414\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.8061 - accuracy: 0.3425 - val_loss: 1.7893 - val_accuracy: 0.3580\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.7965 - accuracy: 0.3457 - val_loss: 1.7221 - val_accuracy: 0.3864\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.7938 - accuracy: 0.3469 - val_loss: 1.7157 - val_accuracy: 0.3824\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.7937 - accuracy: 0.3472 - val_loss: 1.7393 - val_accuracy: 0.3654\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.7859 - accuracy: 0.3507 - val_loss: 1.7237 - val_accuracy: 0.3740\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.7828 - accuracy: 0.3517 - val_loss: 1.7547 - val_accuracy: 0.3677\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.7789 - accuracy: 0.3532 - val_loss: 1.7582 - val_accuracy: 0.3527\n",
            "\n",
            "legjobb val_acc:\n",
            "0.3864000141620636\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.11265340838832857\n",
            "0.02035598667812466\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 1.9044 - accuracy: 0.3161 - val_loss: 1.7575 - val_accuracy: 0.3671\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.7376 - accuracy: 0.3816 - val_loss: 1.6995 - val_accuracy: 0.3973\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.6621 - accuracy: 0.4075 - val_loss: 1.5711 - val_accuracy: 0.4502\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.6139 - accuracy: 0.4264 - val_loss: 1.6164 - val_accuracy: 0.4137\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.5693 - accuracy: 0.4426 - val_loss: 1.5655 - val_accuracy: 0.4452\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.5416 - accuracy: 0.4507 - val_loss: 1.4951 - val_accuracy: 0.4691\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.5148 - accuracy: 0.4602 - val_loss: 1.5307 - val_accuracy: 0.4582\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.4912 - accuracy: 0.4676 - val_loss: 1.4828 - val_accuracy: 0.4696\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.4702 - accuracy: 0.4778 - val_loss: 1.4842 - val_accuracy: 0.4670\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.4481 - accuracy: 0.4831 - val_loss: 1.5943 - val_accuracy: 0.4477\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.4322 - accuracy: 0.4911 - val_loss: 1.4862 - val_accuracy: 0.4620\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.4164 - accuracy: 0.4979 - val_loss: 1.4748 - val_accuracy: 0.4825\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 3s - loss: 1.3995 - accuracy: 0.5031 - val_loss: 1.4564 - val_accuracy: 0.4825\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 3s - loss: 1.3825 - accuracy: 0.5106 - val_loss: 1.5274 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 3s - loss: 1.3696 - accuracy: 0.5134 - val_loss: 1.4334 - val_accuracy: 0.4966\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 3s - loss: 1.3577 - accuracy: 0.5194 - val_loss: 1.4595 - val_accuracy: 0.4851\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.3499 - accuracy: 0.5180 - val_loss: 1.4589 - val_accuracy: 0.4761\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.3329 - accuracy: 0.5258 - val_loss: 1.4069 - val_accuracy: 0.5078\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.3323 - accuracy: 0.5241 - val_loss: 1.4254 - val_accuracy: 0.4982\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.3166 - accuracy: 0.5342 - val_loss: 1.4269 - val_accuracy: 0.4947\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 2s - loss: 1.3113 - accuracy: 0.5353 - val_loss: 1.3729 - val_accuracy: 0.5107\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.2981 - accuracy: 0.5383 - val_loss: 1.3761 - val_accuracy: 0.5065\n",
            "\n",
            "Epoch 23/100\n",
            "782/782 - 2s - loss: 1.2879 - accuracy: 0.5407 - val_loss: 1.3666 - val_accuracy: 0.5136\n",
            "\n",
            "Epoch 24/100\n",
            "782/782 - 2s - loss: 1.2852 - accuracy: 0.5439 - val_loss: 1.3850 - val_accuracy: 0.5104\n",
            "\n",
            "Epoch 25/100\n",
            "782/782 - 2s - loss: 1.2697 - accuracy: 0.5497 - val_loss: 1.3950 - val_accuracy: 0.5055\n",
            "\n",
            "Epoch 26/100\n",
            "782/782 - 2s - loss: 1.2699 - accuracy: 0.5501 - val_loss: 1.3688 - val_accuracy: 0.5195\n",
            "\n",
            "Epoch 27/100\n",
            "782/782 - 2s - loss: 1.2582 - accuracy: 0.5526 - val_loss: 1.3648 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 28/100\n",
            "782/782 - 2s - loss: 1.2466 - accuracy: 0.5555 - val_loss: 1.4042 - val_accuracy: 0.4973\n",
            "\n",
            "Epoch 29/100\n",
            "782/782 - 2s - loss: 1.2424 - accuracy: 0.5590 - val_loss: 1.3893 - val_accuracy: 0.5033\n",
            "\n",
            "Epoch 30/100\n",
            "782/782 - 2s - loss: 1.2390 - accuracy: 0.5592 - val_loss: 1.3714 - val_accuracy: 0.5206\n",
            "\n",
            "Epoch 31/100\n",
            "782/782 - 2s - loss: 1.2248 - accuracy: 0.5648 - val_loss: 1.3720 - val_accuracy: 0.5166\n",
            "\n",
            "Epoch 32/100\n",
            "782/782 - 2s - loss: 1.2302 - accuracy: 0.5617 - val_loss: 1.3627 - val_accuracy: 0.5277\n",
            "\n",
            "Epoch 33/100\n",
            "782/782 - 2s - loss: 1.2203 - accuracy: 0.5659 - val_loss: 1.4119 - val_accuracy: 0.5180\n",
            "\n",
            "Epoch 34/100\n",
            "782/782 - 2s - loss: 1.2059 - accuracy: 0.5684 - val_loss: 1.3812 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 35/100\n",
            "782/782 - 2s - loss: 1.2010 - accuracy: 0.5753 - val_loss: 1.3969 - val_accuracy: 0.5157\n",
            "\n",
            "Epoch 36/100\n",
            "782/782 - 2s - loss: 1.2027 - accuracy: 0.5710 - val_loss: 1.4159 - val_accuracy: 0.5125\n",
            "\n",
            "Epoch 37/100\n",
            "782/782 - 2s - loss: 1.1943 - accuracy: 0.5750 - val_loss: 1.3857 - val_accuracy: 0.5135\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5277000069618225\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "512\n",
            "0.17600587221315478\n",
            "0.40232814274544404\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0208 - accuracy: 0.2824 - val_loss: 1.8119 - val_accuracy: 0.3576\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8379 - accuracy: 0.3431 - val_loss: 1.7322 - val_accuracy: 0.3904\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7637 - accuracy: 0.3755 - val_loss: 1.7209 - val_accuracy: 0.3904\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6942 - accuracy: 0.3979 - val_loss: 1.5956 - val_accuracy: 0.4369\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6649 - accuracy: 0.4108 - val_loss: 1.5885 - val_accuracy: 0.4301\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6361 - accuracy: 0.4204 - val_loss: 1.5479 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6085 - accuracy: 0.4283 - val_loss: 1.5499 - val_accuracy: 0.4576\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5842 - accuracy: 0.4396 - val_loss: 1.5031 - val_accuracy: 0.4675\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5624 - accuracy: 0.4443 - val_loss: 1.5698 - val_accuracy: 0.4498\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5425 - accuracy: 0.4522 - val_loss: 1.5314 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5369 - accuracy: 0.4566 - val_loss: 1.4790 - val_accuracy: 0.4760\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5195 - accuracy: 0.4620 - val_loss: 1.4736 - val_accuracy: 0.4751\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5058 - accuracy: 0.4660 - val_loss: 1.4681 - val_accuracy: 0.4758\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4823 - accuracy: 0.4749 - val_loss: 1.4593 - val_accuracy: 0.4703\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4865 - accuracy: 0.4734 - val_loss: 1.4766 - val_accuracy: 0.4715\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4752 - accuracy: 0.4779 - val_loss: 1.4384 - val_accuracy: 0.4874\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4621 - accuracy: 0.4806 - val_loss: 1.4129 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4476 - accuracy: 0.4861 - val_loss: 1.4501 - val_accuracy: 0.4819\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4483 - accuracy: 0.4874 - val_loss: 1.4083 - val_accuracy: 0.4979\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4279 - accuracy: 0.4911 - val_loss: 1.3936 - val_accuracy: 0.5091\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4248 - accuracy: 0.4940 - val_loss: 1.4334 - val_accuracy: 0.4893\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.4132 - accuracy: 0.5013 - val_loss: 1.3896 - val_accuracy: 0.5072\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.4093 - accuracy: 0.4986 - val_loss: 1.3870 - val_accuracy: 0.5077\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.3973 - accuracy: 0.5032 - val_loss: 1.4073 - val_accuracy: 0.5036\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.3945 - accuracy: 0.5059 - val_loss: 1.3750 - val_accuracy: 0.5143\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.3923 - accuracy: 0.5041 - val_loss: 1.5320 - val_accuracy: 0.4661\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.3823 - accuracy: 0.5099 - val_loss: 1.4286 - val_accuracy: 0.4869\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.3787 - accuracy: 0.5101 - val_loss: 1.3974 - val_accuracy: 0.5067\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.3642 - accuracy: 0.5142 - val_loss: 1.3534 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.3679 - accuracy: 0.5141 - val_loss: 1.3840 - val_accuracy: 0.5073\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.3577 - accuracy: 0.5176 - val_loss: 1.3425 - val_accuracy: 0.5260\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.3514 - accuracy: 0.5189 - val_loss: 1.4277 - val_accuracy: 0.4960\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.3519 - accuracy: 0.5200 - val_loss: 1.3889 - val_accuracy: 0.5037\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.3525 - accuracy: 0.5202 - val_loss: 1.3937 - val_accuracy: 0.4960\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.3381 - accuracy: 0.5256 - val_loss: 1.3596 - val_accuracy: 0.5178\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.3327 - accuracy: 0.5283 - val_loss: 1.3684 - val_accuracy: 0.5131\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5260000228881836\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "128\n",
            "0.30376066741272517\n",
            "0.20903819879722335\n",
            "leakyrelu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 2s - loss: 2.0556 - accuracy: 0.2508 - val_loss: 1.8830 - val_accuracy: 0.3491\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.8887 - accuracy: 0.3287 - val_loss: 1.8048 - val_accuracy: 0.3708\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8256 - accuracy: 0.3530 - val_loss: 1.7519 - val_accuracy: 0.3931\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7839 - accuracy: 0.3694 - val_loss: 1.7287 - val_accuracy: 0.3943\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7492 - accuracy: 0.3851 - val_loss: 1.6815 - val_accuracy: 0.4170\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7245 - accuracy: 0.3917 - val_loss: 1.6937 - val_accuracy: 0.4036\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.7010 - accuracy: 0.4018 - val_loss: 1.6558 - val_accuracy: 0.4160\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.6814 - accuracy: 0.4104 - val_loss: 1.6224 - val_accuracy: 0.4380\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.6650 - accuracy: 0.4166 - val_loss: 1.6141 - val_accuracy: 0.4414\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6521 - accuracy: 0.4172 - val_loss: 1.5938 - val_accuracy: 0.4415\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6358 - accuracy: 0.4276 - val_loss: 1.6271 - val_accuracy: 0.4292\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.6250 - accuracy: 0.4283 - val_loss: 1.6251 - val_accuracy: 0.4305\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.6148 - accuracy: 0.4342 - val_loss: 1.5736 - val_accuracy: 0.4479\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.6003 - accuracy: 0.4389 - val_loss: 1.5625 - val_accuracy: 0.4559\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.5904 - accuracy: 0.4419 - val_loss: 1.5455 - val_accuracy: 0.4586\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.5849 - accuracy: 0.4454 - val_loss: 1.5316 - val_accuracy: 0.4678\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.5756 - accuracy: 0.4461 - val_loss: 1.5663 - val_accuracy: 0.4411\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.5666 - accuracy: 0.4507 - val_loss: 1.5397 - val_accuracy: 0.4623\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.5617 - accuracy: 0.4534 - val_loss: 1.5316 - val_accuracy: 0.4605\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.5518 - accuracy: 0.4550 - val_loss: 1.5071 - val_accuracy: 0.4745\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.5415 - accuracy: 0.4586 - val_loss: 1.5073 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.5343 - accuracy: 0.4618 - val_loss: 1.5410 - val_accuracy: 0.4602\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.5291 - accuracy: 0.4640 - val_loss: 1.4880 - val_accuracy: 0.4800\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.5230 - accuracy: 0.4689 - val_loss: 1.4892 - val_accuracy: 0.4768\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.5127 - accuracy: 0.4705 - val_loss: 1.5085 - val_accuracy: 0.4636\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.5061 - accuracy: 0.4758 - val_loss: 1.4876 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.5020 - accuracy: 0.4734 - val_loss: 1.4603 - val_accuracy: 0.4842\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.4947 - accuracy: 0.4761 - val_loss: 1.4701 - val_accuracy: 0.4845\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.4936 - accuracy: 0.4755 - val_loss: 1.4757 - val_accuracy: 0.4782\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.4855 - accuracy: 0.4797 - val_loss: 1.4672 - val_accuracy: 0.4765\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.4802 - accuracy: 0.4812 - val_loss: 1.4771 - val_accuracy: 0.4768\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.4746 - accuracy: 0.4811 - val_loss: 1.4486 - val_accuracy: 0.4864\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.4682 - accuracy: 0.4873 - val_loss: 1.4735 - val_accuracy: 0.4870\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.4666 - accuracy: 0.4861 - val_loss: 1.5195 - val_accuracy: 0.4720\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.4612 - accuracy: 0.4867 - val_loss: 1.4611 - val_accuracy: 0.4847\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.4583 - accuracy: 0.4887 - val_loss: 1.4673 - val_accuracy: 0.4846\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.4560 - accuracy: 0.4903 - val_loss: 1.4203 - val_accuracy: 0.5009\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 1s - loss: 1.4465 - accuracy: 0.4907 - val_loss: 1.4278 - val_accuracy: 0.4995\n",
            "\n",
            "Epoch 39/100\n",
            "391/391 - 1s - loss: 1.4466 - accuracy: 0.4939 - val_loss: 1.4300 - val_accuracy: 0.4985\n",
            "\n",
            "Epoch 40/100\n",
            "391/391 - 1s - loss: 1.4371 - accuracy: 0.4955 - val_loss: 1.4300 - val_accuracy: 0.4988\n",
            "\n",
            "Epoch 41/100\n",
            "391/391 - 1s - loss: 1.4372 - accuracy: 0.4962 - val_loss: 1.4318 - val_accuracy: 0.4948\n",
            "\n",
            "Epoch 42/100\n",
            "391/391 - 1s - loss: 1.4311 - accuracy: 0.4973 - val_loss: 1.4222 - val_accuracy: 0.4930\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5008999705314636\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.09490274165632118\n",
            "0.369050458300508\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9490 - accuracy: 0.2983 - val_loss: 1.7554 - val_accuracy: 0.3858\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7815 - accuracy: 0.3665 - val_loss: 1.6704 - val_accuracy: 0.4043\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7003 - accuracy: 0.3949 - val_loss: 1.6224 - val_accuracy: 0.4233\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6551 - accuracy: 0.4129 - val_loss: 1.5728 - val_accuracy: 0.4444\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6199 - accuracy: 0.4269 - val_loss: 1.5491 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5931 - accuracy: 0.4358 - val_loss: 1.6236 - val_accuracy: 0.4078\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5688 - accuracy: 0.4434 - val_loss: 1.5157 - val_accuracy: 0.4683\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5351 - accuracy: 0.4555 - val_loss: 1.4883 - val_accuracy: 0.4665\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5190 - accuracy: 0.4624 - val_loss: 1.4660 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5071 - accuracy: 0.4678 - val_loss: 1.4528 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4908 - accuracy: 0.4717 - val_loss: 1.4589 - val_accuracy: 0.4869\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4755 - accuracy: 0.4773 - val_loss: 1.4313 - val_accuracy: 0.4919\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4651 - accuracy: 0.4797 - val_loss: 1.4930 - val_accuracy: 0.4644\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4463 - accuracy: 0.4880 - val_loss: 1.4387 - val_accuracy: 0.4815\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4521 - accuracy: 0.4861 - val_loss: 1.4199 - val_accuracy: 0.4945\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4244 - accuracy: 0.4951 - val_loss: 1.4295 - val_accuracy: 0.4854\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4216 - accuracy: 0.4946 - val_loss: 1.3993 - val_accuracy: 0.4992\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4076 - accuracy: 0.5012 - val_loss: 1.3904 - val_accuracy: 0.5107\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.3987 - accuracy: 0.5045 - val_loss: 1.4311 - val_accuracy: 0.4841\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.3908 - accuracy: 0.5091 - val_loss: 1.3936 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.3856 - accuracy: 0.5064 - val_loss: 1.3658 - val_accuracy: 0.5163\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.3686 - accuracy: 0.5141 - val_loss: 1.4160 - val_accuracy: 0.4928\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.3665 - accuracy: 0.5151 - val_loss: 1.3489 - val_accuracy: 0.5187\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.3556 - accuracy: 0.5175 - val_loss: 1.3573 - val_accuracy: 0.5219\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.3560 - accuracy: 0.5197 - val_loss: 1.3528 - val_accuracy: 0.5137\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.3404 - accuracy: 0.5247 - val_loss: 1.3833 - val_accuracy: 0.5107\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.3411 - accuracy: 0.5258 - val_loss: 1.3492 - val_accuracy: 0.5203\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.3328 - accuracy: 0.5262 - val_loss: 1.3695 - val_accuracy: 0.5087\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.3349 - accuracy: 0.5265 - val_loss: 1.3530 - val_accuracy: 0.5187\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5218999981880188\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "64\n",
            "0.05385886248086531\n",
            "0.30357909124655114\n",
            "relu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0416 - accuracy: 0.2487 - val_loss: 1.8412 - val_accuracy: 0.3436\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8584 - accuracy: 0.3274 - val_loss: 1.7404 - val_accuracy: 0.3722\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7892 - accuracy: 0.3600 - val_loss: 1.7124 - val_accuracy: 0.3796\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7523 - accuracy: 0.3726 - val_loss: 1.7076 - val_accuracy: 0.3986\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.7291 - accuracy: 0.3790 - val_loss: 1.6532 - val_accuracy: 0.4148\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.7001 - accuracy: 0.3924 - val_loss: 1.6309 - val_accuracy: 0.4173\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6801 - accuracy: 0.3988 - val_loss: 1.5979 - val_accuracy: 0.4334\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6651 - accuracy: 0.4049 - val_loss: 1.5821 - val_accuracy: 0.4399\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.6508 - accuracy: 0.4110 - val_loss: 1.5751 - val_accuracy: 0.4416\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.6374 - accuracy: 0.4139 - val_loss: 1.5747 - val_accuracy: 0.4428\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.6213 - accuracy: 0.4195 - val_loss: 1.5641 - val_accuracy: 0.4417\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.6144 - accuracy: 0.4233 - val_loss: 1.5704 - val_accuracy: 0.4381\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6143 - accuracy: 0.4220 - val_loss: 1.5629 - val_accuracy: 0.4383\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6026 - accuracy: 0.4256 - val_loss: 1.5298 - val_accuracy: 0.4549\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5943 - accuracy: 0.4297 - val_loss: 1.5485 - val_accuracy: 0.4440\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5909 - accuracy: 0.4305 - val_loss: 1.5314 - val_accuracy: 0.4544\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5874 - accuracy: 0.4297 - val_loss: 1.5424 - val_accuracy: 0.4550\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5805 - accuracy: 0.4340 - val_loss: 1.5159 - val_accuracy: 0.4613\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.5750 - accuracy: 0.4367 - val_loss: 1.5218 - val_accuracy: 0.4519\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.5636 - accuracy: 0.4419 - val_loss: 1.5260 - val_accuracy: 0.4560\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.5634 - accuracy: 0.4384 - val_loss: 1.5248 - val_accuracy: 0.4563\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.5604 - accuracy: 0.4408 - val_loss: 1.5205 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.5534 - accuracy: 0.4445 - val_loss: 1.5283 - val_accuracy: 0.4572\n",
            "\n",
            "legjobb val_acc:\n",
            "0.46129998564720154\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "32\n",
            "0.2571017899370674\n",
            "0.11453853784788155\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.2977 - accuracy: 0.2046 - val_loss: 2.0010 - val_accuracy: 0.2673\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.0357 - accuracy: 0.2708 - val_loss: 1.9406 - val_accuracy: 0.2939\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9480 - accuracy: 0.3047 - val_loss: 1.9335 - val_accuracy: 0.3048\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8989 - accuracy: 0.3217 - val_loss: 1.7813 - val_accuracy: 0.3673\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8611 - accuracy: 0.3384 - val_loss: 1.7644 - val_accuracy: 0.3710\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8234 - accuracy: 0.3502 - val_loss: 1.7789 - val_accuracy: 0.3714\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8027 - accuracy: 0.3582 - val_loss: 1.7865 - val_accuracy: 0.3739\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7750 - accuracy: 0.3681 - val_loss: 1.7113 - val_accuracy: 0.3827\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7552 - accuracy: 0.3778 - val_loss: 1.9066 - val_accuracy: 0.3226\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7399 - accuracy: 0.3817 - val_loss: 1.6738 - val_accuracy: 0.4017\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7215 - accuracy: 0.3880 - val_loss: 1.6317 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7067 - accuracy: 0.3926 - val_loss: 1.6632 - val_accuracy: 0.3955\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6983 - accuracy: 0.3952 - val_loss: 1.6033 - val_accuracy: 0.4303\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6906 - accuracy: 0.4006 - val_loss: 1.6877 - val_accuracy: 0.4061\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6762 - accuracy: 0.4049 - val_loss: 1.6698 - val_accuracy: 0.4049\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6721 - accuracy: 0.4055 - val_loss: 1.5900 - val_accuracy: 0.4350\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6614 - accuracy: 0.4088 - val_loss: 1.6517 - val_accuracy: 0.4189\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6598 - accuracy: 0.4122 - val_loss: 1.5652 - val_accuracy: 0.4439\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6463 - accuracy: 0.4162 - val_loss: 1.6496 - val_accuracy: 0.4112\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.6408 - accuracy: 0.4157 - val_loss: 1.6103 - val_accuracy: 0.4266\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.6384 - accuracy: 0.4174 - val_loss: 1.5781 - val_accuracy: 0.4470\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6317 - accuracy: 0.4212 - val_loss: 1.6196 - val_accuracy: 0.4147\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.6236 - accuracy: 0.4214 - val_loss: 1.6479 - val_accuracy: 0.4091\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.6229 - accuracy: 0.4224 - val_loss: 1.5769 - val_accuracy: 0.4328\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.6190 - accuracy: 0.4237 - val_loss: 1.6823 - val_accuracy: 0.3973\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.6116 - accuracy: 0.4270 - val_loss: 1.5519 - val_accuracy: 0.4519\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.6062 - accuracy: 0.4303 - val_loss: 1.5297 - val_accuracy: 0.4626\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.6054 - accuracy: 0.4310 - val_loss: 1.5227 - val_accuracy: 0.4635\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.5992 - accuracy: 0.4325 - val_loss: 1.5696 - val_accuracy: 0.4395\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.5961 - accuracy: 0.4345 - val_loss: 1.5017 - val_accuracy: 0.4674\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.5909 - accuracy: 0.4351 - val_loss: 1.5663 - val_accuracy: 0.4449\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.5876 - accuracy: 0.4337 - val_loss: 1.5138 - val_accuracy: 0.4589\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.5862 - accuracy: 0.4381 - val_loss: 1.5520 - val_accuracy: 0.4472\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.5829 - accuracy: 0.4377 - val_loss: 1.6106 - val_accuracy: 0.4102\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.5799 - accuracy: 0.4397 - val_loss: 1.5306 - val_accuracy: 0.4569\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4674000144004822\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "512\n",
            "0.4925848116515753\n",
            "0.18257237752885513\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 2.0286 - accuracy: 0.2507 - val_loss: 1.8056 - val_accuracy: 0.3669\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.9080 - accuracy: 0.3077 - val_loss: 1.7629 - val_accuracy: 0.3677\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.8688 - accuracy: 0.3277 - val_loss: 1.7242 - val_accuracy: 0.3839\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.8431 - accuracy: 0.3359 - val_loss: 1.7109 - val_accuracy: 0.3992\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.8209 - accuracy: 0.3424 - val_loss: 1.7151 - val_accuracy: 0.3818\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.8003 - accuracy: 0.3516 - val_loss: 1.7109 - val_accuracy: 0.3821\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.7935 - accuracy: 0.3525 - val_loss: 1.6567 - val_accuracy: 0.4096\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.7855 - accuracy: 0.3550 - val_loss: 1.6486 - val_accuracy: 0.4144\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.7710 - accuracy: 0.3610 - val_loss: 1.6618 - val_accuracy: 0.4098\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.7646 - accuracy: 0.3662 - val_loss: 1.6582 - val_accuracy: 0.4043\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.7603 - accuracy: 0.3680 - val_loss: 1.6435 - val_accuracy: 0.4117\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.7582 - accuracy: 0.3688 - val_loss: 1.6778 - val_accuracy: 0.3961\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.7484 - accuracy: 0.3726 - val_loss: 1.5985 - val_accuracy: 0.4361\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.7468 - accuracy: 0.3705 - val_loss: 1.6137 - val_accuracy: 0.4084\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.7355 - accuracy: 0.3770 - val_loss: 1.6071 - val_accuracy: 0.4162\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.7336 - accuracy: 0.3779 - val_loss: 1.6088 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.7329 - accuracy: 0.3739 - val_loss: 1.6406 - val_accuracy: 0.4070\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.7326 - accuracy: 0.3773 - val_loss: 1.5938 - val_accuracy: 0.4330\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4361000061035156\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.07015354877290131\n",
            "0.04479465150451655\n",
            "leakyrelu\n",
            "sgd\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1429 - accuracy: 0.2250 - val_loss: 2.0197 - val_accuracy: 0.2898\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9681 - accuracy: 0.3001 - val_loss: 1.9152 - val_accuracy: 0.3346\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9000 - accuracy: 0.3277 - val_loss: 1.8667 - val_accuracy: 0.3392\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8596 - accuracy: 0.3438 - val_loss: 1.8568 - val_accuracy: 0.3507\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8290 - accuracy: 0.3569 - val_loss: 1.8072 - val_accuracy: 0.3650\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8031 - accuracy: 0.3638 - val_loss: 1.7778 - val_accuracy: 0.3803\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7822 - accuracy: 0.3728 - val_loss: 1.7677 - val_accuracy: 0.3761\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7643 - accuracy: 0.3801 - val_loss: 1.7470 - val_accuracy: 0.3867\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7489 - accuracy: 0.3877 - val_loss: 1.7360 - val_accuracy: 0.3889\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7329 - accuracy: 0.3917 - val_loss: 1.7234 - val_accuracy: 0.3941\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7187 - accuracy: 0.3980 - val_loss: 1.7832 - val_accuracy: 0.3625\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7036 - accuracy: 0.4031 - val_loss: 1.7228 - val_accuracy: 0.3987\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6916 - accuracy: 0.4069 - val_loss: 1.6927 - val_accuracy: 0.4025\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6796 - accuracy: 0.4099 - val_loss: 1.7212 - val_accuracy: 0.3929\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6686 - accuracy: 0.4148 - val_loss: 1.6705 - val_accuracy: 0.4140\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6584 - accuracy: 0.4196 - val_loss: 1.6426 - val_accuracy: 0.4255\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6462 - accuracy: 0.4235 - val_loss: 1.6543 - val_accuracy: 0.4174\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6397 - accuracy: 0.4248 - val_loss: 1.6329 - val_accuracy: 0.4230\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6286 - accuracy: 0.4301 - val_loss: 1.6184 - val_accuracy: 0.4313\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.6217 - accuracy: 0.4337 - val_loss: 1.6242 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.6119 - accuracy: 0.4375 - val_loss: 1.6118 - val_accuracy: 0.4320\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6052 - accuracy: 0.4391 - val_loss: 1.6009 - val_accuracy: 0.4342\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.5976 - accuracy: 0.4390 - val_loss: 1.6067 - val_accuracy: 0.4310\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.5908 - accuracy: 0.4432 - val_loss: 1.6555 - val_accuracy: 0.4166\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.5811 - accuracy: 0.4477 - val_loss: 1.6481 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.5760 - accuracy: 0.4463 - val_loss: 1.5996 - val_accuracy: 0.4350\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.5719 - accuracy: 0.4498 - val_loss: 1.5661 - val_accuracy: 0.4470\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.5675 - accuracy: 0.4501 - val_loss: 1.5965 - val_accuracy: 0.4359\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.5575 - accuracy: 0.4537 - val_loss: 1.5628 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.5518 - accuracy: 0.4575 - val_loss: 1.5973 - val_accuracy: 0.4311\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.5462 - accuracy: 0.4606 - val_loss: 1.5526 - val_accuracy: 0.4537\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.5404 - accuracy: 0.4624 - val_loss: 1.6141 - val_accuracy: 0.4341\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.5357 - accuracy: 0.4625 - val_loss: 1.6377 - val_accuracy: 0.4124\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.5340 - accuracy: 0.4647 - val_loss: 1.5508 - val_accuracy: 0.4569\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.5279 - accuracy: 0.4638 - val_loss: 1.6030 - val_accuracy: 0.4335\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.5203 - accuracy: 0.4677 - val_loss: 1.5259 - val_accuracy: 0.4644\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.5179 - accuracy: 0.4678 - val_loss: 1.5490 - val_accuracy: 0.4534\n",
            "\n",
            "Epoch 38/100\n",
            "196/196 - 1s - loss: 1.5140 - accuracy: 0.4714 - val_loss: 1.5230 - val_accuracy: 0.4559\n",
            "\n",
            "Epoch 39/100\n",
            "196/196 - 1s - loss: 1.5061 - accuracy: 0.4713 - val_loss: 1.5102 - val_accuracy: 0.4658\n",
            "\n",
            "Epoch 40/100\n",
            "196/196 - 1s - loss: 1.5056 - accuracy: 0.4730 - val_loss: 1.5777 - val_accuracy: 0.4447\n",
            "\n",
            "Epoch 41/100\n",
            "196/196 - 1s - loss: 1.5049 - accuracy: 0.4754 - val_loss: 1.5798 - val_accuracy: 0.4461\n",
            "\n",
            "Epoch 42/100\n",
            "196/196 - 1s - loss: 1.4995 - accuracy: 0.4774 - val_loss: 1.5230 - val_accuracy: 0.4599\n",
            "\n",
            "Epoch 43/100\n",
            "196/196 - 1s - loss: 1.4921 - accuracy: 0.4772 - val_loss: 1.5322 - val_accuracy: 0.4604\n",
            "\n",
            "Epoch 44/100\n",
            "196/196 - 1s - loss: 1.4888 - accuracy: 0.4801 - val_loss: 1.5364 - val_accuracy: 0.4561\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4657999873161316\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "128\n",
            "0.14505853657100057\n",
            "0.28267670667340095\n",
            "relu\n",
            "adam\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 2s - loss: 2.0132 - accuracy: 0.2571 - val_loss: 1.8705 - val_accuracy: 0.3348\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.8748 - accuracy: 0.3177 - val_loss: 1.7616 - val_accuracy: 0.3626\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8199 - accuracy: 0.3394 - val_loss: 1.7432 - val_accuracy: 0.3742\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7866 - accuracy: 0.3524 - val_loss: 1.6786 - val_accuracy: 0.4021\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7563 - accuracy: 0.3645 - val_loss: 1.6703 - val_accuracy: 0.4029\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7375 - accuracy: 0.3705 - val_loss: 1.6801 - val_accuracy: 0.4051\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.7275 - accuracy: 0.3767 - val_loss: 1.6528 - val_accuracy: 0.4104\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.7091 - accuracy: 0.3825 - val_loss: 1.6356 - val_accuracy: 0.4108\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.7075 - accuracy: 0.3829 - val_loss: 1.6251 - val_accuracy: 0.4248\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6870 - accuracy: 0.3903 - val_loss: 1.6125 - val_accuracy: 0.4215\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6844 - accuracy: 0.3906 - val_loss: 1.6068 - val_accuracy: 0.4224\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.6749 - accuracy: 0.3938 - val_loss: 1.5894 - val_accuracy: 0.4327\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.6688 - accuracy: 0.4021 - val_loss: 1.5763 - val_accuracy: 0.4385\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.6655 - accuracy: 0.3995 - val_loss: 1.5657 - val_accuracy: 0.4418\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.6627 - accuracy: 0.4008 - val_loss: 1.5602 - val_accuracy: 0.4470\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.6503 - accuracy: 0.4073 - val_loss: 1.5726 - val_accuracy: 0.4399\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.6565 - accuracy: 0.4016 - val_loss: 1.5884 - val_accuracy: 0.4340\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.6483 - accuracy: 0.4058 - val_loss: 1.5711 - val_accuracy: 0.4450\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.6461 - accuracy: 0.4069 - val_loss: 1.5717 - val_accuracy: 0.4434\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.6385 - accuracy: 0.4092 - val_loss: 1.5853 - val_accuracy: 0.4312\n",
            "\n",
            "legjobb val_acc:\n",
            "0.44699999690055847\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "512\n",
            "0.016978868907642372\n",
            "0.14203638327672782\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1127 - accuracy: 0.2864 - val_loss: 1.9009 - val_accuracy: 0.3238\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7628 - accuracy: 0.3744 - val_loss: 1.7087 - val_accuracy: 0.3834\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.6855 - accuracy: 0.4016 - val_loss: 1.6731 - val_accuracy: 0.4133\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6172 - accuracy: 0.4268 - val_loss: 1.5601 - val_accuracy: 0.4532\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.5737 - accuracy: 0.4420 - val_loss: 1.5367 - val_accuracy: 0.4552\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5513 - accuracy: 0.4471 - val_loss: 1.5671 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5138 - accuracy: 0.4647 - val_loss: 1.5209 - val_accuracy: 0.4564\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.4842 - accuracy: 0.4735 - val_loss: 1.5000 - val_accuracy: 0.4613\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.4621 - accuracy: 0.4811 - val_loss: 1.6893 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.4208 - accuracy: 0.4963 - val_loss: 1.5918 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4202 - accuracy: 0.4957 - val_loss: 1.4120 - val_accuracy: 0.5008\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.3949 - accuracy: 0.5029 - val_loss: 1.4325 - val_accuracy: 0.4916\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.3660 - accuracy: 0.5154 - val_loss: 1.3950 - val_accuracy: 0.5035\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.3545 - accuracy: 0.5171 - val_loss: 1.4296 - val_accuracy: 0.4884\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.3464 - accuracy: 0.5224 - val_loss: 1.3996 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.3165 - accuracy: 0.5338 - val_loss: 1.4371 - val_accuracy: 0.4925\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.3130 - accuracy: 0.5341 - val_loss: 1.3823 - val_accuracy: 0.5119\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.2853 - accuracy: 0.5435 - val_loss: 1.3968 - val_accuracy: 0.5119\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.2888 - accuracy: 0.5426 - val_loss: 1.3746 - val_accuracy: 0.5110\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.2627 - accuracy: 0.5511 - val_loss: 1.4494 - val_accuracy: 0.4897\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.2534 - accuracy: 0.5548 - val_loss: 1.4133 - val_accuracy: 0.5063\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.2564 - accuracy: 0.5518 - val_loss: 1.3602 - val_accuracy: 0.5220\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.2258 - accuracy: 0.5643 - val_loss: 1.4544 - val_accuracy: 0.4890\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.2255 - accuracy: 0.5640 - val_loss: 1.4514 - val_accuracy: 0.4912\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.2162 - accuracy: 0.5675 - val_loss: 1.4310 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.2131 - accuracy: 0.5667 - val_loss: 1.3372 - val_accuracy: 0.5207\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.1965 - accuracy: 0.5723 - val_loss: 1.4203 - val_accuracy: 0.5077\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5220000147819519\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "64\n",
            "0.21341057555594073\n",
            "0.1558121156104726\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.6586 - accuracy: 0.1929 - val_loss: 2.2305 - val_accuracy: 0.2339\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.1256 - accuracy: 0.2575 - val_loss: 2.1119 - val_accuracy: 0.2724\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 2.0241 - accuracy: 0.2833 - val_loss: 1.8890 - val_accuracy: 0.2964\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9501 - accuracy: 0.3058 - val_loss: 1.9091 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8953 - accuracy: 0.3252 - val_loss: 1.8152 - val_accuracy: 0.3439\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8488 - accuracy: 0.3390 - val_loss: 1.7828 - val_accuracy: 0.3561\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8043 - accuracy: 0.3579 - val_loss: 1.8399 - val_accuracy: 0.3239\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7686 - accuracy: 0.3682 - val_loss: 1.8145 - val_accuracy: 0.3718\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7370 - accuracy: 0.3844 - val_loss: 1.9401 - val_accuracy: 0.3254\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7122 - accuracy: 0.3920 - val_loss: 1.8009 - val_accuracy: 0.3744\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.6927 - accuracy: 0.3997 - val_loss: 1.6374 - val_accuracy: 0.4120\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.6706 - accuracy: 0.4096 - val_loss: 1.6302 - val_accuracy: 0.4160\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6531 - accuracy: 0.4138 - val_loss: 1.6078 - val_accuracy: 0.4262\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6365 - accuracy: 0.4207 - val_loss: 1.6096 - val_accuracy: 0.4169\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6251 - accuracy: 0.4241 - val_loss: 1.5676 - val_accuracy: 0.4446\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6116 - accuracy: 0.4281 - val_loss: 1.5744 - val_accuracy: 0.4364\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6015 - accuracy: 0.4303 - val_loss: 1.5894 - val_accuracy: 0.4301\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5920 - accuracy: 0.4366 - val_loss: 1.5964 - val_accuracy: 0.4301\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.5777 - accuracy: 0.4385 - val_loss: 1.6551 - val_accuracy: 0.4187\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.5746 - accuracy: 0.4399 - val_loss: 1.6755 - val_accuracy: 0.3901\n",
            "\n",
            "legjobb val_acc:\n",
            "0.444599986076355\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "32\n",
            "0.1962218450127035\n",
            "0.09818249567275467\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 1.9902 - accuracy: 0.2806 - val_loss: 1.7772 - val_accuracy: 0.3641\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.8273 - accuracy: 0.3439 - val_loss: 1.7451 - val_accuracy: 0.3796\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.7595 - accuracy: 0.3716 - val_loss: 1.6735 - val_accuracy: 0.3975\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.7105 - accuracy: 0.3912 - val_loss: 1.6422 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.6857 - accuracy: 0.3991 - val_loss: 1.6009 - val_accuracy: 0.4195\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.6589 - accuracy: 0.4090 - val_loss: 1.5906 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.6365 - accuracy: 0.4159 - val_loss: 1.5796 - val_accuracy: 0.4415\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.6163 - accuracy: 0.4265 - val_loss: 1.5480 - val_accuracy: 0.4438\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.5964 - accuracy: 0.4336 - val_loss: 1.5861 - val_accuracy: 0.4290\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.5875 - accuracy: 0.4332 - val_loss: 1.5388 - val_accuracy: 0.4546\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.5770 - accuracy: 0.4385 - val_loss: 1.5379 - val_accuracy: 0.4536\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.5636 - accuracy: 0.4436 - val_loss: 1.4793 - val_accuracy: 0.4769\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.5470 - accuracy: 0.4490 - val_loss: 1.5454 - val_accuracy: 0.4490\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.5425 - accuracy: 0.4519 - val_loss: 1.5002 - val_accuracy: 0.4677\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.5295 - accuracy: 0.4581 - val_loss: 1.4969 - val_accuracy: 0.4617\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.5218 - accuracy: 0.4581 - val_loss: 1.4633 - val_accuracy: 0.4777\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.5151 - accuracy: 0.4648 - val_loss: 1.4998 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.5082 - accuracy: 0.4629 - val_loss: 1.4437 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.5008 - accuracy: 0.4632 - val_loss: 1.4492 - val_accuracy: 0.4855\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.4872 - accuracy: 0.4715 - val_loss: 1.4271 - val_accuracy: 0.4978\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 2s - loss: 1.4869 - accuracy: 0.4734 - val_loss: 1.4774 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.4824 - accuracy: 0.4726 - val_loss: 1.4322 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 23/100\n",
            "782/782 - 2s - loss: 1.4747 - accuracy: 0.4776 - val_loss: 1.4737 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 24/100\n",
            "782/782 - 2s - loss: 1.4712 - accuracy: 0.4748 - val_loss: 1.4165 - val_accuracy: 0.4999\n",
            "\n",
            "Epoch 25/100\n",
            "782/782 - 2s - loss: 1.4633 - accuracy: 0.4772 - val_loss: 1.4686 - val_accuracy: 0.4628\n",
            "\n",
            "Epoch 26/100\n",
            "782/782 - 2s - loss: 1.4629 - accuracy: 0.4806 - val_loss: 1.4325 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 27/100\n",
            "782/782 - 2s - loss: 1.4541 - accuracy: 0.4837 - val_loss: 1.4384 - val_accuracy: 0.4945\n",
            "\n",
            "Epoch 28/100\n",
            "782/782 - 2s - loss: 1.4515 - accuracy: 0.4827 - val_loss: 1.4258 - val_accuracy: 0.4949\n",
            "\n",
            "Epoch 29/100\n",
            "782/782 - 2s - loss: 1.4460 - accuracy: 0.4853 - val_loss: 1.4164 - val_accuracy: 0.4972\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4999000132083893\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "512\n",
            "0.1592218714814964\n",
            "0.17311862294050506\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9268 - accuracy: 0.3008 - val_loss: 1.7400 - val_accuracy: 0.3765\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7670 - accuracy: 0.3686 - val_loss: 1.7086 - val_accuracy: 0.3885\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.6940 - accuracy: 0.3985 - val_loss: 1.6009 - val_accuracy: 0.4399\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6501 - accuracy: 0.4143 - val_loss: 1.5878 - val_accuracy: 0.4377\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6099 - accuracy: 0.4275 - val_loss: 1.5363 - val_accuracy: 0.4600\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5768 - accuracy: 0.4389 - val_loss: 1.5205 - val_accuracy: 0.4572\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5621 - accuracy: 0.4460 - val_loss: 1.4926 - val_accuracy: 0.4691\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5374 - accuracy: 0.4537 - val_loss: 1.5098 - val_accuracy: 0.4637\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5237 - accuracy: 0.4603 - val_loss: 1.4745 - val_accuracy: 0.4758\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5089 - accuracy: 0.4635 - val_loss: 1.4930 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4932 - accuracy: 0.4702 - val_loss: 1.5161 - val_accuracy: 0.4533\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4891 - accuracy: 0.4713 - val_loss: 1.4435 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4712 - accuracy: 0.4783 - val_loss: 1.4392 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4668 - accuracy: 0.4794 - val_loss: 1.4701 - val_accuracy: 0.4716\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4522 - accuracy: 0.4840 - val_loss: 1.4480 - val_accuracy: 0.4825\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4450 - accuracy: 0.4830 - val_loss: 1.4129 - val_accuracy: 0.5028\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4391 - accuracy: 0.4901 - val_loss: 1.4173 - val_accuracy: 0.4954\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4226 - accuracy: 0.4942 - val_loss: 1.4152 - val_accuracy: 0.4943\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4174 - accuracy: 0.4967 - val_loss: 1.3792 - val_accuracy: 0.5155\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4049 - accuracy: 0.4998 - val_loss: 1.3820 - val_accuracy: 0.5158\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4041 - accuracy: 0.5010 - val_loss: 1.3745 - val_accuracy: 0.5174\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.3940 - accuracy: 0.5069 - val_loss: 1.3928 - val_accuracy: 0.5070\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.3826 - accuracy: 0.5075 - val_loss: 1.3855 - val_accuracy: 0.5072\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.3746 - accuracy: 0.5115 - val_loss: 1.3724 - val_accuracy: 0.5145\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.3836 - accuracy: 0.5072 - val_loss: 1.4108 - val_accuracy: 0.4973\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.3818 - accuracy: 0.5064 - val_loss: 1.3581 - val_accuracy: 0.5191\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.3549 - accuracy: 0.5187 - val_loss: 1.3742 - val_accuracy: 0.5012\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.3599 - accuracy: 0.5159 - val_loss: 1.3985 - val_accuracy: 0.5017\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.3431 - accuracy: 0.5226 - val_loss: 1.3430 - val_accuracy: 0.5256\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.3533 - accuracy: 0.5171 - val_loss: 1.3651 - val_accuracy: 0.5188\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.3367 - accuracy: 0.5251 - val_loss: 1.3538 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.3408 - accuracy: 0.5218 - val_loss: 1.3538 - val_accuracy: 0.5169\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.3297 - accuracy: 0.5286 - val_loss: 1.3641 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.3246 - accuracy: 0.5284 - val_loss: 1.3520 - val_accuracy: 0.5203\n",
            "\n",
            "legjobb val_acc:\n",
            "0.525600016117096\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.04024678818069148\n",
            "0.24348618497824218\n",
            "relu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 2.0910 - accuracy: 0.2305 - val_loss: 1.9268 - val_accuracy: 0.3217\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.9029 - accuracy: 0.3160 - val_loss: 1.8359 - val_accuracy: 0.3538\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8393 - accuracy: 0.3444 - val_loss: 1.7809 - val_accuracy: 0.3730\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7890 - accuracy: 0.3630 - val_loss: 1.7323 - val_accuracy: 0.3923\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7487 - accuracy: 0.3807 - val_loss: 1.7034 - val_accuracy: 0.4031\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7183 - accuracy: 0.3914 - val_loss: 1.6651 - val_accuracy: 0.4183\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.6900 - accuracy: 0.4011 - val_loss: 1.6366 - val_accuracy: 0.4258\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.6658 - accuracy: 0.4121 - val_loss: 1.6279 - val_accuracy: 0.4233\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.6425 - accuracy: 0.4190 - val_loss: 1.6080 - val_accuracy: 0.4280\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6226 - accuracy: 0.4271 - val_loss: 1.5904 - val_accuracy: 0.4389\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6045 - accuracy: 0.4342 - val_loss: 1.5815 - val_accuracy: 0.4457\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.5885 - accuracy: 0.4396 - val_loss: 1.5580 - val_accuracy: 0.4505\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.5748 - accuracy: 0.4426 - val_loss: 1.5603 - val_accuracy: 0.4461\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.5604 - accuracy: 0.4496 - val_loss: 1.5337 - val_accuracy: 0.4609\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.5439 - accuracy: 0.4540 - val_loss: 1.5444 - val_accuracy: 0.4572\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.5364 - accuracy: 0.4566 - val_loss: 1.5279 - val_accuracy: 0.4658\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.5201 - accuracy: 0.4618 - val_loss: 1.5310 - val_accuracy: 0.4608\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.5101 - accuracy: 0.4654 - val_loss: 1.4926 - val_accuracy: 0.4717\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.5014 - accuracy: 0.4703 - val_loss: 1.5354 - val_accuracy: 0.4596\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.4889 - accuracy: 0.4751 - val_loss: 1.4944 - val_accuracy: 0.4657\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.4834 - accuracy: 0.4753 - val_loss: 1.4908 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.4718 - accuracy: 0.4801 - val_loss: 1.4606 - val_accuracy: 0.4864\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.4597 - accuracy: 0.4835 - val_loss: 1.4728 - val_accuracy: 0.4749\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.4542 - accuracy: 0.4865 - val_loss: 1.4606 - val_accuracy: 0.4802\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.4400 - accuracy: 0.4894 - val_loss: 1.4462 - val_accuracy: 0.4845\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.4391 - accuracy: 0.4919 - val_loss: 1.4335 - val_accuracy: 0.4898\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.4279 - accuracy: 0.4955 - val_loss: 1.4349 - val_accuracy: 0.4883\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.4167 - accuracy: 0.4991 - val_loss: 1.4500 - val_accuracy: 0.4862\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.4121 - accuracy: 0.5008 - val_loss: 1.4236 - val_accuracy: 0.4939\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.4036 - accuracy: 0.5040 - val_loss: 1.4086 - val_accuracy: 0.4980\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.3977 - accuracy: 0.5050 - val_loss: 1.4271 - val_accuracy: 0.4936\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.3921 - accuracy: 0.5079 - val_loss: 1.4340 - val_accuracy: 0.4957\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.3850 - accuracy: 0.5094 - val_loss: 1.4190 - val_accuracy: 0.4888\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.3783 - accuracy: 0.5126 - val_loss: 1.4055 - val_accuracy: 0.5030\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.3711 - accuracy: 0.5144 - val_loss: 1.3890 - val_accuracy: 0.5092\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.3642 - accuracy: 0.5174 - val_loss: 1.3949 - val_accuracy: 0.5027\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.3606 - accuracy: 0.5192 - val_loss: 1.4093 - val_accuracy: 0.5008\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 1s - loss: 1.3547 - accuracy: 0.5202 - val_loss: 1.4019 - val_accuracy: 0.5081\n",
            "\n",
            "Epoch 39/100\n",
            "391/391 - 1s - loss: 1.3483 - accuracy: 0.5221 - val_loss: 1.4121 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 40/100\n",
            "391/391 - 1s - loss: 1.3431 - accuracy: 0.5246 - val_loss: 1.3951 - val_accuracy: 0.5029\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5091999769210815\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "128\n",
            "0.12243824892363993\n",
            "0.0771256867404211\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9915 - accuracy: 0.2753 - val_loss: 1.8287 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8089 - accuracy: 0.3523 - val_loss: 1.7081 - val_accuracy: 0.3907\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7477 - accuracy: 0.3756 - val_loss: 1.6711 - val_accuracy: 0.4092\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6983 - accuracy: 0.3941 - val_loss: 1.6257 - val_accuracy: 0.4225\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6662 - accuracy: 0.4088 - val_loss: 1.5696 - val_accuracy: 0.4494\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6392 - accuracy: 0.4165 - val_loss: 1.5686 - val_accuracy: 0.4431\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6134 - accuracy: 0.4278 - val_loss: 1.5618 - val_accuracy: 0.4526\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5977 - accuracy: 0.4324 - val_loss: 1.5288 - val_accuracy: 0.4616\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5848 - accuracy: 0.4390 - val_loss: 1.5364 - val_accuracy: 0.4633\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5685 - accuracy: 0.4433 - val_loss: 1.5128 - val_accuracy: 0.4647\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5540 - accuracy: 0.4494 - val_loss: 1.4861 - val_accuracy: 0.4781\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5449 - accuracy: 0.4528 - val_loss: 1.5087 - val_accuracy: 0.4644\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5320 - accuracy: 0.4569 - val_loss: 1.4725 - val_accuracy: 0.4841\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5296 - accuracy: 0.4590 - val_loss: 1.4929 - val_accuracy: 0.4727\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5152 - accuracy: 0.4601 - val_loss: 1.4932 - val_accuracy: 0.4737\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5030 - accuracy: 0.4640 - val_loss: 1.4614 - val_accuracy: 0.4874\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5000 - accuracy: 0.4675 - val_loss: 1.4653 - val_accuracy: 0.4864\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4999 - accuracy: 0.4706 - val_loss: 1.4544 - val_accuracy: 0.4872\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4922 - accuracy: 0.4740 - val_loss: 1.4548 - val_accuracy: 0.4852\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4813 - accuracy: 0.4738 - val_loss: 1.4614 - val_accuracy: 0.4804\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4768 - accuracy: 0.4767 - val_loss: 1.4499 - val_accuracy: 0.4868\n",
            "\n",
            "legjobb val_acc:\n",
            "0.48739999532699585\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.38393577539537305\n",
            "0.20031734608250726\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9948 - accuracy: 0.2772 - val_loss: 1.8236 - val_accuracy: 0.3428\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8464 - accuracy: 0.3396 - val_loss: 1.7207 - val_accuracy: 0.3912\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7790 - accuracy: 0.3647 - val_loss: 1.6937 - val_accuracy: 0.3973\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7273 - accuracy: 0.3858 - val_loss: 1.6138 - val_accuracy: 0.4356\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6967 - accuracy: 0.3959 - val_loss: 1.6092 - val_accuracy: 0.4295\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6721 - accuracy: 0.4057 - val_loss: 1.5780 - val_accuracy: 0.4406\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6479 - accuracy: 0.4141 - val_loss: 1.5381 - val_accuracy: 0.4547\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6244 - accuracy: 0.4226 - val_loss: 1.5356 - val_accuracy: 0.4564\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.6117 - accuracy: 0.4277 - val_loss: 1.5228 - val_accuracy: 0.4627\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5929 - accuracy: 0.4351 - val_loss: 1.5045 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5867 - accuracy: 0.4361 - val_loss: 1.4901 - val_accuracy: 0.4641\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5741 - accuracy: 0.4385 - val_loss: 1.4941 - val_accuracy: 0.4695\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5625 - accuracy: 0.4461 - val_loss: 1.4724 - val_accuracy: 0.4821\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5582 - accuracy: 0.4471 - val_loss: 1.4771 - val_accuracy: 0.4746\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5487 - accuracy: 0.4495 - val_loss: 1.4719 - val_accuracy: 0.4808\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5364 - accuracy: 0.4529 - val_loss: 1.4709 - val_accuracy: 0.4696\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5258 - accuracy: 0.4567 - val_loss: 1.4573 - val_accuracy: 0.4793\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5190 - accuracy: 0.4592 - val_loss: 1.4688 - val_accuracy: 0.4801\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4821000099182129\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "512\n",
            "0.10523082704333389\n",
            "0.26473066908594595\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 3.1529 - accuracy: 0.1818 - val_loss: 3.1910 - val_accuracy: 0.1530\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.3023 - accuracy: 0.2289 - val_loss: 2.2443 - val_accuracy: 0.2386\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 2.1326 - accuracy: 0.2640 - val_loss: 2.1852 - val_accuracy: 0.3061\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 2.0189 - accuracy: 0.2904 - val_loss: 1.9736 - val_accuracy: 0.3040\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.9318 - accuracy: 0.3151 - val_loss: 2.0205 - val_accuracy: 0.2687\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8606 - accuracy: 0.3367 - val_loss: 2.0104 - val_accuracy: 0.3073\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8202 - accuracy: 0.3549 - val_loss: 1.9340 - val_accuracy: 0.2940\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7830 - accuracy: 0.3699 - val_loss: 1.6829 - val_accuracy: 0.3857\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7555 - accuracy: 0.3785 - val_loss: 1.8824 - val_accuracy: 0.3348\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7275 - accuracy: 0.3889 - val_loss: 1.8607 - val_accuracy: 0.3519\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7123 - accuracy: 0.3930 - val_loss: 1.7178 - val_accuracy: 0.4004\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.6860 - accuracy: 0.4011 - val_loss: 1.8004 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6850 - accuracy: 0.4075 - val_loss: 1.8397 - val_accuracy: 0.3634\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6657 - accuracy: 0.4106 - val_loss: 1.6718 - val_accuracy: 0.3820\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6460 - accuracy: 0.4200 - val_loss: 1.5399 - val_accuracy: 0.4535\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6272 - accuracy: 0.4232 - val_loss: 1.6434 - val_accuracy: 0.4231\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6180 - accuracy: 0.4277 - val_loss: 1.6712 - val_accuracy: 0.4040\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6013 - accuracy: 0.4325 - val_loss: 1.6598 - val_accuracy: 0.4125\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6005 - accuracy: 0.4346 - val_loss: 2.3476 - val_accuracy: 0.3111\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.5828 - accuracy: 0.4386 - val_loss: 1.5651 - val_accuracy: 0.4247\n",
            "\n",
            "legjobb val_acc:\n",
            "0.45350000262260437\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "64\n",
            "0.34408226133712616\n",
            "0.349432723570679\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 2.1839 - accuracy: 0.1593 - val_loss: 2.1097 - val_accuracy: 0.1953\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 2.1221 - accuracy: 0.1713 - val_loss: 2.0489 - val_accuracy: 0.2238\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 2.1087 - accuracy: 0.1829 - val_loss: 2.0150 - val_accuracy: 0.2421\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 2.1006 - accuracy: 0.1905 - val_loss: 2.0182 - val_accuracy: 0.2487\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 2.0892 - accuracy: 0.2023 - val_loss: 2.0279 - val_accuracy: 0.2501\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 2.0788 - accuracy: 0.2109 - val_loss: 2.0036 - val_accuracy: 0.2599\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 2.0754 - accuracy: 0.2164 - val_loss: 2.0397 - val_accuracy: 0.2367\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 2.0716 - accuracy: 0.2151 - val_loss: 2.0352 - val_accuracy: 0.2413\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 2.0624 - accuracy: 0.2171 - val_loss: 2.0381 - val_accuracy: 0.2378\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 2.0641 - accuracy: 0.2194 - val_loss: 2.0291 - val_accuracy: 0.2556\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 2.0614 - accuracy: 0.2218 - val_loss: 2.0189 - val_accuracy: 0.2502\n",
            "\n",
            "legjobb val_acc:\n",
            "0.2599000036716461\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "32\n",
            "0.2358957634910323\n",
            "0.005523273734433065\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0840 - accuracy: 0.2606 - val_loss: 1.8689 - val_accuracy: 0.3362\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8439 - accuracy: 0.3430 - val_loss: 1.8077 - val_accuracy: 0.3412\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7811 - accuracy: 0.3727 - val_loss: 1.7388 - val_accuracy: 0.3769\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7312 - accuracy: 0.3894 - val_loss: 1.6677 - val_accuracy: 0.4105\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6955 - accuracy: 0.4020 - val_loss: 1.6633 - val_accuracy: 0.4125\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6599 - accuracy: 0.4135 - val_loss: 1.6167 - val_accuracy: 0.4311\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6381 - accuracy: 0.4204 - val_loss: 1.6085 - val_accuracy: 0.4336\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6054 - accuracy: 0.4334 - val_loss: 1.5587 - val_accuracy: 0.4496\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5879 - accuracy: 0.4406 - val_loss: 1.5342 - val_accuracy: 0.4559\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5719 - accuracy: 0.4442 - val_loss: 1.5487 - val_accuracy: 0.4510\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5515 - accuracy: 0.4529 - val_loss: 1.5720 - val_accuracy: 0.4527\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5413 - accuracy: 0.4549 - val_loss: 1.5200 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5217 - accuracy: 0.4626 - val_loss: 1.4968 - val_accuracy: 0.4692\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5085 - accuracy: 0.4663 - val_loss: 1.4816 - val_accuracy: 0.4715\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5024 - accuracy: 0.4707 - val_loss: 1.4791 - val_accuracy: 0.4732\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4853 - accuracy: 0.4730 - val_loss: 1.5304 - val_accuracy: 0.4651\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4774 - accuracy: 0.4801 - val_loss: 1.4517 - val_accuracy: 0.4824\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4643 - accuracy: 0.4823 - val_loss: 1.4353 - val_accuracy: 0.4920\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4527 - accuracy: 0.4851 - val_loss: 1.4512 - val_accuracy: 0.4843\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4387 - accuracy: 0.4907 - val_loss: 1.4579 - val_accuracy: 0.4889\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4289 - accuracy: 0.4932 - val_loss: 1.4470 - val_accuracy: 0.4896\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.4187 - accuracy: 0.4977 - val_loss: 1.4624 - val_accuracy: 0.4899\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.4115 - accuracy: 0.5000 - val_loss: 1.4289 - val_accuracy: 0.4901\n",
            "\n",
            "legjobb val_acc:\n",
            "0.492000013589859\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.13749775934244454\n",
            "0.12584411267291346\n",
            "leakyrelu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 2.0813 - accuracy: 0.2465 - val_loss: 1.9292 - val_accuracy: 0.3228\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.9030 - accuracy: 0.3216 - val_loss: 1.8542 - val_accuracy: 0.3408\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8412 - accuracy: 0.3500 - val_loss: 1.7954 - val_accuracy: 0.3688\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7965 - accuracy: 0.3675 - val_loss: 1.7649 - val_accuracy: 0.3708\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7648 - accuracy: 0.3750 - val_loss: 1.7517 - val_accuracy: 0.3887\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7376 - accuracy: 0.3899 - val_loss: 1.7019 - val_accuracy: 0.4038\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.7131 - accuracy: 0.3976 - val_loss: 1.6858 - val_accuracy: 0.4096\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.6938 - accuracy: 0.4045 - val_loss: 1.6591 - val_accuracy: 0.4177\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.6748 - accuracy: 0.4109 - val_loss: 1.6465 - val_accuracy: 0.4229\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6604 - accuracy: 0.4152 - val_loss: 1.6676 - val_accuracy: 0.4116\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6452 - accuracy: 0.4217 - val_loss: 1.6312 - val_accuracy: 0.4285\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.6301 - accuracy: 0.4278 - val_loss: 1.5938 - val_accuracy: 0.4410\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.6199 - accuracy: 0.4313 - val_loss: 1.6147 - val_accuracy: 0.4306\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.6068 - accuracy: 0.4377 - val_loss: 1.5869 - val_accuracy: 0.4477\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.5958 - accuracy: 0.4411 - val_loss: 1.5625 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.5875 - accuracy: 0.4411 - val_loss: 1.5539 - val_accuracy: 0.4514\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.5746 - accuracy: 0.4492 - val_loss: 1.5681 - val_accuracy: 0.4405\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.5672 - accuracy: 0.4498 - val_loss: 1.5406 - val_accuracy: 0.4598\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.5592 - accuracy: 0.4534 - val_loss: 1.5434 - val_accuracy: 0.4581\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.5508 - accuracy: 0.4560 - val_loss: 1.5236 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.5456 - accuracy: 0.4571 - val_loss: 1.5186 - val_accuracy: 0.4684\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.5359 - accuracy: 0.4607 - val_loss: 1.5161 - val_accuracy: 0.4723\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.5284 - accuracy: 0.4648 - val_loss: 1.5555 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.5252 - accuracy: 0.4638 - val_loss: 1.5050 - val_accuracy: 0.4737\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.5189 - accuracy: 0.4681 - val_loss: 1.5775 - val_accuracy: 0.4427\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.5093 - accuracy: 0.4696 - val_loss: 1.5018 - val_accuracy: 0.4706\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.5012 - accuracy: 0.4729 - val_loss: 1.4942 - val_accuracy: 0.4745\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.4968 - accuracy: 0.4742 - val_loss: 1.4683 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.4922 - accuracy: 0.4771 - val_loss: 1.5430 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.4883 - accuracy: 0.4770 - val_loss: 1.4794 - val_accuracy: 0.4849\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.4809 - accuracy: 0.4810 - val_loss: 1.4966 - val_accuracy: 0.4714\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.4758 - accuracy: 0.4807 - val_loss: 1.4649 - val_accuracy: 0.4878\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.4679 - accuracy: 0.4835 - val_loss: 1.4959 - val_accuracy: 0.4708\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.4658 - accuracy: 0.4848 - val_loss: 1.4616 - val_accuracy: 0.4779\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.4609 - accuracy: 0.4861 - val_loss: 1.4911 - val_accuracy: 0.4753\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.4575 - accuracy: 0.4914 - val_loss: 1.5156 - val_accuracy: 0.4510\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.4520 - accuracy: 0.4907 - val_loss: 1.5197 - val_accuracy: 0.4649\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4878000020980835\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "512\n",
            "0.1803466519271961\n",
            "0.3221272812364264\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9439 - accuracy: 0.2957 - val_loss: 1.7508 - val_accuracy: 0.3748\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7864 - accuracy: 0.3621 - val_loss: 1.6831 - val_accuracy: 0.4039\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7209 - accuracy: 0.3886 - val_loss: 1.6253 - val_accuracy: 0.4297\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6704 - accuracy: 0.4052 - val_loss: 1.5697 - val_accuracy: 0.4463\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6427 - accuracy: 0.4187 - val_loss: 1.5624 - val_accuracy: 0.4497\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6152 - accuracy: 0.4277 - val_loss: 1.5532 - val_accuracy: 0.4468\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6039 - accuracy: 0.4318 - val_loss: 1.5227 - val_accuracy: 0.4551\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5742 - accuracy: 0.4432 - val_loss: 1.5140 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5596 - accuracy: 0.4485 - val_loss: 1.4994 - val_accuracy: 0.4661\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5510 - accuracy: 0.4498 - val_loss: 1.4866 - val_accuracy: 0.4737\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5370 - accuracy: 0.4512 - val_loss: 1.4820 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5216 - accuracy: 0.4610 - val_loss: 1.4657 - val_accuracy: 0.4791\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5160 - accuracy: 0.4615 - val_loss: 1.4677 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5022 - accuracy: 0.4658 - val_loss: 1.4361 - val_accuracy: 0.4948\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4987 - accuracy: 0.4683 - val_loss: 1.4872 - val_accuracy: 0.4722\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4879 - accuracy: 0.4705 - val_loss: 1.5064 - val_accuracy: 0.4598\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4760 - accuracy: 0.4786 - val_loss: 1.4459 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4778 - accuracy: 0.4708 - val_loss: 1.4186 - val_accuracy: 0.4941\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4656 - accuracy: 0.4770 - val_loss: 1.4201 - val_accuracy: 0.4906\n",
            "\n",
            "legjobb val_acc:\n",
            "0.49480000138282776\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "128\n",
            "0.061238742283512046\n",
            "0.4493906464050008\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0373 - accuracy: 0.2667 - val_loss: 1.8551 - val_accuracy: 0.3374\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8553 - accuracy: 0.3380 - val_loss: 1.7820 - val_accuracy: 0.3631\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7876 - accuracy: 0.3641 - val_loss: 1.7465 - val_accuracy: 0.3774\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7493 - accuracy: 0.3790 - val_loss: 1.6728 - val_accuracy: 0.4088\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6930 - accuracy: 0.4019 - val_loss: 1.6320 - val_accuracy: 0.4244\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6618 - accuracy: 0.4138 - val_loss: 1.6291 - val_accuracy: 0.4229\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6419 - accuracy: 0.4182 - val_loss: 1.6240 - val_accuracy: 0.4244\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6115 - accuracy: 0.4280 - val_loss: 1.5529 - val_accuracy: 0.4509\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5934 - accuracy: 0.4383 - val_loss: 1.5653 - val_accuracy: 0.4336\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5919 - accuracy: 0.4334 - val_loss: 1.5830 - val_accuracy: 0.4381\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5653 - accuracy: 0.4465 - val_loss: 1.5368 - val_accuracy: 0.4552\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5530 - accuracy: 0.4501 - val_loss: 1.5242 - val_accuracy: 0.4590\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5370 - accuracy: 0.4571 - val_loss: 1.4852 - val_accuracy: 0.4779\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5277 - accuracy: 0.4601 - val_loss: 1.5207 - val_accuracy: 0.4639\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5284 - accuracy: 0.4594 - val_loss: 1.4898 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5130 - accuracy: 0.4649 - val_loss: 1.4991 - val_accuracy: 0.4638\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5009 - accuracy: 0.4699 - val_loss: 1.4644 - val_accuracy: 0.4707\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5043 - accuracy: 0.4665 - val_loss: 1.4957 - val_accuracy: 0.4656\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4778999984264374\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "512\n",
            "0.08165444249943302\n",
            "0.23324392853552708\n",
            "relu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1153 - accuracy: 0.2054 - val_loss: 1.9540 - val_accuracy: 0.2856\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9683 - accuracy: 0.2802 - val_loss: 2.0035 - val_accuracy: 0.2758\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9188 - accuracy: 0.2973 - val_loss: 1.8383 - val_accuracy: 0.3227\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8753 - accuracy: 0.3135 - val_loss: 1.8858 - val_accuracy: 0.3007\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8558 - accuracy: 0.3234 - val_loss: 1.8548 - val_accuracy: 0.3310\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8369 - accuracy: 0.3327 - val_loss: 1.7981 - val_accuracy: 0.3403\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8199 - accuracy: 0.3411 - val_loss: 1.9136 - val_accuracy: 0.2954\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.8053 - accuracy: 0.3453 - val_loss: 1.8018 - val_accuracy: 0.3462\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7980 - accuracy: 0.3489 - val_loss: 1.7498 - val_accuracy: 0.3717\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7866 - accuracy: 0.3516 - val_loss: 1.7118 - val_accuracy: 0.3841\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7806 - accuracy: 0.3536 - val_loss: 1.7758 - val_accuracy: 0.3519\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7726 - accuracy: 0.3567 - val_loss: 1.6901 - val_accuracy: 0.3939\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7701 - accuracy: 0.3579 - val_loss: 1.7214 - val_accuracy: 0.3767\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.7592 - accuracy: 0.3627 - val_loss: 1.7110 - val_accuracy: 0.3861\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.7560 - accuracy: 0.3631 - val_loss: 1.7900 - val_accuracy: 0.3244\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.7515 - accuracy: 0.3643 - val_loss: 1.7823 - val_accuracy: 0.3610\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.7493 - accuracy: 0.3694 - val_loss: 1.6970 - val_accuracy: 0.3769\n",
            "\n",
            "legjobb val_acc:\n",
            "0.3939000070095062\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "64\n",
            "0.2170494250749766\n",
            "0.013100248407245224\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 1.9648 - accuracy: 0.2964 - val_loss: 1.7789 - val_accuracy: 0.3699\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.7938 - accuracy: 0.3547 - val_loss: 1.7230 - val_accuracy: 0.3827\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.7253 - accuracy: 0.3889 - val_loss: 1.6388 - val_accuracy: 0.4146\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.6803 - accuracy: 0.4000 - val_loss: 1.6150 - val_accuracy: 0.4281\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.6479 - accuracy: 0.4132 - val_loss: 1.5874 - val_accuracy: 0.4305\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.6096 - accuracy: 0.4272 - val_loss: 1.5881 - val_accuracy: 0.4381\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.5916 - accuracy: 0.4302 - val_loss: 1.5597 - val_accuracy: 0.4471\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.5628 - accuracy: 0.4432 - val_loss: 1.5247 - val_accuracy: 0.4581\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.5463 - accuracy: 0.4506 - val_loss: 1.4971 - val_accuracy: 0.4641\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.5273 - accuracy: 0.4570 - val_loss: 1.5223 - val_accuracy: 0.4563\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.5107 - accuracy: 0.4626 - val_loss: 1.5316 - val_accuracy: 0.4511\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.5017 - accuracy: 0.4658 - val_loss: 1.4742 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.4826 - accuracy: 0.4701 - val_loss: 1.4956 - val_accuracy: 0.4710\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.4749 - accuracy: 0.4746 - val_loss: 1.4751 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.4612 - accuracy: 0.4803 - val_loss: 1.4583 - val_accuracy: 0.4842\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.4525 - accuracy: 0.4833 - val_loss: 1.4420 - val_accuracy: 0.4909\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.4385 - accuracy: 0.4873 - val_loss: 1.4351 - val_accuracy: 0.4886\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.4306 - accuracy: 0.4883 - val_loss: 1.4176 - val_accuracy: 0.4900\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.4250 - accuracy: 0.4925 - val_loss: 1.4208 - val_accuracy: 0.4918\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.4112 - accuracy: 0.4967 - val_loss: 1.4704 - val_accuracy: 0.4793\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 2s - loss: 1.4061 - accuracy: 0.5002 - val_loss: 1.4261 - val_accuracy: 0.4936\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.3976 - accuracy: 0.4994 - val_loss: 1.4205 - val_accuracy: 0.4900\n",
            "\n",
            "Epoch 23/100\n",
            "782/782 - 2s - loss: 1.3875 - accuracy: 0.5050 - val_loss: 1.3971 - val_accuracy: 0.5003\n",
            "\n",
            "Epoch 24/100\n",
            "782/782 - 2s - loss: 1.3868 - accuracy: 0.5072 - val_loss: 1.4189 - val_accuracy: 0.4949\n",
            "\n",
            "Epoch 25/100\n",
            "782/782 - 2s - loss: 1.3775 - accuracy: 0.5066 - val_loss: 1.3729 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 26/100\n",
            "782/782 - 2s - loss: 1.3717 - accuracy: 0.5104 - val_loss: 1.3781 - val_accuracy: 0.5146\n",
            "\n",
            "Epoch 27/100\n",
            "782/782 - 2s - loss: 1.3674 - accuracy: 0.5131 - val_loss: 1.3909 - val_accuracy: 0.5086\n",
            "\n",
            "Epoch 28/100\n",
            "782/782 - 2s - loss: 1.3555 - accuracy: 0.5191 - val_loss: 1.3639 - val_accuracy: 0.5113\n",
            "\n",
            "Epoch 29/100\n",
            "782/782 - 2s - loss: 1.3514 - accuracy: 0.5192 - val_loss: 1.3922 - val_accuracy: 0.5022\n",
            "\n",
            "Epoch 30/100\n",
            "782/782 - 2s - loss: 1.3520 - accuracy: 0.5179 - val_loss: 1.3761 - val_accuracy: 0.5129\n",
            "\n",
            "Epoch 31/100\n",
            "782/782 - 2s - loss: 1.3481 - accuracy: 0.5209 - val_loss: 1.3763 - val_accuracy: 0.5066\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5145999789237976\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "32\n",
            "0.19328551127968233\n",
            "0.07348695662347163\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.2483 - accuracy: 0.2454 - val_loss: 1.8847 - val_accuracy: 0.3153\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8680 - accuracy: 0.3356 - val_loss: 1.7734 - val_accuracy: 0.3816\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7922 - accuracy: 0.3641 - val_loss: 1.7483 - val_accuracy: 0.3936\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7426 - accuracy: 0.3843 - val_loss: 1.6902 - val_accuracy: 0.4042\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6955 - accuracy: 0.3988 - val_loss: 1.6675 - val_accuracy: 0.4062\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6744 - accuracy: 0.4068 - val_loss: 1.5952 - val_accuracy: 0.4380\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6423 - accuracy: 0.4204 - val_loss: 1.5927 - val_accuracy: 0.4420\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6248 - accuracy: 0.4247 - val_loss: 1.5487 - val_accuracy: 0.4508\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5986 - accuracy: 0.4328 - val_loss: 1.5373 - val_accuracy: 0.4550\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5734 - accuracy: 0.4403 - val_loss: 1.5203 - val_accuracy: 0.4622\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5579 - accuracy: 0.4470 - val_loss: 1.5819 - val_accuracy: 0.4407\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5581 - accuracy: 0.4478 - val_loss: 1.4983 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5342 - accuracy: 0.4566 - val_loss: 1.4741 - val_accuracy: 0.4830\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5191 - accuracy: 0.4617 - val_loss: 1.4973 - val_accuracy: 0.4680\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5083 - accuracy: 0.4643 - val_loss: 1.4736 - val_accuracy: 0.4818\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4897 - accuracy: 0.4719 - val_loss: 1.5282 - val_accuracy: 0.4635\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4743 - accuracy: 0.4767 - val_loss: 1.4594 - val_accuracy: 0.4752\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4772 - accuracy: 0.4742 - val_loss: 1.4745 - val_accuracy: 0.4809\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4830000102519989\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.11525101614625305\n",
            "0.05756649865353293\n",
            "leakyrelu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 2.0747 - accuracy: 0.2481 - val_loss: 1.9337 - val_accuracy: 0.3193\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.9005 - accuracy: 0.3249 - val_loss: 1.8495 - val_accuracy: 0.3482\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8339 - accuracy: 0.3530 - val_loss: 1.8191 - val_accuracy: 0.3573\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7921 - accuracy: 0.3675 - val_loss: 1.7448 - val_accuracy: 0.3922\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7600 - accuracy: 0.3809 - val_loss: 1.7259 - val_accuracy: 0.3936\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7337 - accuracy: 0.3882 - val_loss: 1.6942 - val_accuracy: 0.4088\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.7089 - accuracy: 0.3995 - val_loss: 1.6932 - val_accuracy: 0.4057\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.6901 - accuracy: 0.4048 - val_loss: 1.6807 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.6742 - accuracy: 0.4120 - val_loss: 1.6358 - val_accuracy: 0.4297\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6554 - accuracy: 0.4190 - val_loss: 1.6281 - val_accuracy: 0.4344\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6405 - accuracy: 0.4237 - val_loss: 1.6236 - val_accuracy: 0.4324\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.6268 - accuracy: 0.4284 - val_loss: 1.5885 - val_accuracy: 0.4410\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.6134 - accuracy: 0.4339 - val_loss: 1.5860 - val_accuracy: 0.4417\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.6019 - accuracy: 0.4370 - val_loss: 1.5894 - val_accuracy: 0.4404\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.5922 - accuracy: 0.4410 - val_loss: 1.5684 - val_accuracy: 0.4536\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.5802 - accuracy: 0.4458 - val_loss: 1.5817 - val_accuracy: 0.4386\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.5699 - accuracy: 0.4509 - val_loss: 1.6145 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.5605 - accuracy: 0.4545 - val_loss: 1.5472 - val_accuracy: 0.4538\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.5505 - accuracy: 0.4581 - val_loss: 1.5398 - val_accuracy: 0.4539\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.5427 - accuracy: 0.4566 - val_loss: 1.5300 - val_accuracy: 0.4630\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.5344 - accuracy: 0.4609 - val_loss: 1.5569 - val_accuracy: 0.4460\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.5281 - accuracy: 0.4630 - val_loss: 1.5404 - val_accuracy: 0.4610\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.5188 - accuracy: 0.4676 - val_loss: 1.5407 - val_accuracy: 0.4573\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.5133 - accuracy: 0.4716 - val_loss: 1.5238 - val_accuracy: 0.4628\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.5057 - accuracy: 0.4727 - val_loss: 1.4939 - val_accuracy: 0.4723\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.4993 - accuracy: 0.4730 - val_loss: 1.4937 - val_accuracy: 0.4693\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.4890 - accuracy: 0.4801 - val_loss: 1.4790 - val_accuracy: 0.4810\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.4885 - accuracy: 0.4785 - val_loss: 1.5255 - val_accuracy: 0.4683\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.4793 - accuracy: 0.4793 - val_loss: 1.5487 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.4732 - accuracy: 0.4848 - val_loss: 1.4823 - val_accuracy: 0.4775\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.4674 - accuracy: 0.4845 - val_loss: 1.4619 - val_accuracy: 0.4837\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.4627 - accuracy: 0.4858 - val_loss: 1.4702 - val_accuracy: 0.4803\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.4594 - accuracy: 0.4879 - val_loss: 1.4685 - val_accuracy: 0.4816\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.4535 - accuracy: 0.4897 - val_loss: 1.4613 - val_accuracy: 0.4813\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.4463 - accuracy: 0.4930 - val_loss: 1.4442 - val_accuracy: 0.4904\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.4421 - accuracy: 0.4942 - val_loss: 1.4441 - val_accuracy: 0.4895\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.4381 - accuracy: 0.4959 - val_loss: 1.4595 - val_accuracy: 0.4852\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 1s - loss: 1.4299 - accuracy: 0.4989 - val_loss: 1.4318 - val_accuracy: 0.4964\n",
            "\n",
            "Epoch 39/100\n",
            "391/391 - 1s - loss: 1.4279 - accuracy: 0.5004 - val_loss: 1.4495 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 40/100\n",
            "391/391 - 1s - loss: 1.4263 - accuracy: 0.4982 - val_loss: 1.4279 - val_accuracy: 0.5022\n",
            "\n",
            "Epoch 41/100\n",
            "391/391 - 1s - loss: 1.4168 - accuracy: 0.5038 - val_loss: 1.4285 - val_accuracy: 0.5002\n",
            "\n",
            "Epoch 42/100\n",
            "391/391 - 1s - loss: 1.4186 - accuracy: 0.5034 - val_loss: 1.4640 - val_accuracy: 0.4871\n",
            "\n",
            "Epoch 43/100\n",
            "391/391 - 1s - loss: 1.4080 - accuracy: 0.5043 - val_loss: 1.4378 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 44/100\n",
            "391/391 - 1s - loss: 1.4042 - accuracy: 0.5068 - val_loss: 1.4942 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 45/100\n",
            "391/391 - 1s - loss: 1.3976 - accuracy: 0.5094 - val_loss: 1.4205 - val_accuracy: 0.5026\n",
            "\n",
            "Epoch 46/100\n",
            "391/391 - 1s - loss: 1.3966 - accuracy: 0.5101 - val_loss: 1.4288 - val_accuracy: 0.4978\n",
            "\n",
            "Epoch 47/100\n",
            "391/391 - 1s - loss: 1.3904 - accuracy: 0.5129 - val_loss: 1.4161 - val_accuracy: 0.5048\n",
            "\n",
            "Epoch 48/100\n",
            "391/391 - 1s - loss: 1.3896 - accuracy: 0.5108 - val_loss: 1.4174 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 49/100\n",
            "391/391 - 1s - loss: 1.3854 - accuracy: 0.5123 - val_loss: 1.4238 - val_accuracy: 0.5020\n",
            "\n",
            "Epoch 50/100\n",
            "391/391 - 1s - loss: 1.3808 - accuracy: 0.5160 - val_loss: 1.4675 - val_accuracy: 0.4795\n",
            "\n",
            "Epoch 51/100\n",
            "391/391 - 1s - loss: 1.3773 - accuracy: 0.5167 - val_loss: 1.4024 - val_accuracy: 0.5076\n",
            "\n",
            "Epoch 52/100\n",
            "391/391 - 1s - loss: 1.3766 - accuracy: 0.5187 - val_loss: 1.3948 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 53/100\n",
            "391/391 - 1s - loss: 1.3709 - accuracy: 0.5189 - val_loss: 1.4166 - val_accuracy: 0.5012\n",
            "\n",
            "Epoch 54/100\n",
            "391/391 - 1s - loss: 1.3640 - accuracy: 0.5229 - val_loss: 1.4528 - val_accuracy: 0.4918\n",
            "\n",
            "Epoch 55/100\n",
            "391/391 - 1s - loss: 1.3679 - accuracy: 0.5209 - val_loss: 1.4290 - val_accuracy: 0.4896\n",
            "\n",
            "Epoch 56/100\n",
            "391/391 - 1s - loss: 1.3610 - accuracy: 0.5225 - val_loss: 1.4245 - val_accuracy: 0.4967\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5076000094413757\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "512\n",
            "0.005314805498475489\n",
            "0.4844789023910697\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0045 - accuracy: 0.2887 - val_loss: 1.8296 - val_accuracy: 0.3372\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7857 - accuracy: 0.3641 - val_loss: 1.7277 - val_accuracy: 0.3866\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7209 - accuracy: 0.3914 - val_loss: 1.6167 - val_accuracy: 0.4411\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6532 - accuracy: 0.4125 - val_loss: 1.6016 - val_accuracy: 0.4382\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6104 - accuracy: 0.4280 - val_loss: 1.5590 - val_accuracy: 0.4396\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5761 - accuracy: 0.4400 - val_loss: 1.5791 - val_accuracy: 0.4361\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5484 - accuracy: 0.4502 - val_loss: 1.5090 - val_accuracy: 0.4625\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5313 - accuracy: 0.4552 - val_loss: 1.4882 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5068 - accuracy: 0.4668 - val_loss: 1.5547 - val_accuracy: 0.4493\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.4858 - accuracy: 0.4742 - val_loss: 1.4828 - val_accuracy: 0.4665\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4569 - accuracy: 0.4833 - val_loss: 1.4857 - val_accuracy: 0.4770\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4598 - accuracy: 0.4836 - val_loss: 1.5786 - val_accuracy: 0.4293\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4395 - accuracy: 0.4896 - val_loss: 1.4158 - val_accuracy: 0.4925\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4168 - accuracy: 0.4976 - val_loss: 1.4221 - val_accuracy: 0.4924\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4155 - accuracy: 0.4983 - val_loss: 1.3981 - val_accuracy: 0.5080\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4018 - accuracy: 0.5047 - val_loss: 1.3996 - val_accuracy: 0.5011\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.3903 - accuracy: 0.5065 - val_loss: 1.4305 - val_accuracy: 0.4891\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.3789 - accuracy: 0.5105 - val_loss: 1.4289 - val_accuracy: 0.4904\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.3679 - accuracy: 0.5151 - val_loss: 1.3976 - val_accuracy: 0.5003\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.3556 - accuracy: 0.5169 - val_loss: 1.4660 - val_accuracy: 0.4764\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5080000162124634\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.2764558431824834\n",
            "0.1046841681352493\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9626 - accuracy: 0.2908 - val_loss: 1.8352 - val_accuracy: 0.3370\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7898 - accuracy: 0.3581 - val_loss: 1.6701 - val_accuracy: 0.4048\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7259 - accuracy: 0.3871 - val_loss: 1.6630 - val_accuracy: 0.4037\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6732 - accuracy: 0.4047 - val_loss: 1.5779 - val_accuracy: 0.4389\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6328 - accuracy: 0.4205 - val_loss: 1.5492 - val_accuracy: 0.4522\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6086 - accuracy: 0.4272 - val_loss: 1.5519 - val_accuracy: 0.4464\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5866 - accuracy: 0.4373 - val_loss: 1.5375 - val_accuracy: 0.4529\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5574 - accuracy: 0.4461 - val_loss: 1.5022 - val_accuracy: 0.4718\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5435 - accuracy: 0.4512 - val_loss: 1.4666 - val_accuracy: 0.4835\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5232 - accuracy: 0.4556 - val_loss: 1.4494 - val_accuracy: 0.4949\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5132 - accuracy: 0.4626 - val_loss: 1.4977 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5034 - accuracy: 0.4645 - val_loss: 1.4776 - val_accuracy: 0.4731\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4777 - accuracy: 0.4750 - val_loss: 1.4245 - val_accuracy: 0.4958\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4773 - accuracy: 0.4765 - val_loss: 1.4357 - val_accuracy: 0.4861\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4646 - accuracy: 0.4803 - val_loss: 1.4163 - val_accuracy: 0.4931\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4475 - accuracy: 0.4869 - val_loss: 1.4278 - val_accuracy: 0.4960\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4402 - accuracy: 0.4873 - val_loss: 1.4086 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4281 - accuracy: 0.4925 - val_loss: 1.4196 - val_accuracy: 0.4957\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4274 - accuracy: 0.4904 - val_loss: 1.3798 - val_accuracy: 0.5199\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4132 - accuracy: 0.4961 - val_loss: 1.3788 - val_accuracy: 0.5114\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4054 - accuracy: 0.5038 - val_loss: 1.3949 - val_accuracy: 0.5003\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.3972 - accuracy: 0.5026 - val_loss: 1.3595 - val_accuracy: 0.5215\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.3829 - accuracy: 0.5077 - val_loss: 1.3927 - val_accuracy: 0.4964\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.3815 - accuracy: 0.5082 - val_loss: 1.3542 - val_accuracy: 0.5194\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.3764 - accuracy: 0.5109 - val_loss: 1.3774 - val_accuracy: 0.5061\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.3653 - accuracy: 0.5153 - val_loss: 1.3831 - val_accuracy: 0.5052\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.3579 - accuracy: 0.5179 - val_loss: 1.3517 - val_accuracy: 0.5203\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5214999914169312\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "128\n",
            "0.2588394914536556\n",
            "0.02579786304313327\n",
            "relu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1340 - accuracy: 0.2024 - val_loss: 1.9638 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9705 - accuracy: 0.2705 - val_loss: 1.8777 - val_accuracy: 0.3084\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9211 - accuracy: 0.2939 - val_loss: 1.8419 - val_accuracy: 0.3219\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8901 - accuracy: 0.3075 - val_loss: 1.8089 - val_accuracy: 0.3502\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8707 - accuracy: 0.3118 - val_loss: 1.8786 - val_accuracy: 0.3054\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8535 - accuracy: 0.3209 - val_loss: 1.9095 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8430 - accuracy: 0.3248 - val_loss: 1.8136 - val_accuracy: 0.3451\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.8289 - accuracy: 0.3311 - val_loss: 1.7792 - val_accuracy: 0.3452\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.8175 - accuracy: 0.3365 - val_loss: 1.7289 - val_accuracy: 0.3987\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.8095 - accuracy: 0.3411 - val_loss: 1.7399 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.8006 - accuracy: 0.3444 - val_loss: 1.7722 - val_accuracy: 0.3744\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7966 - accuracy: 0.3455 - val_loss: 1.7774 - val_accuracy: 0.3666\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7868 - accuracy: 0.3493 - val_loss: 1.7135 - val_accuracy: 0.3858\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.7840 - accuracy: 0.3513 - val_loss: 1.7550 - val_accuracy: 0.3728\n",
            "\n",
            "legjobb val_acc:\n",
            "0.3986999988555908\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.16134500618404157\n",
            "0.16557869378564172\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 1.9398 - accuracy: 0.3013 - val_loss: 1.8024 - val_accuracy: 0.3690\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.7816 - accuracy: 0.3651 - val_loss: 1.7166 - val_accuracy: 0.3757\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.7077 - accuracy: 0.3909 - val_loss: 1.5863 - val_accuracy: 0.4338\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.6554 - accuracy: 0.4122 - val_loss: 1.5661 - val_accuracy: 0.4408\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.6242 - accuracy: 0.4212 - val_loss: 1.5634 - val_accuracy: 0.4419\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.5985 - accuracy: 0.4312 - val_loss: 1.5068 - val_accuracy: 0.4632\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.5765 - accuracy: 0.4389 - val_loss: 1.5203 - val_accuracy: 0.4607\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.5642 - accuracy: 0.4448 - val_loss: 1.5584 - val_accuracy: 0.4424\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.5464 - accuracy: 0.4490 - val_loss: 1.5078 - val_accuracy: 0.4603\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.5263 - accuracy: 0.4562 - val_loss: 1.4868 - val_accuracy: 0.4726\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.5152 - accuracy: 0.4640 - val_loss: 1.4848 - val_accuracy: 0.4664\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.5023 - accuracy: 0.4664 - val_loss: 1.4995 - val_accuracy: 0.4680\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.4872 - accuracy: 0.4725 - val_loss: 1.4678 - val_accuracy: 0.4719\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.4802 - accuracy: 0.4719 - val_loss: 1.4423 - val_accuracy: 0.4941\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.4627 - accuracy: 0.4779 - val_loss: 1.4247 - val_accuracy: 0.4942\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.4529 - accuracy: 0.4860 - val_loss: 1.4489 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.4468 - accuracy: 0.4852 - val_loss: 1.4272 - val_accuracy: 0.4934\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.4347 - accuracy: 0.4887 - val_loss: 1.4255 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.4299 - accuracy: 0.4875 - val_loss: 1.4521 - val_accuracy: 0.4806\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.4225 - accuracy: 0.4950 - val_loss: 1.4686 - val_accuracy: 0.4768\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4941999912261963\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "64\n",
            "0.09626140311511588\n",
            "0.044052625369803367\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9906 - accuracy: 0.2771 - val_loss: 1.8422 - val_accuracy: 0.3360\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8007 - accuracy: 0.3566 - val_loss: 1.7245 - val_accuracy: 0.3881\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7412 - accuracy: 0.3814 - val_loss: 1.6891 - val_accuracy: 0.4027\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6974 - accuracy: 0.3964 - val_loss: 1.6529 - val_accuracy: 0.4114\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6616 - accuracy: 0.4086 - val_loss: 1.5971 - val_accuracy: 0.4399\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6434 - accuracy: 0.4188 - val_loss: 1.5770 - val_accuracy: 0.4386\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6125 - accuracy: 0.4282 - val_loss: 1.5642 - val_accuracy: 0.4471\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5976 - accuracy: 0.4339 - val_loss: 1.5304 - val_accuracy: 0.4651\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5826 - accuracy: 0.4374 - val_loss: 1.5274 - val_accuracy: 0.4612\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5776 - accuracy: 0.4390 - val_loss: 1.5330 - val_accuracy: 0.4594\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5557 - accuracy: 0.4460 - val_loss: 1.5151 - val_accuracy: 0.4675\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5425 - accuracy: 0.4528 - val_loss: 1.4875 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5376 - accuracy: 0.4510 - val_loss: 1.4850 - val_accuracy: 0.4738\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5288 - accuracy: 0.4544 - val_loss: 1.4860 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5266 - accuracy: 0.4560 - val_loss: 1.4879 - val_accuracy: 0.4732\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5096 - accuracy: 0.4643 - val_loss: 1.4819 - val_accuracy: 0.4737\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5017 - accuracy: 0.4670 - val_loss: 1.4580 - val_accuracy: 0.4833\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5007 - accuracy: 0.4655 - val_loss: 1.4762 - val_accuracy: 0.4812\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4925 - accuracy: 0.4695 - val_loss: 1.4818 - val_accuracy: 0.4780\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4833 - accuracy: 0.4707 - val_loss: 1.4479 - val_accuracy: 0.4864\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.4781 - accuracy: 0.4733 - val_loss: 1.4846 - val_accuracy: 0.4756\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.4708 - accuracy: 0.4754 - val_loss: 1.4496 - val_accuracy: 0.4849\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.4706 - accuracy: 0.4767 - val_loss: 1.4648 - val_accuracy: 0.4835\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.4664 - accuracy: 0.4799 - val_loss: 1.4816 - val_accuracy: 0.4721\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.4562 - accuracy: 0.4833 - val_loss: 1.4326 - val_accuracy: 0.4943\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.4454 - accuracy: 0.4868 - val_loss: 1.4332 - val_accuracy: 0.4920\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.4489 - accuracy: 0.4821 - val_loss: 1.4313 - val_accuracy: 0.4961\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.4425 - accuracy: 0.4854 - val_loss: 1.4275 - val_accuracy: 0.4942\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.4425 - accuracy: 0.4883 - val_loss: 1.4388 - val_accuracy: 0.4921\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.4333 - accuracy: 0.4902 - val_loss: 1.4458 - val_accuracy: 0.4904\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.4368 - accuracy: 0.4881 - val_loss: 1.4277 - val_accuracy: 0.4947\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.4260 - accuracy: 0.4934 - val_loss: 1.4212 - val_accuracy: 0.4905\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4961000084877014\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.037291909695138556\n",
            "0.3050285016071079\n",
            "leakyrelu\n",
            "sgd\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1523 - accuracy: 0.2067 - val_loss: 2.0253 - val_accuracy: 0.2754\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9879 - accuracy: 0.2814 - val_loss: 1.9307 - val_accuracy: 0.3210\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9210 - accuracy: 0.3109 - val_loss: 1.8763 - val_accuracy: 0.3440\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8791 - accuracy: 0.3316 - val_loss: 1.8501 - val_accuracy: 0.3468\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8442 - accuracy: 0.3451 - val_loss: 1.8099 - val_accuracy: 0.3680\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8187 - accuracy: 0.3555 - val_loss: 1.8120 - val_accuracy: 0.3572\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7980 - accuracy: 0.3638 - val_loss: 1.7622 - val_accuracy: 0.3792\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7766 - accuracy: 0.3730 - val_loss: 1.7454 - val_accuracy: 0.3924\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7595 - accuracy: 0.3804 - val_loss: 1.7339 - val_accuracy: 0.3914\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7421 - accuracy: 0.3878 - val_loss: 1.7542 - val_accuracy: 0.3805\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7300 - accuracy: 0.3902 - val_loss: 1.7015 - val_accuracy: 0.4032\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7163 - accuracy: 0.3989 - val_loss: 1.6971 - val_accuracy: 0.4083\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7048 - accuracy: 0.4004 - val_loss: 1.7422 - val_accuracy: 0.3945\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6922 - accuracy: 0.4053 - val_loss: 1.6816 - val_accuracy: 0.4124\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6819 - accuracy: 0.4093 - val_loss: 1.6813 - val_accuracy: 0.4090\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6710 - accuracy: 0.4135 - val_loss: 1.6522 - val_accuracy: 0.4222\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6604 - accuracy: 0.4158 - val_loss: 1.6454 - val_accuracy: 0.4215\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6504 - accuracy: 0.4197 - val_loss: 1.6641 - val_accuracy: 0.4169\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6449 - accuracy: 0.4228 - val_loss: 1.6106 - val_accuracy: 0.4376\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.6351 - accuracy: 0.4269 - val_loss: 1.6124 - val_accuracy: 0.4383\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.6281 - accuracy: 0.4288 - val_loss: 1.6155 - val_accuracy: 0.4321\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6209 - accuracy: 0.4324 - val_loss: 1.6132 - val_accuracy: 0.4336\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.6128 - accuracy: 0.4334 - val_loss: 1.6118 - val_accuracy: 0.4289\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.6042 - accuracy: 0.4389 - val_loss: 1.6287 - val_accuracy: 0.4265\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.6042 - accuracy: 0.4366 - val_loss: 1.5829 - val_accuracy: 0.4473\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.5947 - accuracy: 0.4409 - val_loss: 1.6139 - val_accuracy: 0.4408\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.5890 - accuracy: 0.4438 - val_loss: 1.6135 - val_accuracy: 0.4213\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.5846 - accuracy: 0.4441 - val_loss: 1.5740 - val_accuracy: 0.4513\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.5798 - accuracy: 0.4461 - val_loss: 1.5658 - val_accuracy: 0.4534\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.5701 - accuracy: 0.4493 - val_loss: 1.5492 - val_accuracy: 0.4560\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.5635 - accuracy: 0.4515 - val_loss: 1.5883 - val_accuracy: 0.4357\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.5641 - accuracy: 0.4501 - val_loss: 1.6158 - val_accuracy: 0.4334\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.5541 - accuracy: 0.4536 - val_loss: 1.5681 - val_accuracy: 0.4487\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.5526 - accuracy: 0.4563 - val_loss: 1.5337 - val_accuracy: 0.4612\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.5485 - accuracy: 0.4586 - val_loss: 1.5625 - val_accuracy: 0.4468\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.5423 - accuracy: 0.4594 - val_loss: 1.5398 - val_accuracy: 0.4543\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.5352 - accuracy: 0.4637 - val_loss: 1.5377 - val_accuracy: 0.4543\n",
            "\n",
            "Epoch 38/100\n",
            "196/196 - 1s - loss: 1.5307 - accuracy: 0.4655 - val_loss: 1.6168 - val_accuracy: 0.4233\n",
            "\n",
            "Epoch 39/100\n",
            "196/196 - 1s - loss: 1.5271 - accuracy: 0.4631 - val_loss: 1.5766 - val_accuracy: 0.4391\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4611999988555908\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "32\n",
            "0.023486064134472684\n",
            "0.13795060794387648\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 1.9790 - accuracy: 0.2927 - val_loss: 1.8302 - val_accuracy: 0.3393\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.8134 - accuracy: 0.3542 - val_loss: 1.6895 - val_accuracy: 0.3991\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.7429 - accuracy: 0.3821 - val_loss: 1.6437 - val_accuracy: 0.4312\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.6988 - accuracy: 0.3979 - val_loss: 1.6255 - val_accuracy: 0.4152\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.6637 - accuracy: 0.4107 - val_loss: 1.6413 - val_accuracy: 0.3993\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.6318 - accuracy: 0.4198 - val_loss: 1.5568 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.6054 - accuracy: 0.4321 - val_loss: 1.5970 - val_accuracy: 0.4247\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.5792 - accuracy: 0.4396 - val_loss: 1.5266 - val_accuracy: 0.4580\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.5612 - accuracy: 0.4448 - val_loss: 1.5713 - val_accuracy: 0.4353\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.5432 - accuracy: 0.4501 - val_loss: 1.5012 - val_accuracy: 0.4642\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.5239 - accuracy: 0.4585 - val_loss: 1.4979 - val_accuracy: 0.4671\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.5068 - accuracy: 0.4646 - val_loss: 1.5558 - val_accuracy: 0.4405\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.4989 - accuracy: 0.4663 - val_loss: 1.4685 - val_accuracy: 0.4725\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.4846 - accuracy: 0.4719 - val_loss: 1.4675 - val_accuracy: 0.4784\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.4724 - accuracy: 0.4762 - val_loss: 1.4793 - val_accuracy: 0.4663\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.4577 - accuracy: 0.4825 - val_loss: 1.4474 - val_accuracy: 0.4897\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.4444 - accuracy: 0.4885 - val_loss: 1.4567 - val_accuracy: 0.4734\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.4365 - accuracy: 0.4882 - val_loss: 1.4718 - val_accuracy: 0.4817\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.4272 - accuracy: 0.4922 - val_loss: 1.4371 - val_accuracy: 0.4940\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.4205 - accuracy: 0.4916 - val_loss: 1.4824 - val_accuracy: 0.4746\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.4086 - accuracy: 0.4972 - val_loss: 1.4139 - val_accuracy: 0.4977\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.3935 - accuracy: 0.5057 - val_loss: 1.4443 - val_accuracy: 0.4886\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.3865 - accuracy: 0.5065 - val_loss: 1.4412 - val_accuracy: 0.4894\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.3824 - accuracy: 0.5072 - val_loss: 1.4382 - val_accuracy: 0.4907\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.3764 - accuracy: 0.5125 - val_loss: 1.3900 - val_accuracy: 0.5068\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.3711 - accuracy: 0.5128 - val_loss: 1.4116 - val_accuracy: 0.5036\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.3647 - accuracy: 0.5136 - val_loss: 1.4569 - val_accuracy: 0.4851\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.3550 - accuracy: 0.5173 - val_loss: 1.3609 - val_accuracy: 0.5176\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.3407 - accuracy: 0.5236 - val_loss: 1.4409 - val_accuracy: 0.4875\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.3424 - accuracy: 0.5215 - val_loss: 1.3798 - val_accuracy: 0.5119\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.3372 - accuracy: 0.5248 - val_loss: 1.4175 - val_accuracy: 0.4956\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.3229 - accuracy: 0.5287 - val_loss: 1.4135 - val_accuracy: 0.5017\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.3221 - accuracy: 0.5321 - val_loss: 1.3805 - val_accuracy: 0.5114\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5175999999046326\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "256\n",
            "0.3023905871363534\n",
            "0.41842460716702257\n",
            "relu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0842 - accuracy: 0.2413 - val_loss: 1.8453 - val_accuracy: 0.3423\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8942 - accuracy: 0.3113 - val_loss: 1.8181 - val_accuracy: 0.3474\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.8594 - accuracy: 0.3205 - val_loss: 1.7641 - val_accuracy: 0.3847\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8219 - accuracy: 0.3349 - val_loss: 1.7108 - val_accuracy: 0.3921\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.7924 - accuracy: 0.3507 - val_loss: 1.6980 - val_accuracy: 0.4008\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.7811 - accuracy: 0.3516 - val_loss: 1.6943 - val_accuracy: 0.4012\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7622 - accuracy: 0.3619 - val_loss: 1.6650 - val_accuracy: 0.4155\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7491 - accuracy: 0.3654 - val_loss: 1.6449 - val_accuracy: 0.4258\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7352 - accuracy: 0.3725 - val_loss: 1.6441 - val_accuracy: 0.4267\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7179 - accuracy: 0.3764 - val_loss: 1.6689 - val_accuracy: 0.4120\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7176 - accuracy: 0.3777 - val_loss: 1.6536 - val_accuracy: 0.4182\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7062 - accuracy: 0.3817 - val_loss: 1.6210 - val_accuracy: 0.4270\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7034 - accuracy: 0.3839 - val_loss: 1.6187 - val_accuracy: 0.4412\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6828 - accuracy: 0.3893 - val_loss: 1.6128 - val_accuracy: 0.4376\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6815 - accuracy: 0.3921 - val_loss: 1.6116 - val_accuracy: 0.4382\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6785 - accuracy: 0.3922 - val_loss: 1.5984 - val_accuracy: 0.4441\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.6783 - accuracy: 0.3951 - val_loss: 1.6175 - val_accuracy: 0.4342\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6600 - accuracy: 0.3998 - val_loss: 1.5962 - val_accuracy: 0.4424\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6650 - accuracy: 0.3982 - val_loss: 1.6087 - val_accuracy: 0.4447\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.6594 - accuracy: 0.4025 - val_loss: 1.5852 - val_accuracy: 0.4426\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.6576 - accuracy: 0.4003 - val_loss: 1.5896 - val_accuracy: 0.4489\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6582 - accuracy: 0.4002 - val_loss: 1.6012 - val_accuracy: 0.4465\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.6516 - accuracy: 0.4043 - val_loss: 1.6017 - val_accuracy: 0.4337\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.6500 - accuracy: 0.4045 - val_loss: 1.5856 - val_accuracy: 0.4470\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.6397 - accuracy: 0.4076 - val_loss: 1.5819 - val_accuracy: 0.4498\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.6390 - accuracy: 0.4080 - val_loss: 1.5844 - val_accuracy: 0.4556\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.6469 - accuracy: 0.4050 - val_loss: 1.5891 - val_accuracy: 0.4408\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.6395 - accuracy: 0.4077 - val_loss: 1.5653 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.6284 - accuracy: 0.4133 - val_loss: 1.5750 - val_accuracy: 0.4528\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.6244 - accuracy: 0.4105 - val_loss: 1.5776 - val_accuracy: 0.4531\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.6324 - accuracy: 0.4112 - val_loss: 1.5632 - val_accuracy: 0.4548\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.6256 - accuracy: 0.4139 - val_loss: 1.5556 - val_accuracy: 0.4624\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.6226 - accuracy: 0.4112 - val_loss: 1.5685 - val_accuracy: 0.4542\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.6191 - accuracy: 0.4186 - val_loss: 1.5650 - val_accuracy: 0.4543\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.6093 - accuracy: 0.4189 - val_loss: 1.5601 - val_accuracy: 0.4561\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.6200 - accuracy: 0.4150 - val_loss: 1.5780 - val_accuracy: 0.4568\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.6088 - accuracy: 0.4196 - val_loss: 1.5640 - val_accuracy: 0.4490\n",
            "\n",
            "legjobb val_acc:\n",
            "0.46239998936653137\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "512\n",
            "0.1732273212656117\n",
            "0.1929913074617016\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.5853 - accuracy: 0.1981 - val_loss: 2.1733 - val_accuracy: 0.1961\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.1000 - accuracy: 0.2573 - val_loss: 2.0366 - val_accuracy: 0.2757\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9978 - accuracy: 0.2908 - val_loss: 1.9805 - val_accuracy: 0.2816\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9188 - accuracy: 0.3166 - val_loss: 1.7830 - val_accuracy: 0.3328\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8597 - accuracy: 0.3383 - val_loss: 1.7557 - val_accuracy: 0.3709\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8025 - accuracy: 0.3603 - val_loss: 1.7801 - val_accuracy: 0.3604\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7698 - accuracy: 0.3696 - val_loss: 1.6479 - val_accuracy: 0.4055\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7365 - accuracy: 0.3846 - val_loss: 1.7771 - val_accuracy: 0.3456\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7018 - accuracy: 0.3937 - val_loss: 1.6973 - val_accuracy: 0.3931\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.6850 - accuracy: 0.4006 - val_loss: 1.7014 - val_accuracy: 0.3897\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.6619 - accuracy: 0.4092 - val_loss: 1.7213 - val_accuracy: 0.3848\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.6473 - accuracy: 0.4161 - val_loss: 1.6594 - val_accuracy: 0.3993\n",
            "\n",
            "legjobb val_acc:\n",
            "0.40549999475479126\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.33096026689586183\n",
            "0.2121564746269309\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 3s - loss: 1.9941 - accuracy: 0.2826 - val_loss: 1.8505 - val_accuracy: 0.3351\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.8542 - accuracy: 0.3369 - val_loss: 1.8334 - val_accuracy: 0.3558\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.7813 - accuracy: 0.3641 - val_loss: 1.6749 - val_accuracy: 0.3968\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.7366 - accuracy: 0.3804 - val_loss: 1.6324 - val_accuracy: 0.4017\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.7063 - accuracy: 0.3927 - val_loss: 1.6176 - val_accuracy: 0.4227\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.6894 - accuracy: 0.3965 - val_loss: 1.5757 - val_accuracy: 0.4403\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.6669 - accuracy: 0.4063 - val_loss: 1.5647 - val_accuracy: 0.4347\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.6530 - accuracy: 0.4125 - val_loss: 1.5704 - val_accuracy: 0.4408\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.6377 - accuracy: 0.4195 - val_loss: 1.5538 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.6245 - accuracy: 0.4213 - val_loss: 1.5376 - val_accuracy: 0.4551\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.6153 - accuracy: 0.4265 - val_loss: 1.5305 - val_accuracy: 0.4461\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.6028 - accuracy: 0.4260 - val_loss: 1.5071 - val_accuracy: 0.4556\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.5935 - accuracy: 0.4311 - val_loss: 1.5218 - val_accuracy: 0.4513\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.5820 - accuracy: 0.4377 - val_loss: 1.5376 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.5760 - accuracy: 0.4374 - val_loss: 1.4801 - val_accuracy: 0.4746\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.5711 - accuracy: 0.4410 - val_loss: 1.4901 - val_accuracy: 0.4765\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.5554 - accuracy: 0.4463 - val_loss: 1.4551 - val_accuracy: 0.4848\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.5569 - accuracy: 0.4471 - val_loss: 1.5483 - val_accuracy: 0.4508\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.5499 - accuracy: 0.4489 - val_loss: 1.4535 - val_accuracy: 0.4835\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.5417 - accuracy: 0.4521 - val_loss: 1.4473 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 2s - loss: 1.5342 - accuracy: 0.4544 - val_loss: 1.4954 - val_accuracy: 0.4664\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.5274 - accuracy: 0.4558 - val_loss: 1.4708 - val_accuracy: 0.4759\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4848000109195709\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "128\n",
            "0.14941748921336362\n",
            "0.3636820796734548\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0227 - accuracy: 0.2653 - val_loss: 1.8244 - val_accuracy: 0.3468\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8521 - accuracy: 0.3366 - val_loss: 1.7240 - val_accuracy: 0.4013\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7897 - accuracy: 0.3628 - val_loss: 1.6782 - val_accuracy: 0.4157\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7447 - accuracy: 0.3794 - val_loss: 1.6410 - val_accuracy: 0.4223\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.7073 - accuracy: 0.3942 - val_loss: 1.6202 - val_accuracy: 0.4233\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6772 - accuracy: 0.4052 - val_loss: 1.5996 - val_accuracy: 0.4289\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6596 - accuracy: 0.4090 - val_loss: 1.6095 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6430 - accuracy: 0.4172 - val_loss: 1.5933 - val_accuracy: 0.4336\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.6263 - accuracy: 0.4228 - val_loss: 1.5647 - val_accuracy: 0.4473\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.6121 - accuracy: 0.4293 - val_loss: 1.5239 - val_accuracy: 0.4646\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5946 - accuracy: 0.4351 - val_loss: 1.5377 - val_accuracy: 0.4575\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5867 - accuracy: 0.4371 - val_loss: 1.5111 - val_accuracy: 0.4638\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5712 - accuracy: 0.4425 - val_loss: 1.4916 - val_accuracy: 0.4764\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5671 - accuracy: 0.4441 - val_loss: 1.4983 - val_accuracy: 0.4699\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.5556 - accuracy: 0.4496 - val_loss: 1.5020 - val_accuracy: 0.4720\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.5405 - accuracy: 0.4552 - val_loss: 1.4795 - val_accuracy: 0.4811\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.5404 - accuracy: 0.4540 - val_loss: 1.4916 - val_accuracy: 0.4672\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.5302 - accuracy: 0.4559 - val_loss: 1.4655 - val_accuracy: 0.4830\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.5244 - accuracy: 0.4587 - val_loss: 1.4711 - val_accuracy: 0.4790\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.5159 - accuracy: 0.4637 - val_loss: 1.4705 - val_accuracy: 0.4730\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.5113 - accuracy: 0.4619 - val_loss: 1.4457 - val_accuracy: 0.4830\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.5050 - accuracy: 0.4673 - val_loss: 1.4581 - val_accuracy: 0.4809\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.5035 - accuracy: 0.4675 - val_loss: 1.4315 - val_accuracy: 0.4929\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.4941 - accuracy: 0.4706 - val_loss: 1.4682 - val_accuracy: 0.4798\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.4894 - accuracy: 0.4726 - val_loss: 1.4591 - val_accuracy: 0.4851\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.4861 - accuracy: 0.4712 - val_loss: 1.4216 - val_accuracy: 0.4970\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.4775 - accuracy: 0.4769 - val_loss: 1.4504 - val_accuracy: 0.4917\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.4789 - accuracy: 0.4737 - val_loss: 1.4419 - val_accuracy: 0.4879\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.4646 - accuracy: 0.4829 - val_loss: 1.4215 - val_accuracy: 0.4963\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.4643 - accuracy: 0.4803 - val_loss: 1.4184 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.4621 - accuracy: 0.4814 - val_loss: 1.4766 - val_accuracy: 0.4718\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.4544 - accuracy: 0.4869 - val_loss: 1.4427 - val_accuracy: 0.4814\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.4564 - accuracy: 0.4842 - val_loss: 1.4265 - val_accuracy: 0.4875\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.4472 - accuracy: 0.4880 - val_loss: 1.4353 - val_accuracy: 0.4869\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.4559 - accuracy: 0.4838 - val_loss: 1.3964 - val_accuracy: 0.5090\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.4437 - accuracy: 0.4904 - val_loss: 1.4093 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.4491 - accuracy: 0.4842 - val_loss: 1.4317 - val_accuracy: 0.4897\n",
            "\n",
            "Epoch 38/100\n",
            "196/196 - 1s - loss: 1.4434 - accuracy: 0.4883 - val_loss: 1.4031 - val_accuracy: 0.5038\n",
            "\n",
            "Epoch 39/100\n",
            "196/196 - 1s - loss: 1.4392 - accuracy: 0.4895 - val_loss: 1.4158 - val_accuracy: 0.4970\n",
            "\n",
            "Epoch 40/100\n",
            "196/196 - 1s - loss: 1.4333 - accuracy: 0.4927 - val_loss: 1.4109 - val_accuracy: 0.4925\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5090000033378601\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.22898653682422493\n",
            "0.28278423563437327\n",
            "leakyrelu\n",
            "sgd\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1883 - accuracy: 0.1909 - val_loss: 2.0495 - val_accuracy: 0.2870\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.0200 - accuracy: 0.2663 - val_loss: 1.9424 - val_accuracy: 0.3199\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9482 - accuracy: 0.2989 - val_loss: 1.8911 - val_accuracy: 0.3348\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9048 - accuracy: 0.3208 - val_loss: 1.8624 - val_accuracy: 0.3499\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8739 - accuracy: 0.3362 - val_loss: 1.8302 - val_accuracy: 0.3544\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8457 - accuracy: 0.3484 - val_loss: 1.8084 - val_accuracy: 0.3626\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8242 - accuracy: 0.3568 - val_loss: 1.7855 - val_accuracy: 0.3767\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.8067 - accuracy: 0.3611 - val_loss: 1.7576 - val_accuracy: 0.3866\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7910 - accuracy: 0.3688 - val_loss: 1.7463 - val_accuracy: 0.3877\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7770 - accuracy: 0.3731 - val_loss: 1.7386 - val_accuracy: 0.3949\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7623 - accuracy: 0.3764 - val_loss: 1.7360 - val_accuracy: 0.3876\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7494 - accuracy: 0.3836 - val_loss: 1.7038 - val_accuracy: 0.4025\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7381 - accuracy: 0.3882 - val_loss: 1.7000 - val_accuracy: 0.4030\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.7278 - accuracy: 0.3902 - val_loss: 1.6843 - val_accuracy: 0.4111\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.7175 - accuracy: 0.3959 - val_loss: 1.6882 - val_accuracy: 0.4066\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.7105 - accuracy: 0.3981 - val_loss: 1.6925 - val_accuracy: 0.4075\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.7006 - accuracy: 0.4018 - val_loss: 1.6905 - val_accuracy: 0.4099\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.6916 - accuracy: 0.4041 - val_loss: 1.6817 - val_accuracy: 0.4102\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.6832 - accuracy: 0.4076 - val_loss: 1.6524 - val_accuracy: 0.4171\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.6772 - accuracy: 0.4128 - val_loss: 1.6344 - val_accuracy: 0.4316\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.6692 - accuracy: 0.4140 - val_loss: 1.6401 - val_accuracy: 0.4238\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6644 - accuracy: 0.4178 - val_loss: 1.6132 - val_accuracy: 0.4369\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.6580 - accuracy: 0.4165 - val_loss: 1.6135 - val_accuracy: 0.4330\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.6508 - accuracy: 0.4228 - val_loss: 1.6136 - val_accuracy: 0.4332\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.6444 - accuracy: 0.4254 - val_loss: 1.6552 - val_accuracy: 0.4144\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.6388 - accuracy: 0.4235 - val_loss: 1.5938 - val_accuracy: 0.4397\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.6309 - accuracy: 0.4283 - val_loss: 1.5902 - val_accuracy: 0.4476\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.6268 - accuracy: 0.4309 - val_loss: 1.6011 - val_accuracy: 0.4431\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.6229 - accuracy: 0.4296 - val_loss: 1.5853 - val_accuracy: 0.4460\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.6192 - accuracy: 0.4315 - val_loss: 1.6005 - val_accuracy: 0.4395\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.6135 - accuracy: 0.4349 - val_loss: 1.5759 - val_accuracy: 0.4490\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.6085 - accuracy: 0.4361 - val_loss: 1.5696 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.6000 - accuracy: 0.4395 - val_loss: 1.5875 - val_accuracy: 0.4385\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.6010 - accuracy: 0.4371 - val_loss: 1.6019 - val_accuracy: 0.4390\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.5930 - accuracy: 0.4431 - val_loss: 1.5551 - val_accuracy: 0.4585\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.5877 - accuracy: 0.4406 - val_loss: 1.5749 - val_accuracy: 0.4491\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.5813 - accuracy: 0.4456 - val_loss: 1.5419 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 38/100\n",
            "196/196 - 1s - loss: 1.5776 - accuracy: 0.4476 - val_loss: 1.5472 - val_accuracy: 0.4624\n",
            "\n",
            "Epoch 39/100\n",
            "196/196 - 1s - loss: 1.5796 - accuracy: 0.4454 - val_loss: 1.6208 - val_accuracy: 0.4383\n",
            "\n",
            "Epoch 40/100\n",
            "196/196 - 1s - loss: 1.5709 - accuracy: 0.4503 - val_loss: 1.5474 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 41/100\n",
            "196/196 - 1s - loss: 1.5693 - accuracy: 0.4492 - val_loss: 1.5415 - val_accuracy: 0.4512\n",
            "\n",
            "Epoch 42/100\n",
            "196/196 - 1s - loss: 1.5682 - accuracy: 0.4498 - val_loss: 1.5219 - val_accuracy: 0.4657\n",
            "\n",
            "Epoch 43/100\n",
            "196/196 - 1s - loss: 1.5638 - accuracy: 0.4522 - val_loss: 1.5320 - val_accuracy: 0.4631\n",
            "\n",
            "Epoch 44/100\n",
            "196/196 - 1s - loss: 1.5575 - accuracy: 0.4539 - val_loss: 1.5190 - val_accuracy: 0.4667\n",
            "\n",
            "Epoch 45/100\n",
            "196/196 - 1s - loss: 1.5570 - accuracy: 0.4548 - val_loss: 1.5331 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 46/100\n",
            "196/196 - 1s - loss: 1.5517 - accuracy: 0.4555 - val_loss: 1.5246 - val_accuracy: 0.4645\n",
            "\n",
            "Epoch 47/100\n",
            "196/196 - 1s - loss: 1.5479 - accuracy: 0.4574 - val_loss: 1.5294 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 48/100\n",
            "196/196 - 1s - loss: 1.5469 - accuracy: 0.4587 - val_loss: 1.6194 - val_accuracy: 0.4222\n",
            "\n",
            "Epoch 49/100\n",
            "196/196 - 1s - loss: 1.5443 - accuracy: 0.4603 - val_loss: 1.5031 - val_accuracy: 0.4704\n",
            "\n",
            "Epoch 50/100\n",
            "196/196 - 1s - loss: 1.5443 - accuracy: 0.4578 - val_loss: 1.5454 - val_accuracy: 0.4580\n",
            "\n",
            "Epoch 51/100\n",
            "196/196 - 1s - loss: 1.5387 - accuracy: 0.4599 - val_loss: 1.5510 - val_accuracy: 0.4425\n",
            "\n",
            "Epoch 52/100\n",
            "196/196 - 1s - loss: 1.5324 - accuracy: 0.4633 - val_loss: 1.5296 - val_accuracy: 0.4582\n",
            "\n",
            "Epoch 53/100\n",
            "196/196 - 1s - loss: 1.5355 - accuracy: 0.4602 - val_loss: 1.5037 - val_accuracy: 0.4654\n",
            "\n",
            "Epoch 54/100\n",
            "196/196 - 1s - loss: 1.5237 - accuracy: 0.4645 - val_loss: 1.5231 - val_accuracy: 0.4620\n",
            "\n",
            "legjobb val_acc:\n",
            "0.47040000557899475\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "256\n",
            "0.36560383366401833\n",
            "0.1513344002467654\n",
            "relu\n",
            "adam\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 2.1041 - accuracy: 0.1928 - val_loss: 1.9867 - val_accuracy: 0.2691\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 2.0220 - accuracy: 0.2293 - val_loss: 1.8923 - val_accuracy: 0.2966\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.9852 - accuracy: 0.2519 - val_loss: 1.8782 - val_accuracy: 0.3262\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.9637 - accuracy: 0.2566 - val_loss: 1.8915 - val_accuracy: 0.3268\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.9475 - accuracy: 0.2722 - val_loss: 1.8762 - val_accuracy: 0.3350\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.9430 - accuracy: 0.2728 - val_loss: 1.8826 - val_accuracy: 0.3244\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.9305 - accuracy: 0.2808 - val_loss: 1.8983 - val_accuracy: 0.3247\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.9259 - accuracy: 0.2813 - val_loss: 1.8918 - val_accuracy: 0.3184\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.9202 - accuracy: 0.2857 - val_loss: 1.8911 - val_accuracy: 0.3090\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.9112 - accuracy: 0.2917 - val_loss: 1.8572 - val_accuracy: 0.3394\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.9091 - accuracy: 0.2928 - val_loss: 1.8536 - val_accuracy: 0.3484\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.9018 - accuracy: 0.2941 - val_loss: 1.8772 - val_accuracy: 0.3220\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.8972 - accuracy: 0.2971 - val_loss: 1.8730 - val_accuracy: 0.3334\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.8944 - accuracy: 0.2998 - val_loss: 1.8538 - val_accuracy: 0.3532\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.8957 - accuracy: 0.2983 - val_loss: 1.9028 - val_accuracy: 0.3314\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.8910 - accuracy: 0.3029 - val_loss: 1.9119 - val_accuracy: 0.3255\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.8885 - accuracy: 0.3034 - val_loss: 1.8612 - val_accuracy: 0.3265\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.8847 - accuracy: 0.3054 - val_loss: 1.8816 - val_accuracy: 0.3431\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.8865 - accuracy: 0.3034 - val_loss: 1.8808 - val_accuracy: 0.3234\n",
            "\n",
            "legjobb val_acc:\n",
            "0.3531999886035919\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.13067399087357662\n",
            "0.33882874958831244\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9409 - accuracy: 0.3012 - val_loss: 1.7356 - val_accuracy: 0.3848\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7768 - accuracy: 0.3675 - val_loss: 1.6672 - val_accuracy: 0.4104\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7124 - accuracy: 0.3929 - val_loss: 1.6415 - val_accuracy: 0.4162\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6645 - accuracy: 0.4107 - val_loss: 1.5943 - val_accuracy: 0.4392\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6246 - accuracy: 0.4246 - val_loss: 1.5938 - val_accuracy: 0.4311\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5994 - accuracy: 0.4338 - val_loss: 1.5264 - val_accuracy: 0.4634\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5680 - accuracy: 0.4409 - val_loss: 1.5021 - val_accuracy: 0.4682\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5435 - accuracy: 0.4525 - val_loss: 1.5632 - val_accuracy: 0.4513\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5459 - accuracy: 0.4546 - val_loss: 1.4968 - val_accuracy: 0.4600\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5193 - accuracy: 0.4609 - val_loss: 1.4717 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4971 - accuracy: 0.4689 - val_loss: 1.4598 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4875 - accuracy: 0.4735 - val_loss: 1.4570 - val_accuracy: 0.4811\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4728 - accuracy: 0.4756 - val_loss: 1.4643 - val_accuracy: 0.4817\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4615 - accuracy: 0.4818 - val_loss: 1.4630 - val_accuracy: 0.4831\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4492 - accuracy: 0.4880 - val_loss: 1.4409 - val_accuracy: 0.4823\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4383 - accuracy: 0.4885 - val_loss: 1.4450 - val_accuracy: 0.4849\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4231 - accuracy: 0.4933 - val_loss: 1.4199 - val_accuracy: 0.5002\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4149 - accuracy: 0.4976 - val_loss: 1.3911 - val_accuracy: 0.5056\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.4052 - accuracy: 0.4991 - val_loss: 1.4291 - val_accuracy: 0.4913\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.4045 - accuracy: 0.5006 - val_loss: 1.3838 - val_accuracy: 0.5087\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.3898 - accuracy: 0.5047 - val_loss: 1.4560 - val_accuracy: 0.4880\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.3820 - accuracy: 0.5084 - val_loss: 1.4420 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.3793 - accuracy: 0.5117 - val_loss: 1.3784 - val_accuracy: 0.5078\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.3684 - accuracy: 0.5133 - val_loss: 1.3896 - val_accuracy: 0.5039\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.3656 - accuracy: 0.5131 - val_loss: 1.3562 - val_accuracy: 0.5148\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.3597 - accuracy: 0.5152 - val_loss: 1.3708 - val_accuracy: 0.5131\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.3439 - accuracy: 0.5221 - val_loss: 1.3848 - val_accuracy: 0.5088\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.3495 - accuracy: 0.5196 - val_loss: 1.3593 - val_accuracy: 0.5171\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.3443 - accuracy: 0.5207 - val_loss: 1.3706 - val_accuracy: 0.5101\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.3315 - accuracy: 0.5278 - val_loss: 1.3608 - val_accuracy: 0.5177\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.3249 - accuracy: 0.5312 - val_loss: 1.3471 - val_accuracy: 0.5253\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.3147 - accuracy: 0.5328 - val_loss: 1.3289 - val_accuracy: 0.5329\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.3169 - accuracy: 0.5326 - val_loss: 1.3566 - val_accuracy: 0.5209\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.3108 - accuracy: 0.5337 - val_loss: 1.3438 - val_accuracy: 0.5209\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.3066 - accuracy: 0.5338 - val_loss: 1.3324 - val_accuracy: 0.5279\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.3146 - accuracy: 0.5318 - val_loss: 1.3843 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 2s - loss: 1.2961 - accuracy: 0.5373 - val_loss: 1.3560 - val_accuracy: 0.5156\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5328999757766724\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "64\n",
            "0.07411414405579572\n",
            "0.25556364849293434\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.3699 - accuracy: 0.2028 - val_loss: 2.3945 - val_accuracy: 0.2142\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.0611 - accuracy: 0.2700 - val_loss: 2.2554 - val_accuracy: 0.2643\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9654 - accuracy: 0.3018 - val_loss: 1.9826 - val_accuracy: 0.2985\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9066 - accuracy: 0.3232 - val_loss: 1.9517 - val_accuracy: 0.3263\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8579 - accuracy: 0.3409 - val_loss: 1.8812 - val_accuracy: 0.3418\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8145 - accuracy: 0.3545 - val_loss: 1.7245 - val_accuracy: 0.3959\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7771 - accuracy: 0.3698 - val_loss: 1.7159 - val_accuracy: 0.3681\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7529 - accuracy: 0.3799 - val_loss: 1.7681 - val_accuracy: 0.3763\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7313 - accuracy: 0.3874 - val_loss: 1.7044 - val_accuracy: 0.3813\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7032 - accuracy: 0.3965 - val_loss: 1.6992 - val_accuracy: 0.3914\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.6903 - accuracy: 0.4007 - val_loss: 1.7163 - val_accuracy: 0.3859\n",
            "\n",
            "legjobb val_acc:\n",
            "0.39590001106262207\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "32\n",
            "0.04782081799100843\n",
            "0.17894088587534437\n",
            "leakyrelu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 3s - loss: 2.0614 - accuracy: 0.2795 - val_loss: 1.8289 - val_accuracy: 0.3474\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.8513 - accuracy: 0.3406 - val_loss: 1.7423 - val_accuracy: 0.3841\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.7595 - accuracy: 0.3735 - val_loss: 1.6786 - val_accuracy: 0.4123\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.7074 - accuracy: 0.3941 - val_loss: 1.6634 - val_accuracy: 0.4108\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.6674 - accuracy: 0.4052 - val_loss: 1.5919 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.6260 - accuracy: 0.4208 - val_loss: 1.5704 - val_accuracy: 0.4356\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.5963 - accuracy: 0.4300 - val_loss: 1.6195 - val_accuracy: 0.4098\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 3s - loss: 1.5789 - accuracy: 0.4373 - val_loss: 1.5404 - val_accuracy: 0.4522\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.5587 - accuracy: 0.4431 - val_loss: 1.5160 - val_accuracy: 0.4609\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 3s - loss: 1.5343 - accuracy: 0.4567 - val_loss: 1.5139 - val_accuracy: 0.4597\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 3s - loss: 1.5202 - accuracy: 0.4606 - val_loss: 1.5592 - val_accuracy: 0.4449\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.5064 - accuracy: 0.4659 - val_loss: 1.4994 - val_accuracy: 0.4655\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.4937 - accuracy: 0.4694 - val_loss: 1.4823 - val_accuracy: 0.4636\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 3s - loss: 1.4738 - accuracy: 0.4750 - val_loss: 1.5048 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 3s - loss: 1.4678 - accuracy: 0.4754 - val_loss: 1.4423 - val_accuracy: 0.4829\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.4521 - accuracy: 0.4809 - val_loss: 1.4203 - val_accuracy: 0.4959\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.4463 - accuracy: 0.4881 - val_loss: 1.4500 - val_accuracy: 0.4710\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 3s - loss: 1.4358 - accuracy: 0.4909 - val_loss: 1.4537 - val_accuracy: 0.4872\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.4213 - accuracy: 0.4926 - val_loss: 1.3994 - val_accuracy: 0.5005\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.4091 - accuracy: 0.4997 - val_loss: 1.4263 - val_accuracy: 0.4892\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 3s - loss: 1.4041 - accuracy: 0.4990 - val_loss: 1.4672 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.3953 - accuracy: 0.5052 - val_loss: 1.4067 - val_accuracy: 0.4881\n",
            "\n",
            "Epoch 23/100\n",
            "782/782 - 3s - loss: 1.3855 - accuracy: 0.5078 - val_loss: 1.4200 - val_accuracy: 0.4928\n",
            "\n",
            "Epoch 24/100\n",
            "782/782 - 3s - loss: 1.3758 - accuracy: 0.5097 - val_loss: 1.4218 - val_accuracy: 0.4879\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5005000233650208\n",
            "a modell hiperparaméterei: \n",
            "256\n",
            "512\n",
            "0.20163694702316085\n",
            "0.2321487286787669\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.0259 - accuracy: 0.2798 - val_loss: 1.8041 - val_accuracy: 0.3560\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8004 - accuracy: 0.3578 - val_loss: 1.7009 - val_accuracy: 0.3904\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.7256 - accuracy: 0.3895 - val_loss: 1.6382 - val_accuracy: 0.4281\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6860 - accuracy: 0.4037 - val_loss: 1.5962 - val_accuracy: 0.4337\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.6398 - accuracy: 0.4213 - val_loss: 1.5523 - val_accuracy: 0.4502\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6034 - accuracy: 0.4304 - val_loss: 1.5760 - val_accuracy: 0.4441\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5773 - accuracy: 0.4394 - val_loss: 1.5593 - val_accuracy: 0.4492\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.5510 - accuracy: 0.4519 - val_loss: 1.5154 - val_accuracy: 0.4585\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.5493 - accuracy: 0.4507 - val_loss: 1.4903 - val_accuracy: 0.4691\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5223 - accuracy: 0.4597 - val_loss: 1.5120 - val_accuracy: 0.4692\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5046 - accuracy: 0.4626 - val_loss: 1.4832 - val_accuracy: 0.4688\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4787 - accuracy: 0.4756 - val_loss: 1.4770 - val_accuracy: 0.4645\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4746 - accuracy: 0.4787 - val_loss: 1.4384 - val_accuracy: 0.4981\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.4650 - accuracy: 0.4808 - val_loss: 1.4364 - val_accuracy: 0.4930\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4411 - accuracy: 0.4888 - val_loss: 1.4551 - val_accuracy: 0.4838\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.4439 - accuracy: 0.4863 - val_loss: 1.4676 - val_accuracy: 0.4731\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.4289 - accuracy: 0.4936 - val_loss: 1.4337 - val_accuracy: 0.4944\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.4129 - accuracy: 0.4973 - val_loss: 1.4275 - val_accuracy: 0.4917\n",
            "\n",
            "legjobb val_acc:\n",
            "0.49810001254081726\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.41073868942760605\n",
            "0.11617590819130447\n",
            "relu\n",
            "sgd\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.2155 - accuracy: 0.1743 - val_loss: 2.0904 - val_accuracy: 0.2564\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 2.0785 - accuracy: 0.2313 - val_loss: 1.9844 - val_accuracy: 0.2974\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 2.0055 - accuracy: 0.2657 - val_loss: 1.9250 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.9550 - accuracy: 0.2910 - val_loss: 1.8881 - val_accuracy: 0.3279\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.9210 - accuracy: 0.3081 - val_loss: 1.8495 - val_accuracy: 0.3468\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8901 - accuracy: 0.3219 - val_loss: 1.8216 - val_accuracy: 0.3612\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.8684 - accuracy: 0.3298 - val_loss: 1.7969 - val_accuracy: 0.3692\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.8455 - accuracy: 0.3416 - val_loss: 1.7730 - val_accuracy: 0.3752\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.8275 - accuracy: 0.3465 - val_loss: 1.7636 - val_accuracy: 0.3729\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.8123 - accuracy: 0.3551 - val_loss: 1.7425 - val_accuracy: 0.3858\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7974 - accuracy: 0.3614 - val_loss: 1.7199 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7874 - accuracy: 0.3626 - val_loss: 1.7150 - val_accuracy: 0.3951\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.7735 - accuracy: 0.3699 - val_loss: 1.7153 - val_accuracy: 0.3906\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.7661 - accuracy: 0.3715 - val_loss: 1.6859 - val_accuracy: 0.4033\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.7550 - accuracy: 0.3771 - val_loss: 1.6776 - val_accuracy: 0.4082\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.7483 - accuracy: 0.3781 - val_loss: 1.6683 - val_accuracy: 0.4149\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.7382 - accuracy: 0.3835 - val_loss: 1.6646 - val_accuracy: 0.4142\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.7281 - accuracy: 0.3860 - val_loss: 1.6503 - val_accuracy: 0.4210\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.7234 - accuracy: 0.3902 - val_loss: 1.6649 - val_accuracy: 0.4129\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.7124 - accuracy: 0.3955 - val_loss: 1.6352 - val_accuracy: 0.4231\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.7067 - accuracy: 0.3952 - val_loss: 1.6344 - val_accuracy: 0.4208\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.6951 - accuracy: 0.3986 - val_loss: 1.6133 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.6899 - accuracy: 0.4017 - val_loss: 1.6192 - val_accuracy: 0.4282\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.6841 - accuracy: 0.4038 - val_loss: 1.6102 - val_accuracy: 0.4222\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.6814 - accuracy: 0.4032 - val_loss: 1.5978 - val_accuracy: 0.4367\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.6718 - accuracy: 0.4069 - val_loss: 1.6099 - val_accuracy: 0.4339\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.6655 - accuracy: 0.4096 - val_loss: 1.5826 - val_accuracy: 0.4440\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.6608 - accuracy: 0.4105 - val_loss: 1.5828 - val_accuracy: 0.4475\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.6552 - accuracy: 0.4146 - val_loss: 1.5769 - val_accuracy: 0.4447\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.6479 - accuracy: 0.4200 - val_loss: 1.5939 - val_accuracy: 0.4353\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.6465 - accuracy: 0.4212 - val_loss: 1.5596 - val_accuracy: 0.4461\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.6414 - accuracy: 0.4197 - val_loss: 1.5647 - val_accuracy: 0.4530\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.6351 - accuracy: 0.4217 - val_loss: 1.5876 - val_accuracy: 0.4364\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.6318 - accuracy: 0.4226 - val_loss: 1.5492 - val_accuracy: 0.4512\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.6236 - accuracy: 0.4255 - val_loss: 1.5539 - val_accuracy: 0.4423\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.6232 - accuracy: 0.4233 - val_loss: 1.5457 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 37/100\n",
            "196/196 - 1s - loss: 1.6181 - accuracy: 0.4264 - val_loss: 1.5391 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 38/100\n",
            "196/196 - 1s - loss: 1.6126 - accuracy: 0.4295 - val_loss: 1.5272 - val_accuracy: 0.4619\n",
            "\n",
            "Epoch 39/100\n",
            "196/196 - 1s - loss: 1.6071 - accuracy: 0.4308 - val_loss: 1.5316 - val_accuracy: 0.4551\n",
            "\n",
            "Epoch 40/100\n",
            "196/196 - 1s - loss: 1.6053 - accuracy: 0.4338 - val_loss: 1.5230 - val_accuracy: 0.4591\n",
            "\n",
            "Epoch 41/100\n",
            "196/196 - 1s - loss: 1.6020 - accuracy: 0.4345 - val_loss: 1.5251 - val_accuracy: 0.4608\n",
            "\n",
            "Epoch 42/100\n",
            "196/196 - 1s - loss: 1.5979 - accuracy: 0.4348 - val_loss: 1.5435 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 43/100\n",
            "196/196 - 1s - loss: 1.5933 - accuracy: 0.4387 - val_loss: 1.5267 - val_accuracy: 0.4610\n",
            "\n",
            "Epoch 44/100\n",
            "196/196 - 1s - loss: 1.5881 - accuracy: 0.4386 - val_loss: 1.5031 - val_accuracy: 0.4663\n",
            "\n",
            "Epoch 45/100\n",
            "196/196 - 1s - loss: 1.5847 - accuracy: 0.4414 - val_loss: 1.5075 - val_accuracy: 0.4681\n",
            "\n",
            "Epoch 46/100\n",
            "196/196 - 1s - loss: 1.5808 - accuracy: 0.4407 - val_loss: 1.5154 - val_accuracy: 0.4649\n",
            "\n",
            "Epoch 47/100\n",
            "196/196 - 1s - loss: 1.5788 - accuracy: 0.4417 - val_loss: 1.5052 - val_accuracy: 0.4648\n",
            "\n",
            "Epoch 48/100\n",
            "196/196 - 1s - loss: 1.5730 - accuracy: 0.4457 - val_loss: 1.5063 - val_accuracy: 0.4711\n",
            "\n",
            "Epoch 49/100\n",
            "196/196 - 1s - loss: 1.5737 - accuracy: 0.4442 - val_loss: 1.5081 - val_accuracy: 0.4692\n",
            "\n",
            "Epoch 50/100\n",
            "196/196 - 1s - loss: 1.5674 - accuracy: 0.4478 - val_loss: 1.5048 - val_accuracy: 0.4696\n",
            "\n",
            "Epoch 51/100\n",
            "196/196 - 1s - loss: 1.5688 - accuracy: 0.4433 - val_loss: 1.4924 - val_accuracy: 0.4748\n",
            "\n",
            "Epoch 52/100\n",
            "196/196 - 1s - loss: 1.5641 - accuracy: 0.4458 - val_loss: 1.5319 - val_accuracy: 0.4627\n",
            "\n",
            "Epoch 53/100\n",
            "196/196 - 1s - loss: 1.5594 - accuracy: 0.4483 - val_loss: 1.4890 - val_accuracy: 0.4671\n",
            "\n",
            "Epoch 54/100\n",
            "196/196 - 1s - loss: 1.5562 - accuracy: 0.4499 - val_loss: 1.4899 - val_accuracy: 0.4704\n",
            "\n",
            "Epoch 55/100\n",
            "196/196 - 1s - loss: 1.5537 - accuracy: 0.4515 - val_loss: 1.5102 - val_accuracy: 0.4589\n",
            "\n",
            "Epoch 56/100\n",
            "196/196 - 1s - loss: 1.5502 - accuracy: 0.4516 - val_loss: 1.4731 - val_accuracy: 0.4790\n",
            "\n",
            "Epoch 57/100\n",
            "196/196 - 1s - loss: 1.5465 - accuracy: 0.4522 - val_loss: 1.5056 - val_accuracy: 0.4640\n",
            "\n",
            "Epoch 58/100\n",
            "196/196 - 1s - loss: 1.5443 - accuracy: 0.4526 - val_loss: 1.4772 - val_accuracy: 0.4689\n",
            "\n",
            "Epoch 59/100\n",
            "196/196 - 1s - loss: 1.5424 - accuracy: 0.4542 - val_loss: 1.4715 - val_accuracy: 0.4796\n",
            "\n",
            "Epoch 60/100\n",
            "196/196 - 1s - loss: 1.5409 - accuracy: 0.4558 - val_loss: 1.4829 - val_accuracy: 0.4747\n",
            "\n",
            "Epoch 61/100\n",
            "196/196 - 1s - loss: 1.5359 - accuracy: 0.4591 - val_loss: 1.4692 - val_accuracy: 0.4750\n",
            "\n",
            "Epoch 62/100\n",
            "196/196 - 1s - loss: 1.5343 - accuracy: 0.4559 - val_loss: 1.4718 - val_accuracy: 0.4750\n",
            "\n",
            "Epoch 63/100\n",
            "196/196 - 1s - loss: 1.5326 - accuracy: 0.4582 - val_loss: 1.4655 - val_accuracy: 0.4818\n",
            "\n",
            "Epoch 64/100\n",
            "196/196 - 1s - loss: 1.5307 - accuracy: 0.4580 - val_loss: 1.4750 - val_accuracy: 0.4764\n",
            "\n",
            "Epoch 65/100\n",
            "196/196 - 1s - loss: 1.5285 - accuracy: 0.4571 - val_loss: 1.4633 - val_accuracy: 0.4793\n",
            "\n",
            "Epoch 66/100\n",
            "196/196 - 1s - loss: 1.5217 - accuracy: 0.4617 - val_loss: 1.4673 - val_accuracy: 0.4753\n",
            "\n",
            "Epoch 67/100\n",
            "196/196 - 1s - loss: 1.5223 - accuracy: 0.4611 - val_loss: 1.4847 - val_accuracy: 0.4722\n",
            "\n",
            "Epoch 68/100\n",
            "196/196 - 1s - loss: 1.5172 - accuracy: 0.4656 - val_loss: 1.4733 - val_accuracy: 0.4687\n",
            "\n",
            "legjobb val_acc:\n",
            "0.48179998993873596\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.088290781952474\n",
            "0.08644017030534433\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9247 - accuracy: 0.3074 - val_loss: 1.8260 - val_accuracy: 0.3441\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7372 - accuracy: 0.3799 - val_loss: 1.6592 - val_accuracy: 0.4028\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.6554 - accuracy: 0.4113 - val_loss: 1.5876 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6025 - accuracy: 0.4328 - val_loss: 1.5814 - val_accuracy: 0.4451\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.5583 - accuracy: 0.4475 - val_loss: 1.5337 - val_accuracy: 0.4621\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5248 - accuracy: 0.4587 - val_loss: 1.4943 - val_accuracy: 0.4699\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.4998 - accuracy: 0.4687 - val_loss: 1.4663 - val_accuracy: 0.4749\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.4759 - accuracy: 0.4802 - val_loss: 1.4510 - val_accuracy: 0.4853\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.4580 - accuracy: 0.4837 - val_loss: 1.4662 - val_accuracy: 0.4821\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.4317 - accuracy: 0.4912 - val_loss: 1.4428 - val_accuracy: 0.4849\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4194 - accuracy: 0.4963 - val_loss: 1.4925 - val_accuracy: 0.4715\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4043 - accuracy: 0.5005 - val_loss: 1.4065 - val_accuracy: 0.4991\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.3821 - accuracy: 0.5095 - val_loss: 1.4556 - val_accuracy: 0.4820\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.3650 - accuracy: 0.5154 - val_loss: 1.4170 - val_accuracy: 0.4989\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.3511 - accuracy: 0.5198 - val_loss: 1.3863 - val_accuracy: 0.5068\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.3320 - accuracy: 0.5266 - val_loss: 1.3656 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.3259 - accuracy: 0.5291 - val_loss: 1.3691 - val_accuracy: 0.5163\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 1s - loss: 1.3139 - accuracy: 0.5331 - val_loss: 1.3440 - val_accuracy: 0.5233\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 1s - loss: 1.2962 - accuracy: 0.5359 - val_loss: 1.3807 - val_accuracy: 0.5079\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 1s - loss: 1.2787 - accuracy: 0.5456 - val_loss: 1.3869 - val_accuracy: 0.5129\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 1s - loss: 1.2807 - accuracy: 0.5437 - val_loss: 1.3655 - val_accuracy: 0.5156\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 1s - loss: 1.2652 - accuracy: 0.5528 - val_loss: 1.3605 - val_accuracy: 0.5164\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 1s - loss: 1.2609 - accuracy: 0.5508 - val_loss: 1.3325 - val_accuracy: 0.5240\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 1s - loss: 1.2518 - accuracy: 0.5552 - val_loss: 1.3691 - val_accuracy: 0.5195\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 1s - loss: 1.2408 - accuracy: 0.5587 - val_loss: 1.3415 - val_accuracy: 0.5284\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 1s - loss: 1.2320 - accuracy: 0.5627 - val_loss: 1.3651 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 1s - loss: 1.2227 - accuracy: 0.5645 - val_loss: 1.3198 - val_accuracy: 0.5289\n",
            "\n",
            "Epoch 28/100\n",
            "196/196 - 1s - loss: 1.2172 - accuracy: 0.5669 - val_loss: 1.3251 - val_accuracy: 0.5269\n",
            "\n",
            "Epoch 29/100\n",
            "196/196 - 1s - loss: 1.2121 - accuracy: 0.5678 - val_loss: 1.3261 - val_accuracy: 0.5289\n",
            "\n",
            "Epoch 30/100\n",
            "196/196 - 1s - loss: 1.2043 - accuracy: 0.5717 - val_loss: 1.3752 - val_accuracy: 0.5198\n",
            "\n",
            "Epoch 31/100\n",
            "196/196 - 1s - loss: 1.1906 - accuracy: 0.5751 - val_loss: 1.2985 - val_accuracy: 0.5424\n",
            "\n",
            "Epoch 32/100\n",
            "196/196 - 1s - loss: 1.1836 - accuracy: 0.5768 - val_loss: 1.3474 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 33/100\n",
            "196/196 - 1s - loss: 1.1766 - accuracy: 0.5785 - val_loss: 1.3191 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 34/100\n",
            "196/196 - 1s - loss: 1.1659 - accuracy: 0.5868 - val_loss: 1.3262 - val_accuracy: 0.5268\n",
            "\n",
            "Epoch 35/100\n",
            "196/196 - 1s - loss: 1.1628 - accuracy: 0.5863 - val_loss: 1.3118 - val_accuracy: 0.5407\n",
            "\n",
            "Epoch 36/100\n",
            "196/196 - 1s - loss: 1.1603 - accuracy: 0.5866 - val_loss: 1.3387 - val_accuracy: 0.5244\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5424000024795532\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "128\n",
            "0.09113545597367531\n",
            "0.08683644490637958\n",
            "leakyrelu\n",
            "adam\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 1.9523 - accuracy: 0.3010 - val_loss: 1.8422 - val_accuracy: 0.3401\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.7741 - accuracy: 0.3668 - val_loss: 1.7088 - val_accuracy: 0.3903\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.7039 - accuracy: 0.3938 - val_loss: 1.6173 - val_accuracy: 0.4338\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.6465 - accuracy: 0.4146 - val_loss: 1.5696 - val_accuracy: 0.4467\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.6011 - accuracy: 0.4309 - val_loss: 1.5343 - val_accuracy: 0.4545\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.5760 - accuracy: 0.4404 - val_loss: 1.5182 - val_accuracy: 0.4653\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.5466 - accuracy: 0.4488 - val_loss: 1.4835 - val_accuracy: 0.4776\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.5222 - accuracy: 0.4592 - val_loss: 1.4964 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.5057 - accuracy: 0.4648 - val_loss: 1.4859 - val_accuracy: 0.4736\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.4874 - accuracy: 0.4716 - val_loss: 1.4529 - val_accuracy: 0.4886\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.4754 - accuracy: 0.4750 - val_loss: 1.4463 - val_accuracy: 0.4924\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.4588 - accuracy: 0.4837 - val_loss: 1.4586 - val_accuracy: 0.4840\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.4419 - accuracy: 0.4862 - val_loss: 1.4460 - val_accuracy: 0.4827\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.4283 - accuracy: 0.4927 - val_loss: 1.4401 - val_accuracy: 0.4803\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.4158 - accuracy: 0.4991 - val_loss: 1.4070 - val_accuracy: 0.4981\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.3985 - accuracy: 0.5034 - val_loss: 1.4076 - val_accuracy: 0.4926\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.3986 - accuracy: 0.5050 - val_loss: 1.4319 - val_accuracy: 0.4917\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.3831 - accuracy: 0.5088 - val_loss: 1.4092 - val_accuracy: 0.5026\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.3648 - accuracy: 0.5166 - val_loss: 1.3925 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.3617 - accuracy: 0.5151 - val_loss: 1.4086 - val_accuracy: 0.4981\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.3526 - accuracy: 0.5177 - val_loss: 1.3517 - val_accuracy: 0.5212\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.3422 - accuracy: 0.5219 - val_loss: 1.3548 - val_accuracy: 0.5141\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.3321 - accuracy: 0.5261 - val_loss: 1.3596 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.3255 - accuracy: 0.5278 - val_loss: 1.3574 - val_accuracy: 0.5159\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.3199 - accuracy: 0.5296 - val_loss: 1.3487 - val_accuracy: 0.5235\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.3151 - accuracy: 0.5330 - val_loss: 1.3447 - val_accuracy: 0.5231\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.3073 - accuracy: 0.5353 - val_loss: 1.3362 - val_accuracy: 0.5273\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.2998 - accuracy: 0.5360 - val_loss: 1.3737 - val_accuracy: 0.5137\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.2950 - accuracy: 0.5388 - val_loss: 1.3549 - val_accuracy: 0.5195\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.2913 - accuracy: 0.5408 - val_loss: 1.3662 - val_accuracy: 0.5200\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.2804 - accuracy: 0.5433 - val_loss: 1.3723 - val_accuracy: 0.5149\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.2784 - accuracy: 0.5446 - val_loss: 1.3487 - val_accuracy: 0.5263\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5273000001907349\n",
            "a modell hiperparaméterei: \n",
            "64\n",
            "512\n",
            "0.05833072702024829\n",
            "0.1324692066246537\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 1.9140 - accuracy: 0.3095 - val_loss: 1.7454 - val_accuracy: 0.3740\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.7228 - accuracy: 0.3860 - val_loss: 1.6699 - val_accuracy: 0.4000\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.6575 - accuracy: 0.4102 - val_loss: 1.6664 - val_accuracy: 0.4077\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.6090 - accuracy: 0.4312 - val_loss: 1.5554 - val_accuracy: 0.4413\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.5686 - accuracy: 0.4453 - val_loss: 1.5484 - val_accuracy: 0.4484\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.5356 - accuracy: 0.4560 - val_loss: 1.5456 - val_accuracy: 0.4538\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.5126 - accuracy: 0.4638 - val_loss: 1.4932 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.4850 - accuracy: 0.4733 - val_loss: 1.5285 - val_accuracy: 0.4508\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.4659 - accuracy: 0.4820 - val_loss: 1.4490 - val_accuracy: 0.4885\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.4481 - accuracy: 0.4871 - val_loss: 1.4475 - val_accuracy: 0.4850\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.4292 - accuracy: 0.4939 - val_loss: 1.4144 - val_accuracy: 0.4992\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.4245 - accuracy: 0.4950 - val_loss: 1.4184 - val_accuracy: 0.5022\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.4029 - accuracy: 0.5040 - val_loss: 1.4078 - val_accuracy: 0.4998\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.3936 - accuracy: 0.5070 - val_loss: 1.4312 - val_accuracy: 0.4937\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.3759 - accuracy: 0.5123 - val_loss: 1.4288 - val_accuracy: 0.4938\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.3690 - accuracy: 0.5161 - val_loss: 1.3980 - val_accuracy: 0.4910\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 1s - loss: 1.3590 - accuracy: 0.5171 - val_loss: 1.3908 - val_accuracy: 0.4977\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5022000074386597\n",
            "a modell hiperparaméterei: \n",
            "32\n",
            "64\n",
            "0.14140190043449952\n",
            "0.2182061546509619\n",
            "leakyrelu\n",
            "rmsprop\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.1879 - accuracy: 0.2095 - val_loss: 2.0034 - val_accuracy: 0.2702\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.9967 - accuracy: 0.2804 - val_loss: 1.9085 - val_accuracy: 0.3046\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.9234 - accuracy: 0.3105 - val_loss: 1.8167 - val_accuracy: 0.3412\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.8795 - accuracy: 0.3267 - val_loss: 1.8421 - val_accuracy: 0.3483\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.8462 - accuracy: 0.3395 - val_loss: 1.8327 - val_accuracy: 0.3511\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.8162 - accuracy: 0.3506 - val_loss: 1.8131 - val_accuracy: 0.3622\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.7927 - accuracy: 0.3608 - val_loss: 1.7818 - val_accuracy: 0.3475\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.7678 - accuracy: 0.3720 - val_loss: 1.7010 - val_accuracy: 0.4021\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.7476 - accuracy: 0.3765 - val_loss: 1.7397 - val_accuracy: 0.3659\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.7363 - accuracy: 0.3847 - val_loss: 1.7102 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.7241 - accuracy: 0.3896 - val_loss: 1.6171 - val_accuracy: 0.4260\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.7142 - accuracy: 0.3951 - val_loss: 1.6489 - val_accuracy: 0.4034\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.6992 - accuracy: 0.3949 - val_loss: 1.6965 - val_accuracy: 0.3865\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.6897 - accuracy: 0.4008 - val_loss: 1.6858 - val_accuracy: 0.3928\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.6784 - accuracy: 0.4051 - val_loss: 1.6499 - val_accuracy: 0.3990\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 1s - loss: 1.6696 - accuracy: 0.4076 - val_loss: 1.6729 - val_accuracy: 0.4124\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4259999990463257\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "256\n",
            "0.1848874045809159\n",
            "0.18654016442868465\n",
            "relu\n",
            "adam\n",
            "64\n",
            "Epoch 1/100\n",
            "782/782 - 2s - loss: 2.0159 - accuracy: 0.2454 - val_loss: 1.9081 - val_accuracy: 0.3021\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 2s - loss: 1.9237 - accuracy: 0.2892 - val_loss: 1.9310 - val_accuracy: 0.2765\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 2s - loss: 1.8930 - accuracy: 0.3016 - val_loss: 1.8281 - val_accuracy: 0.3423\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 2s - loss: 1.8677 - accuracy: 0.3164 - val_loss: 1.7978 - val_accuracy: 0.3404\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 2s - loss: 1.8453 - accuracy: 0.3218 - val_loss: 1.7608 - val_accuracy: 0.3662\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 2s - loss: 1.8300 - accuracy: 0.3311 - val_loss: 1.7439 - val_accuracy: 0.3735\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 2s - loss: 1.8229 - accuracy: 0.3329 - val_loss: 1.7233 - val_accuracy: 0.3861\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 2s - loss: 1.8045 - accuracy: 0.3420 - val_loss: 1.7528 - val_accuracy: 0.3680\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 2s - loss: 1.7951 - accuracy: 0.3489 - val_loss: 1.7442 - val_accuracy: 0.3632\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 2s - loss: 1.7937 - accuracy: 0.3499 - val_loss: 1.7069 - val_accuracy: 0.3894\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 2s - loss: 1.7753 - accuracy: 0.3551 - val_loss: 1.7022 - val_accuracy: 0.3994\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 2s - loss: 1.7648 - accuracy: 0.3604 - val_loss: 1.6908 - val_accuracy: 0.3997\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 2s - loss: 1.7600 - accuracy: 0.3618 - val_loss: 1.6840 - val_accuracy: 0.4117\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 2s - loss: 1.7494 - accuracy: 0.3647 - val_loss: 1.6717 - val_accuracy: 0.3970\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 2s - loss: 1.7480 - accuracy: 0.3682 - val_loss: 1.6968 - val_accuracy: 0.4019\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 2s - loss: 1.7387 - accuracy: 0.3679 - val_loss: 1.6760 - val_accuracy: 0.4079\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 2s - loss: 1.7330 - accuracy: 0.3747 - val_loss: 1.6492 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 2s - loss: 1.7268 - accuracy: 0.3773 - val_loss: 1.6617 - val_accuracy: 0.4131\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 2s - loss: 1.7247 - accuracy: 0.3777 - val_loss: 1.6545 - val_accuracy: 0.4080\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 2s - loss: 1.7167 - accuracy: 0.3834 - val_loss: 1.6573 - val_accuracy: 0.4041\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 2s - loss: 1.7121 - accuracy: 0.3800 - val_loss: 1.6720 - val_accuracy: 0.4104\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 2s - loss: 1.7130 - accuracy: 0.3808 - val_loss: 1.6497 - val_accuracy: 0.4131\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4162999987602234\n",
            "a modell hiperparaméterei: \n",
            "512\n",
            "32\n",
            "0.08000261304092696\n",
            "0.14631259533326987\n",
            "leakyrelu\n",
            "adam\n",
            "256\n",
            "Epoch 1/100\n",
            "196/196 - 1s - loss: 2.2169 - accuracy: 0.2546 - val_loss: 1.8514 - val_accuracy: 0.3599\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 1s - loss: 1.8648 - accuracy: 0.3391 - val_loss: 1.8227 - val_accuracy: 0.3502\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 1s - loss: 1.8075 - accuracy: 0.3602 - val_loss: 1.6920 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 1s - loss: 1.7580 - accuracy: 0.3733 - val_loss: 1.7238 - val_accuracy: 0.3841\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 1s - loss: 1.7157 - accuracy: 0.3931 - val_loss: 1.6663 - val_accuracy: 0.4055\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 1s - loss: 1.6761 - accuracy: 0.4053 - val_loss: 1.6289 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 1s - loss: 1.6506 - accuracy: 0.4160 - val_loss: 1.5813 - val_accuracy: 0.4428\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 1s - loss: 1.6204 - accuracy: 0.4257 - val_loss: 1.5744 - val_accuracy: 0.4396\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 1s - loss: 1.6027 - accuracy: 0.4298 - val_loss: 1.6070 - val_accuracy: 0.4313\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 1s - loss: 1.5786 - accuracy: 0.4377 - val_loss: 1.5265 - val_accuracy: 0.4586\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 1s - loss: 1.5548 - accuracy: 0.4471 - val_loss: 1.5207 - val_accuracy: 0.4510\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 1s - loss: 1.5495 - accuracy: 0.4508 - val_loss: 1.5461 - val_accuracy: 0.4491\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 1s - loss: 1.5232 - accuracy: 0.4613 - val_loss: 1.5428 - val_accuracy: 0.4418\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 1s - loss: 1.5199 - accuracy: 0.4607 - val_loss: 1.5515 - val_accuracy: 0.4454\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 1s - loss: 1.4982 - accuracy: 0.4671 - val_loss: 1.5502 - val_accuracy: 0.4462\n",
            "\n",
            "legjobb val_acc:\n",
            "0.4586000144481659\n",
            "a modell hiperparaméterei: \n",
            "128\n",
            "512\n",
            "0.002637123933316138\n",
            "0.0930350470950645\n",
            "leakyrelu\n",
            "sgd\n",
            "128\n",
            "Epoch 1/100\n",
            "391/391 - 1s - loss: 2.0620 - accuracy: 0.2543 - val_loss: 1.9280 - val_accuracy: 0.3213\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 1s - loss: 1.8874 - accuracy: 0.3304 - val_loss: 1.8405 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 1s - loss: 1.8219 - accuracy: 0.3575 - val_loss: 1.7922 - val_accuracy: 0.3662\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 1s - loss: 1.7774 - accuracy: 0.3779 - val_loss: 1.7835 - val_accuracy: 0.3644\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 1s - loss: 1.7418 - accuracy: 0.3901 - val_loss: 1.7227 - val_accuracy: 0.3926\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 1s - loss: 1.7154 - accuracy: 0.3995 - val_loss: 1.7142 - val_accuracy: 0.4012\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 1s - loss: 1.6912 - accuracy: 0.4080 - val_loss: 1.6808 - val_accuracy: 0.4084\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 1s - loss: 1.6700 - accuracy: 0.4145 - val_loss: 1.6702 - val_accuracy: 0.4095\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 1s - loss: 1.6500 - accuracy: 0.4222 - val_loss: 1.6544 - val_accuracy: 0.4110\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 1s - loss: 1.6322 - accuracy: 0.4283 - val_loss: 1.6314 - val_accuracy: 0.4289\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 1s - loss: 1.6171 - accuracy: 0.4335 - val_loss: 1.5954 - val_accuracy: 0.4437\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 1s - loss: 1.6022 - accuracy: 0.4395 - val_loss: 1.6213 - val_accuracy: 0.4216\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 1s - loss: 1.5875 - accuracy: 0.4453 - val_loss: 1.5797 - val_accuracy: 0.4464\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 1s - loss: 1.5776 - accuracy: 0.4465 - val_loss: 1.6286 - val_accuracy: 0.4215\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 1s - loss: 1.5637 - accuracy: 0.4522 - val_loss: 1.5878 - val_accuracy: 0.4431\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 1s - loss: 1.5546 - accuracy: 0.4568 - val_loss: 1.5628 - val_accuracy: 0.4462\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 1s - loss: 1.5397 - accuracy: 0.4593 - val_loss: 1.5614 - val_accuracy: 0.4554\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 1s - loss: 1.5324 - accuracy: 0.4622 - val_loss: 1.5487 - val_accuracy: 0.4548\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 1s - loss: 1.5242 - accuracy: 0.4667 - val_loss: 1.5453 - val_accuracy: 0.4483\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 1s - loss: 1.5131 - accuracy: 0.4714 - val_loss: 1.5303 - val_accuracy: 0.4573\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 1s - loss: 1.5098 - accuracy: 0.4721 - val_loss: 1.5150 - val_accuracy: 0.4657\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 1s - loss: 1.4986 - accuracy: 0.4757 - val_loss: 1.5509 - val_accuracy: 0.4545\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 1s - loss: 1.4898 - accuracy: 0.4798 - val_loss: 1.4974 - val_accuracy: 0.4720\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 1s - loss: 1.4819 - accuracy: 0.4802 - val_loss: 1.5140 - val_accuracy: 0.4634\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 1s - loss: 1.4719 - accuracy: 0.4852 - val_loss: 1.5031 - val_accuracy: 0.4741\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 1s - loss: 1.4657 - accuracy: 0.4891 - val_loss: 1.5041 - val_accuracy: 0.4645\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 1s - loss: 1.4576 - accuracy: 0.4919 - val_loss: 1.5111 - val_accuracy: 0.4655\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 1s - loss: 1.4503 - accuracy: 0.4941 - val_loss: 1.4765 - val_accuracy: 0.4822\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 1s - loss: 1.4444 - accuracy: 0.4938 - val_loss: 1.4687 - val_accuracy: 0.4791\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 1s - loss: 1.4344 - accuracy: 0.4971 - val_loss: 1.4851 - val_accuracy: 0.4753\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 1s - loss: 1.4304 - accuracy: 0.4986 - val_loss: 1.5360 - val_accuracy: 0.4628\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 1s - loss: 1.4222 - accuracy: 0.5022 - val_loss: 1.4913 - val_accuracy: 0.4769\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 1s - loss: 1.4178 - accuracy: 0.5048 - val_loss: 1.4424 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 1s - loss: 1.4137 - accuracy: 0.5034 - val_loss: 1.5067 - val_accuracy: 0.4683\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 1s - loss: 1.4056 - accuracy: 0.5100 - val_loss: 1.4802 - val_accuracy: 0.4787\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 1s - loss: 1.4015 - accuracy: 0.5092 - val_loss: 1.4526 - val_accuracy: 0.4865\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 1s - loss: 1.3995 - accuracy: 0.5106 - val_loss: 1.4254 - val_accuracy: 0.4994\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 1s - loss: 1.3873 - accuracy: 0.5134 - val_loss: 1.4710 - val_accuracy: 0.4814\n",
            "\n",
            "Epoch 39/100\n",
            "391/391 - 1s - loss: 1.3842 - accuracy: 0.5151 - val_loss: 1.4360 - val_accuracy: 0.4976\n",
            "\n",
            "Epoch 40/100\n",
            "391/391 - 1s - loss: 1.3777 - accuracy: 0.5158 - val_loss: 1.4295 - val_accuracy: 0.4939\n",
            "\n",
            "Epoch 41/100\n",
            "391/391 - 1s - loss: 1.3771 - accuracy: 0.5197 - val_loss: 1.4087 - val_accuracy: 0.5070\n",
            "\n",
            "Epoch 42/100\n",
            "391/391 - 1s - loss: 1.3683 - accuracy: 0.5195 - val_loss: 1.4253 - val_accuracy: 0.5016\n",
            "\n",
            "Epoch 43/100\n",
            "391/391 - 1s - loss: 1.3596 - accuracy: 0.5241 - val_loss: 1.4681 - val_accuracy: 0.4822\n",
            "\n",
            "Epoch 44/100\n",
            "391/391 - 1s - loss: 1.3566 - accuracy: 0.5271 - val_loss: 1.4322 - val_accuracy: 0.4948\n",
            "\n",
            "Epoch 45/100\n",
            "391/391 - 1s - loss: 1.3535 - accuracy: 0.5256 - val_loss: 1.4420 - val_accuracy: 0.4941\n",
            "\n",
            "Epoch 46/100\n",
            "391/391 - 1s - loss: 1.3470 - accuracy: 0.5275 - val_loss: 1.5282 - val_accuracy: 0.4609\n",
            "\n",
            "legjobb val_acc:\n",
            "0.5070000290870667\n",
            "100%|██████████| 130/130 [1:11:20<00:00, 32.92s/it, best loss: -0.5424000024795532]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F78SnYox5K7F",
        "outputId": "cf4d1f7e-7384-4e50-ff95-1f7ace0ceaba"
      },
      "source": [
        "x_train, y_train, x_test, y_test = data()\n",
        "print(\"evaluation of the best model:\")\n",
        "print(best_model.evaluate(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "legjobb modell kiértékelése:\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.3387 - accuracy: 0.5244\n",
            "[1.3387049436569214, 0.524399995803833]\n",
            "legjobb hiperparaméterek:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "thC8Lewz5Uj_",
        "outputId": "5ce900db-0afc-4417-a4d6-a6d8cb0ad999"
      },
      "source": [
        "import pandas\n",
        "df = pandas.read_csv('cifar10.csv', delimiter=';') \n",
        "df.to_csv('hyperparams_log.csv') #after we have our dataframe in a nice format, we want to save it to a csv file \n",
        "\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_layer1</th>\n",
              "      <th>n_layer2</th>\n",
              "      <th>dropout_1</th>\n",
              "      <th>dropout_2</th>\n",
              "      <th>act</th>\n",
              "      <th>optim</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.305438</td>\n",
              "      <td>0.368585</td>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512</td>\n",
              "      <td>64</td>\n",
              "      <td>0.348754</td>\n",
              "      <td>0.257640</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512</td>\n",
              "      <td>128</td>\n",
              "      <td>0.281191</td>\n",
              "      <td>0.197497</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>128</td>\n",
              "      <td>0.4977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.498777</td>\n",
              "      <td>0.495601</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0.448256</td>\n",
              "      <td>0.016617</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>64</td>\n",
              "      <td>512</td>\n",
              "      <td>0.058331</td>\n",
              "      <td>0.132469</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.141402</td>\n",
              "      <td>0.218206</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>256</td>\n",
              "      <td>0.184887</td>\n",
              "      <td>0.186540</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.4163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>512</td>\n",
              "      <td>32</td>\n",
              "      <td>0.080003</td>\n",
              "      <td>0.146313</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.002637</td>\n",
              "      <td>0.093035</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     n_layer1  n_layer2  dropout_1  ...    optim n_batch best_val_acc\n",
              "0          32        64   0.305438  ...      sgd     256       0.3743\n",
              "1         512        64   0.348754  ...  rmsprop     256       0.4614\n",
              "2         512       128   0.281191  ...     adam     128       0.4977\n",
              "3         128        64   0.498777  ...     adam      64       0.1912\n",
              "4         256       256   0.448256  ...  rmsprop     256       0.4333\n",
              "..        ...       ...        ...  ...      ...     ...          ...\n",
              "125        64       512   0.058331  ...     adam     256       0.5022\n",
              "126        32        64   0.141402  ...  rmsprop     256       0.4260\n",
              "127       128       256   0.184887  ...     adam      64       0.4163\n",
              "128       512        32   0.080003  ...     adam     256       0.4586\n",
              "129       128       512   0.002637  ...      sgd     128       0.5070\n",
              "\n",
              "[130 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "_6UCn-k1jdzZ",
        "outputId": "35c71d3f-4273-49ce-b40b-ae78ef4b1bfe"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_layer1</th>\n",
              "      <th>n_layer2</th>\n",
              "      <th>dropout_1</th>\n",
              "      <th>dropout_2</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "      <th>act_leakyrelu</th>\n",
              "      <th>act_relu</th>\n",
              "      <th>optim_adam</th>\n",
              "      <th>optim_rmsprop</th>\n",
              "      <th>optim_sgd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>176.246154</td>\n",
              "      <td>294.646154</td>\n",
              "      <td>0.179375</td>\n",
              "      <td>0.207533</td>\n",
              "      <td>200.861538</td>\n",
              "      <td>0.471896</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>0.169231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>144.995486</td>\n",
              "      <td>201.823964</td>\n",
              "      <td>0.120366</td>\n",
              "      <td>0.125439</td>\n",
              "      <td>78.385230</td>\n",
              "      <td>0.061980</td>\n",
              "      <td>0.422955</td>\n",
              "      <td>0.422955</td>\n",
              "      <td>0.477583</td>\n",
              "      <td>0.383080</td>\n",
              "      <td>0.376406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.001131</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.086748</td>\n",
              "      <td>0.109296</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.454150</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.157760</td>\n",
              "      <td>0.195244</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.482450</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>256.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>0.248888</td>\n",
              "      <td>0.292066</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.510700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>0.498777</td>\n",
              "      <td>0.495601</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.542400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         n_layer1    n_layer2  ...  optim_rmsprop   optim_sgd\n",
              "count  130.000000  130.000000  ...     130.000000  130.000000\n",
              "mean   176.246154  294.646154  ...       0.176923    0.169231\n",
              "std    144.995486  201.823964  ...       0.383080    0.376406\n",
              "min     32.000000   32.000000  ...       0.000000    0.000000\n",
              "25%    128.000000   64.000000  ...       0.000000    0.000000\n",
              "50%    128.000000  256.000000  ...       0.000000    0.000000\n",
              "75%    256.000000  512.000000  ...       0.000000    0.000000\n",
              "max    512.000000  512.000000  ...       1.000000    1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGgh85tzExjZ"
      },
      "source": [
        "*Right now, we can already see quite a lot.*\n",
        "\n",
        "*First, we can see that for dropout_1 the most optimal values is probably going to be a lower one. (The same can also be said about dropout_2)*\n",
        "\n",
        "*Second, we can see that the best validation accuracy we've achieved was 0.542. And we can even see that there was a model that didn't even learn, and it couldn't improve from 0.1 val accuracy. *\n",
        "\n",
        "*Moving on, we've used 2 types of activation. We can see that leakyrelu was picked 76.9% of the time, while relu was picked 23.1% of the time. Probably meaning that leakyrelu was performing better, but we shall see later.* \n",
        "\n",
        "*We had 3 types of optimization, adam was used 65.3% of the time, rmsprop 17.6% and sgd 16.9%. If i had to guess, I would say that adam is the best performing one.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trlpLKZuNws2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2cd3358b-e017-4ad8-a66c-b8c591922e05"
      },
      "source": [
        "best10 = df.sort_values(by=['best_val_acc'], ascending=False).head(n=10)\n",
        "best10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_layer1</th>\n",
              "      <th>n_layer2</th>\n",
              "      <th>dropout_1</th>\n",
              "      <th>dropout_2</th>\n",
              "      <th>act</th>\n",
              "      <th>optim</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.088291</td>\n",
              "      <td>0.086440</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.144599</td>\n",
              "      <td>0.170449</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.137113</td>\n",
              "      <td>0.215578</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.127076</td>\n",
              "      <td>0.001131</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>128</td>\n",
              "      <td>256</td>\n",
              "      <td>0.031248</td>\n",
              "      <td>0.157957</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.168410</td>\n",
              "      <td>0.170959</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.130674</td>\n",
              "      <td>0.338829</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.112653</td>\n",
              "      <td>0.020356</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.5277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.091135</td>\n",
              "      <td>0.086836</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0.122071</td>\n",
              "      <td>0.135603</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     n_layer1  n_layer2  dropout_1  ...  optim n_batch best_val_acc\n",
              "123       128       512   0.088291  ...   adam     256       0.5424\n",
              "66        128       512   0.144599  ...   adam     256       0.5413\n",
              "39        128       512   0.137113  ...   adam     256       0.5355\n",
              "68        128       512   0.127076  ...   adam     256       0.5354\n",
              "20        128       256   0.031248  ...   adam     256       0.5352\n",
              "33        128       512   0.168410  ...   adam     256       0.5333\n",
              "118       128       512   0.130674  ...   adam     256       0.5329\n",
              "79        128       512   0.112653  ...   adam      64       0.5277\n",
              "124       128       128   0.091135  ...   adam     128       0.5273\n",
              "25        256       256   0.122071  ...   adam     256       0.5266\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z4lERmwHBSB"
      },
      "source": [
        "*Okay, we are not that bad at guessing as I expected!*\n",
        "\n",
        "*Jokes aside, it's quite obvious that leakyrelu + adam is the way to go, and it seems that the higher the batch size the better. Also n_layer1 should be 128, n_layer2 similarly 512, and for dropout_1 the values are around 0.08-0.16, but dropout_2 seems to be all over the place (0.33 and 0.00 also work quite fine).* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZGXyPejN_As",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "1f98c98f-7b50-4735-8c97-73e5d3b9826c"
      },
      "source": [
        "worst10 = df.sort_values(by=['best_val_acc'], ascending=False).tail(n=10)\n",
        "worst10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_layer1</th>\n",
              "      <th>n_layer2</th>\n",
              "      <th>dropout_1</th>\n",
              "      <th>dropout_2</th>\n",
              "      <th>act</th>\n",
              "      <th>optim</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.074114</td>\n",
              "      <td>0.255564</td>\n",
              "      <td>leakyrelu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>32</td>\n",
              "      <td>512</td>\n",
              "      <td>0.081654</td>\n",
              "      <td>0.233244</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>32</td>\n",
              "      <td>512</td>\n",
              "      <td>0.156299</td>\n",
              "      <td>0.252141</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.305438</td>\n",
              "      <td>0.368585</td>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>32</td>\n",
              "      <td>256</td>\n",
              "      <td>0.365604</td>\n",
              "      <td>0.151334</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>128</td>\n",
              "      <td>0.3532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>32</td>\n",
              "      <td>512</td>\n",
              "      <td>0.066281</td>\n",
              "      <td>0.472874</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>0.208559</td>\n",
              "      <td>0.269212</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.344082</td>\n",
              "      <td>0.349433</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.498777</td>\n",
              "      <td>0.495601</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>0.240367</td>\n",
              "      <td>0.207741</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     n_layer1  n_layer2  dropout_1  ...    optim n_batch best_val_acc\n",
              "119       128        64   0.074114  ...  rmsprop     256       0.3959\n",
              "101        32       512   0.081654  ...  rmsprop     256       0.3939\n",
              "78         32       512   0.156299  ...  rmsprop     256       0.3864\n",
              "0          32        64   0.305438  ...      sgd     256       0.3743\n",
              "117        32       256   0.365604  ...     adam     128       0.3532\n",
              "11         32       512   0.066281  ...     adam     256       0.3523\n",
              "17         64        32   0.208559  ...  rmsprop      64       0.3329\n",
              "96        128        64   0.344082  ...     adam      64       0.2599\n",
              "3         128        64   0.498777  ...     adam      64       0.1912\n",
              "16         64        64   0.240367  ...     adam      64       0.1000\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD1_TxgQIE2U"
      },
      "source": [
        "*It seems that one thing we should not doo is use relu with low values for n_layer1 and n_layer2. Also it seems that high dropout rates are not giving good results.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duMt3TuIOK2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "3c03f275-649a-4833-9991-8a1b3c76d504"
      },
      "source": [
        "df = pandas.get_dummies(df, columns=['act', 'optim', ]) # for correlation matrix I use dummy variables\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_layer1</th>\n",
              "      <th>n_layer2</th>\n",
              "      <th>dropout_1</th>\n",
              "      <th>dropout_2</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "      <th>act_leakyrelu</th>\n",
              "      <th>act_relu</th>\n",
              "      <th>optim_adam</th>\n",
              "      <th>optim_rmsprop</th>\n",
              "      <th>optim_sgd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.305438</td>\n",
              "      <td>0.368585</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3743</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512</td>\n",
              "      <td>64</td>\n",
              "      <td>0.348754</td>\n",
              "      <td>0.257640</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4614</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>512</td>\n",
              "      <td>128</td>\n",
              "      <td>0.281191</td>\n",
              "      <td>0.197497</td>\n",
              "      <td>128</td>\n",
              "      <td>0.4977</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.498777</td>\n",
              "      <td>0.495601</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1912</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>0.448256</td>\n",
              "      <td>0.016617</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>64</td>\n",
              "      <td>512</td>\n",
              "      <td>0.058331</td>\n",
              "      <td>0.132469</td>\n",
              "      <td>256</td>\n",
              "      <td>0.5022</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.141402</td>\n",
              "      <td>0.218206</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4260</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>256</td>\n",
              "      <td>0.184887</td>\n",
              "      <td>0.186540</td>\n",
              "      <td>64</td>\n",
              "      <td>0.4163</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>512</td>\n",
              "      <td>32</td>\n",
              "      <td>0.080003</td>\n",
              "      <td>0.146313</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4586</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "      <td>0.002637</td>\n",
              "      <td>0.093035</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     n_layer1  n_layer2  dropout_1  ...  optim_adam  optim_rmsprop  optim_sgd\n",
              "0          32        64   0.305438  ...           0              0          1\n",
              "1         512        64   0.348754  ...           0              1          0\n",
              "2         512       128   0.281191  ...           1              0          0\n",
              "3         128        64   0.498777  ...           1              0          0\n",
              "4         256       256   0.448256  ...           0              1          0\n",
              "..        ...       ...        ...  ...         ...            ...        ...\n",
              "125        64       512   0.058331  ...           1              0          0\n",
              "126        32        64   0.141402  ...           0              1          0\n",
              "127       128       256   0.184887  ...           1              0          0\n",
              "128       512        32   0.080003  ...           1              0          0\n",
              "129       128       512   0.002637  ...           0              0          1\n",
              "\n",
              "[130 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24y513X_NXil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "3e724f2f-8c35-4b22-fd81-630f9531496a"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(df.corr(), annot=True, fmt='.1g')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d94971ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAIXCAYAAAAv2XxIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e+ZSSaN9BASinRQkV5EBYWEBMS+YlsLsBakKL0sIJYVVFTsgrgorq4N3XXZFYQAAiIovSMhFClJSC+kTTJzfn/MQGZCKElumODv/TzPPMzce+5935w593LmnHtnlNYaIYQQQgijmDydgBBCCCH+WKRzIYQQQghDSedCCCGEEIaSzoUQQgghDCWdCyGEEEIYSjoXQgghhDCUdC6EEEKIy5hS6iOlVJpSavc51iul1NtKqSSl1E6lVBeXdYOVUgecj8FG5SSdCyGEEOLythAYcJ71NwOtnY8ngLkASqkw4FngWqAH8KxSKtSIhKRzIYQQQlzGtNZrgazzFLkD+Id2+AUIUUpFA/2BBK11ltY6G0jg/J2UiyadCyGEEOKPrRFwzOX1ceeycy2vMS8jdiLOrzTjkEe/Y/0fnWZ4MjwAHXSBR+N7e9k8Gt9uVx6NDxASUuTR+IUFFo/GB8gq9PNo/GJt9mh8gKubpXk0/qHfwz0aH+DG1EW1dkDWxvneUr/lMBzTGafN11rPNzqOkaRzIYQQQtRhzo5ETToTJ4AmLq8bO5edAPpUWL66BnHOkGkRIYQQwih2m/GPmlsMPOK8a6QnkKu1TgGWAfFKqVDnhZzxzmU1JiMXQgghxGVMKfUFjhGICKXUcRx3gHgDaK3nAUuAgUASUAgMda7LUkr9Ddjk3NULWuvzXRh60aRzIYQQQhhF2y99SK0fuMB6DYw8x7qPgI+MzkmmRYQQQghhKBm5EEIIIYxiv/QjF3WRdC6EEEIIg2gPTIvURTItIoQQQghDyciFEEIIYRSZFgFk5EIIIYQQBpORCyGEEMIocs0FIJ0LIYQQwjjGfKPmZU+mRYQQQghhKBm5EEIIIYwi0yKAdC7qtOmz5rD2542EhYbw3WfzLlncni88TJOYTpQVlbB27Hwydx9xW2/2tRD7wdMENo1E2+wcXbGNzS99VeU4V7zwKMExXbEXlXB47DsU7j50Vhn/9i1o/sbTmHwt5K7awtEZCxw5hNSj5dzx+DSJpORYGgeffA1bbgGB17Wj1Ud/xXrM8bPS2Ut+IfnNr8+bR+BNXWj07GMos5nML5eTNvdbt/XK4sUVc8bi374VZdl5/D7qVazH06jXqxMNpzyC8vZCl5aRPGshp9bvrHI9AAT16Uzj5x4Hs4nMLxI4+f7ZOTR7cyx+7Vtiy87n8AhHDuaQQFp8MBn/jq3IXLSK48/U/FeY/W7oRvjk4Sizibx//UDuAvf31rdre8InPYmlTQvSJs2iIOGnGscEqHdjF6JnPAEmE9lfLydj3jdu65XFi8avjcP3mlbYcvI59tQrlJ5Iw7tRJK0T5lJy6AQARdv3kzz9vWrl0PLFoYTFdsFWVELi6Pc4tevw2Xl2aEHbt0Zi8rWQtXIrB6d/DEDTCfcQ9WA/SjPzADj80udkr9xW5RzazhxM/djO2IpK2P30XPJ3HTmrTGCH5lzz9nDMvhbSV25j/7RPHLldfQVXv/oY5gBfio+ls3P4u9hOFVU5BwCfnt0JGTcKZTJRsHgJ+f/4wm19vQcGEXDHQHSZDXtOLtkvvoot9WS1YlVUF94HUTMyLVKH3TkwjnlzXrykMRvHdCSoeRSLeo1n3eQFXP/SkErL7frge77tM4nvBkyjQbc2NO7boUpxgmO64NO8Ibt6jeDI5Lk0fWlYpeWavvQkRya9z65eI/Bp3pDgvl0AiB75J/LW7WJXr5HkrdtF9Mg/ndnm1MZ97Ikfx574cRfsWGAy0fhvwzg0+Hl+6zeS0NtvxKd1E7ciYffFYcs9xb6bhpG+YDHRUwYDYMvO49BfXmR//6c5Ou5NrnhjbJXqwDWHJi8OI+mR59kXM4rQO3rjWyGH8PvjKMs5xd7eT5L298U0murIQZdYSX7tn5x4cWH1YleSS8S0UaSOmMaxOx6n3s198G5xhVuRspQ00p95jVNLVhkT0xm34fPDOTL0WZL6jyD4tpvwaeVeB6H3xmPLK+BAzBNkfvQfoiYPObPO+nsqB299moO3Pl3tjkVobGf8WkSz6bqnODDhA1q98nil5Vq98jiJ4+ex6bqn8GsRTWhMpzPrTsz/H1v7TWRrv4nV+g8tIrYTAc2jWddzDHsnfMjVsx+rtNzVsx9l7/j5rOs5hoDm0UQ4c2g3ZxgHXvyCDX0mcXLJJpqNvK3KOQBgMhE6cTQZY6aQev9Q/OJj8Gre1K1IaWISaYOHk/bQ4xStWkvwqCeqF6uCuvA+1IjdbvzjMvSH6lwopRYqpQbVcowblVJblVJltR2rW6f2BAcF1maIszSN70rSN+sASN96EEtQAH6RIW5lbMVWUtbvA8BeaiNz9xECosOqFCekfw8yv/kRgIKtiZiDA/CODHUr4x0ZijnQj4KtiQBkfvMjIQN6lG+/yLF95qIfCRlwbRX/Ugf/Tq0pOZKC9dhJdGkZ2f/9ieA4930Fx11L1reO/0hzlvxM4A0dASjac4iyNMcPCBYnHsXka0FZqj4YGNCpNSVHUrEedeaw+CeC43u4lQmJv5asbxw5ZH//M4E3ODpz9qISCjbtw15irXLcyvi0b0vp0WTKjqdCWRkFS9cQ0Pd6tzJlySexJh4GrQ2JCeDXsQ0lv6dQ6nwfcv+3lsC4nm5lAvv1JPvblQDkLl1HwPUdDYsPENG/Oye/XgNA/tYDeAUFYKnQ9i2RIXjV8yN/6wEATn69hogBPc7aV3XVH9CN5EVrAcjdkoRXkP85c8jdkgRA8qK11L+5GwD+LaPJ3uA4NjPX7KLBLdXLzXL1lZQdP4EtOQXKyihKWIXfje7toGTLdnRJCQDW3XsxR9avVqyK6sL7IGruD9W5qG1KKS/gKDAE+Nyz2dQO/6hQCpIzz7wuTMkiICr0nOUtQf406deZ5HV7qhTHEhWO1SVOaUom3lHuHRTvqDCsKeVlrCmZWKLCHesiQihNy3Zsm5aNd0T5yade17a0S5hD60+fwbeN+6ffiryjwilNyXDJIwNvZwy3MsnOMjY7tvwCzKHunb7ggddTtPsg2lp2oT+90hysya45ZFaSQ1h5mXPkYASvyAjKUtPPvC47mY65Qfh5tjCG431wiZuSgXeFuN4NXMrY7NjzCzGHBgFgadKAlv99i+ZfvIR/93bVysESHUaJS5ssScnEUqHTbIkOoyTl3GUa/mUAXVa9Rps3huMVHFDlHHyjwyg+Ub7/4pQsfCvk4BsdRnFK+a9iFyeXlynYf/xMRyPqtmvxbVS9984cGYHtZNqZ17a0DMz1z915CLh9IMUbNlYrVkV14X2oCa3thj8uR3W+c6GUaqaU2qeU+lAptUcptVwp5XcR281QSm1SSu1WSs1XDi2VUltdyrQ+/Vop1VUptUYptUUptUwpFe1cvlop9aZSajMwWmt9RGu9E7g833EDKbOJPu+NZO9Hy8g/mn7hDWqT81N0wa5D7OjxBHvixpH28fe0/mhKrYf2bd2EhlMGc+yv79d6LHG2svQs9vcaysHbRpMy8+80eWMCpnoXPEUYLnnhcjZe+xRbYydiPZlDi+ceueQ57B4zjyZD4um5fBbmen7Yq9HZrSr/Af3wvqoN+Z9V/bqr2uDx90GmRYDL54LO1sADWuvHlVJfA3cDn11gm3e11i8AKKU+BW7VWv9XKZWrlOqktd4ODAU+Vkp5A+8Ad2it05VS9wEzgb8492XRWnerSsJKqSeAJwDef/1FHnvkgapsfkldNbgfbf/cF4CMHYcIaFj+acc/OoyC1OxKt+v1yqPkHU5lz4JlFxUncvDN1H8wDoCC7UlYXOJ4R4dTmprlVr40NQtLdHkZS3Q41lTHp5XSjBy8I0MdoxaRoZRm5gJgd7l4LXfVVtSsYXiFBkJ+TqU5laZm4h0d4ZJHBKWpmWeXaehcbjZhDgzAlp3vKB8VTrP5Uzk67k2sR1Mvqh4qy8HS0DWH8EpyyMJyjhyMVJaWgVdU+SdUrwb1sZ3MPM8WxnC8Dy5xoyMorRC39KSjTJmzDkyB/tiyHRft2ayOuijefRDr0VQszRtRvCvpgnGjh/Yn+sF+AORvT8LHpU36RIdjTXFvk9aULHyiKy9TmpF7ZnnKP1dwzacX17FtMjSeRg/FAJC3/aDbaEPFUQo4ezTDt2F5mcKkZLbeNwsA/xbR1I/rfFE5VGRLy8DcIPLMa3NkBLb0sz9A+HTvQuCQB0kfPhZKS6sVC+rG+yCMVedHLpwOOzsDAFuAZhexTV+l1K9KqV1ADHB6rPTvwFCllBm4D8f0RlvgGiBBKbUdmA40dtlXlbvkWuv5WutuWutudbljAbDvkxV8138a3/Wfxu8/bKHVoF4A1O/SktL8QorSzv6PuevEQXgH+fHLsxfq45VL+2TpmQsts5f9SvggR4cmoEsbbHmFZ6Y5TitNy8aWX0RAlzYAhA/qS84yx9BrzvJNhN/j2D78nvLlXvXLp0cCOrUGk6LsPP8JF+44gE/zhliaNEB5exF6W2/yEn51K5O3YiNhdztO/iEDbyDfeUeIOSiAFh/PIOWVf1Cwed9F10NFBTsO4NMsGkuTSEcOt/cmN8F9iDknYSNhgxw5hN5yA/k/V++ulAsp2b0f76aN8GoUBV5eBNx8EwWrN9RKLFdFOxPxadYQ78aO9yH41hvJX+H+PuSv/JXQu2MBCL65FwUbnO9DWBCYHKcy7yYNsDRrSOlFdvRSPl525sK/zB820eDemwAI7NKasvxCrBXavjUth7JTRQR2aQ1Ag3tvImPZJgC36wIibu5BwW/HLiqHYx8v55fYKfwSO4W0pZtpeM+Njr+xa6vz5hDctRUADe+5kfQfNjtyiHBME6EULcbexbFPVlxUDhVZ9/2GV5NGmKMd7cAvLoaite7twLtNK0KnjCNz4nTs2ZV33i9WXXgfDKPtxj8uQ5fLyEWJy3MbcN4xT6WUL/A+0E1rfUwp9Rzg61z9LfAssArYorXOVEo1BPZora87xy4LapJ8dU189mU2bdtJTk4esXc+xIhHH+bu2/rXasxjq7bTOKYj96x7nbJiKz+NK7+18c5lM/mu/zT8o8PoNPpOcg6c4M4fHHez7F2YQOIXqy86Tu7KLQTHdKX9z3Mdt6KOe+fMunbL57AnfhwAv0/9oPxW1B+3krvKMauV8t6/aDVvAvUfiKXkeDoHn3wNgLBbriPykQFomw17sZVDI14/fyI2O8dnfECLfzyHMpvI+noFxQeOETXuzxTuTCJvxUYyv0qg6RvjuGrNB5Tl5PP7qFcBiBh8C5Zm0UQ9fR9RT98HwMGHn6UsM/d8ESvN4dgz82n1mSOHzK9WUpx4jOjxjhxyEzaS+WUCzd4cy9U/zcOWk8/hka+V19f6+ZgD/VHeXoT0v5akB5+j+EA1T6g2Oxmz3iVq3iyU2UT+v5dRevB3Qkc+QsmeRApX/4JPuzY0eOtZTIGB+N/Uk9ARD3P8rhreKWCzk/zcPJp98gLKZCJ7UQIlB44SOeZBinYdIH/lRrK/Wk7jOeNpvWo+ttxTHHv6FQACelxD5JgH0WU2sNtJnv4ettxTVU4ha8VWwmI70/2Xd7AXWdk/pvyuky4rXmVrv4kAJE35sPwWyFXbz9yN0PyZh6l3TTO01pQcS+fAxA+qnEPGim1ExHai169vYSsqYc/o8lvQe658mV9iHZ/C903+iGveHo7J10LGyu1krHR89oq66waaDI0HIG3JRpKrcEy6sdnJee0dIt5+BWUyU/DfpZQdPkLQE0Ow7kuk+Kf1BD81DOXvS9isZx2bpKaROXF69eK5qAvvg6g5pQ284rs2KKWaAf/TWl/jfD0BqKe1fq6SsguB/wErgP04RjjMwC/AN6e3UUq9g2Nq5VGt9VKllAXYCzystd7gnCZpo7Xeo5RaDUzQWm+uLJbW2v1m/EqUZhzyaCX/o9MMT4YHoIP2SP/sDG8vz34lr92uPBofICSket93YJTCAotH4wNkFV76azFcFWuzR+MDXN0s7cKFatGh32v/AuELuTF1Ua0dkCW/rTH8fO9z5U2eP4FU0eUyLVIlWusc4ENgN7AM2FShyD9xXJC53FneCgwCXlFK7QC2A9dTCaVUd6XUceAe4AOlVNVukxBCCPHHJdMiwGUwLaK1PoLjeojTr187T9khLs+n47h2ojK9gI+11jaX8tuBGyvZZ58Krzfhfj2GEEIIIVzU+c6F0ZRS/wZa4rjIUwghhDDOZXrrqNEuy86FUuo94IYKi9/SWn98oW211nfVTlZCCCGEgMu0c6G1HunpHIQQQoizXKbXSBjtsuxcCCGEEHWSTIsAf9C7RYQQQgjhOTJyIYQQQhjE5SbE/9dk5EIIIYQQhpKRCyGEEMIockEnICMXQgghhDCYjFwIIYQQRpG7RQDpXAghhBDGkWkRQKZFhBBCCGEwGbkQQgghjGKXW1FBOheXxD86zfBo/Ee2v+DR+ABfd/BsHbS1nfJo/CatcjwaH8CnkWcHKi1JZR6ND7DvaLBH47f09mw7BEg43tCj8Qdedcyj8cWlIZ0LIYQQwihyzQUgnQshhBDCOHK3CCAXdAohhBDCYDJyIYQQQhhFpkUAGbkQQgghhMFk5EIIIYQwilxzAUjnQgghhDCOdC4AmRYRQgghhMFk5EIIIYQwiNbyDZ0gIxdCCCGEMJiMXAghhBBGkWsuABm5EEIIIS57SqkBSqn9SqkkpdSUSta/oZTa7nwkKqVyXNbZXNYtNiIfGbkQQgghjOKBL9FSSpmB94A44DiwSSm1WGu990xaWo91Kf8U0NllF0Va605G5iSdCyGEEMIonpkW6QEkaa0PASilvgTuAPaeo/wDwLO1mZBMiwghhBB1mFLqCaXUZpfHExWKNAJcf8v+uHNZZftqCjQHVrks9nXu9xel1J1G5CwjF3VMzxcepklMJ8qKSlg7dj6Zu4+4rTf7Woj94GkCm0aibXaOrtjG5pe+qrV8ps+aw9qfNxIWGsJ3n82rtTiuuv7tYRo562DD2Plk7zritt7sZ6H3B09Tr5mjDk4kbGP7rKrVQVCfzlzx/GNgNpHxRQKp7/3Lbb2yeNH8zTH4d2hJWXY+h4a/hvV4GgBRI+8m4oF+YLNzdMaH5K3ZjvLx5spvZ6Is3iizmewl60l+/ctq/f2WHj0IHDUKzGaKvv+ews8/d1vvf889+N1yC9pmw56TQ97s2dhPnqxWrMp4deiO38OjwGTCunoJJf/9wj2/2NvwibsD7HZ0cRGFC+ZgP/G7YfEBfHp2J2TcKJTJRMHiJeT/wz2Heg8MIuCOgegyG/acXLJffBVbqnF1ANDpb48QHduRsiIrm8Z8QE4l7fC6+U8T0KwB2mYnZflWdlWxHVYU1KczjZ97HMwmMr9I4OT737qtVxYvmr05Fr/2LbFl53N4xKtYj6dhDgmkxQeT8e/YisxFqzj+zPwa5XHatS88TGPnsbjuHOejvvPLz0fHEraxxcDzkaV7DwJHPQVmk+NY+KLisXAvfgOdx0JuDnmzXzH0WKiWWpgW0VrPB4x5U+F+4Bvtfs9sU631CaVUC2CVUmqX1vpgTYL8oUYulFILlVKDajnGOKXUXqXUTqXUSmcv0BCNYzoS1DyKRb3Gs27yAq5/aUil5XZ98D3f9pnEdwOm0aBbGxr37WBUCme5c2Ac8+a8WGv7r6ihsw4W3zCeXyctoMc56mDfvO/5342TWBo/jfrd29CwKnVgMnHFi8NIfPgF9vR9irA7euPburFbkYj74yjLPcXuXsM5+eFiGk99BADf1o0Ju6MXe2KeIvGh57li5pNgMqFLStl/7wz2xo9lb/+xBPXpQkCXNlWvAJOJwNGjyZk8mczBg/GNicHc1L2JlR44QOawYWQ9+igla9YQOGxY1eOcizLhN2Q0BbOnkD9pKJbrYjA1co9vXb+S/CmPkT/1CYr/9xV+Dw43Lj6AyUToxNFkjJlC6v1D8YuPwat5hTpITCJt8HDSHnqcolVrCR5V8YNczUTFdKReiyiWXj+eLRMX0OXloZWW2z93Cct6TyQhbirhPdoQFdOx+kFNJpq8OIykR55nX8woQu/ojW/rJm5Fwu+PoyznFHt7P0na3xfTaOpgAHSJleTX/smJFxdWP34Fp89H3/Yaz/rJC7juHMfi7nnf8++bJrG4/zQiu7ehkVHnI5OJwNFjyJkyicwhg/GNja38WHjyCbIe+4vzWHjSmNiXnxOAa2Np7FxWmfsBt9661vqE899DwGrcr8eolj9U56K2KaW8gG1AN611B+AbYLZR+28a35Wkb9YBkL71IJagAPwiQ9zK2IqtpKzfB4C91Ebm7iMERIcZlcJZunVqT3BQYK3tv6LG/btyyFkHmVsPYgkOwLdiHRRZOelSB1m7juBXhToI6NSakiMpWI+eRJeWkfWfdYTEX+tWJiS+B5mLfgQg+/v1BPbq4Fx+LVn/WYe2lmE9lkbJkRQCOrV25FJYDIDyMqO8zKB1lf9+7yuvxHbiBLaUFCgro3jVKnxuuMGtTOn27VBS4ni+dy+m+vWrHOdczC2vxH7yBPb0FLCVYf1lFd5dr3cvVFR45qny8QWq/neej+XqKyk7fgJbsqMOihJW4Xejew4lW7ajnXVg3b0Xc6RxdQDQcEBXfl/0EwBZW5OwBPlX2g7T1zumtHWpjZwqtsOKHO0y9Uy7zF78E8HxPdzKhMRfS9Y3jtHs7O9/JvAGR7u0F5VQsGkf9hJrteNXdEX/Cuej4MrPR6kVjkWjzkfeV16FLbnisdDLrUzp9m21dixUm91u/OPCNgGtlVLNlVIWHB2Is+76UEpdCYQCG1yWhSqlfJzPI4AbOPe1GhetznculFLNlFL7lFIfKqX2KKWWK6X8LmK7GUqpTUqp3Uqp+cqhpVJqq0uZ1qdfK6W6KqXWKKW2KKWWKaWinctXK6XeVEptBkZrrX/UWp8+u/6Co4doCP+oUAqSM8+8LkzJIiAq9JzlLUH+NOnXmeR1e4xKweP8o0IpdK2D5Cz8z1MH3kH+NIrrzMkq1IElOgxrSsaZ19bUTCwVToiWKJcyNju2vEK8QgPPv63JxNXL3qDjjk/I+2kHBdsOXHROp5nq18eenn7mtT09HfN5Tph+t9yCdePGKsc5Z/ywCOyZaeXxszIwhZ4d3xJ3B4FzPsPvgSco+uRdw+IDmCMjsJ0sz8GWlnHeOgi4fSDFG4yrAwC/qDD3dpiShV/0+dthdFwX0n7aXe2Y3lHhWJPL21ZpSibeUeEVyoSVl7HZseUXYA6tnc5/xfNRQcr5j0VLkD9N4ow7H5kiIrCnubTF9HTMERHnLO83cCDWX381JHaNaLvxjwuF1LoMGAUsA/YBX2ut9yilXlBK3e5S9H7gS63dPvlcBWxWSu0AfgRedr3LpLrqfOfCqTXwnta6HZAD3H0R27yrte6utb4G8ANudc4h5SqlTt9yMxT4WCnlDbwDDNJadwU+Ama67Muite6mtX69QoxHgaWVBXe9AGdNQdX/k7kQZTbR572R7P1oGflH0y+8wR+QMpvo9f5I9i9Yxqm6UAd2O3v7j2Vn98cI6NQa37ZX1Go437g4vNq2peDL6l3bURPWhP+QP+4hir6cj++dD13y+Kf5D+iH91VtyP+s9q47uhBlNnHt3FEkLVhGQV1ohx6gzCZucp6PPHEs+vZzHgtfXfpjoa7QWi/RWrfRWrfUWs90LpuhtV7sUuY5rfWUCtut11q311p3dP67wIh8LpcLOg9rrbc7n28Bml3ENn2VUpMAfyAM2AP8F/g7MFQpNQ64D8ctPG2Ba4AEpRSAGUhx2ddZZy6l1ENAN+CmyoK7XoCzoPFD5xw3vmpwP9r+uS8AGTsOEdCw/JOKf3QYBanZlW7X65VHyTucyp4Fy86168tGmyH9aPmgow6yth/C37UOGoZReI46uPZVRx3s/3vV6sCakoUluvwTkCUqHGtKlnuZVEeZ0pRMMJswB/lTlp1/Udva8grIX7+L4D6dKd5/tEq52dPT3YZ2TfXrY0s/+2Rt6dqVgIceImv0aCgtrVKM88bPysAUHlkePywCe/a5/7Mo3fAj/kPHwAeGpeAYqWhQnoM5MqLSOvDp3oXAIQ+SPnysIXXQckgcLU63wx2Odnj6c7t/dBhFKZW3w66vPsqpQ6kc+PCHGsUvTc3E0rC8bXlHh1OamlmhTBaWhhGO5WYT5sAAbNn5NYrr6srB/WjjrIOM7e7no4Docx+L1892HIt7q3gsno89IwNTpEtbrF8fW0bGWeUsXboS8NDDZI152tBjodrkGzqBy2fkosTluY0LdIqUUr7A+zhGItoDHwK+ztXfAjcDtwJbtNaZgAL2aK07OR/ttdbxLrssqLD/fsA04HattWtuVbbvkxV8138a3/Wfxu8/bKHVIMecYv0uLSnNL6QoLeesbbpOHIR3kB+/PPtZTULXGYkLV7A0bhpL46Zx7IcttHDWQXiXlljzCimupA46ThqEd6AfW2ZUvQ4KdhzAt3k0liaRKG8vwu7oRU6C+7B6TsJGwu9xnGRDb7me/J93nVkedkcvlMULS5NIfJtHU7D9AF5hQZiDAgBQvhaCeneiOOlc11OdW+n+/ZgbN8YUFQVeXvjGxFCyfr1bGa9WrQgcN46cqVPROWfXTU3YDv2GKaoRpvpRYPbC0jOG0i0b3MqYGpTf4ebVqSe21Kr/nedj3fcbXk0aYY521IFfXAxFa91z8G7TitAp48icOB17tjF1cHBhAglxU0mIm8qJpZtpek9vAMK6tKI0v6jSdthu8j14B/mzfcanNY5fsOMAPs3K22Xo7b3JraRdhg2KASD0lhvI/3lnjeO6+u2TFSyOn8bi+GkcXeZ+PrLmVX4+6jJpEJZAP341+HxU+ttvmBtVPBZ+divj1ao1gePGkzPtr4YfC6JmLpeRi6o63ZHIUErVAwbhuPgSrXWxUmoZMBfHtEKdvAQAACAASURBVAbAfqC+Uuo6rfUG5zRJG631WZOHSqnOOD6nDdBap1VcXxPHVm2ncUxH7ln3OmXFVn4aV37n0Z3LZvJd/2n4R4fRafSd5Bw4wZ0/OO7i2LswgcQvVhuZyhkTn32ZTdt2kpOTR+ydDzHi0Ye5+7b+tRILIHnldhrFduT29a9jK7KyYWx5HdycMJOlcdPwiw7jmjF3knvgBDcvd9RB4scJHPx89cUFsdk5+syHtPnns2Ayk/nVCooTj9FwwgMU7EgiN2ETGV+uoPlbY7hm3VxsOfkcHOGYEStOPEb2f3+m3ap3wWbj9+nzwW7Hu0Eozd8YDWYTSimy/vczuSs3V70CbDby33qL0FdfBZOJ4qVLsR05QsDQoZTt30/J+vXUGz4c5edH8PPPA2A/eZKcadOqHqsydjtFC98hYPIrYDJjXbMU+4kj+N49hLLDiZRtXY9P/J14XdMVbGXYC/IpnPeKMbFPs9nJee0dIt5+BWUyU/DfpZQdPkLQE0Ow7kuk+Kf1BD81DOXvS9gsx/cA2VLTyJw43bAUUlduJzq2EzdvmIOtyMqmseVDM3EJs0iIm4pfdBhXj7mTvAMniFvumEVN+ng5hz9fXb2gNjvHnplPq8+eQ5lNZH61kuLEY0SP/zOFO5PITdhI5pcJNHtzLFf/NA9bTj6HR752ZvN26+djDvRHeXsR0v9akh58juIDx84d7wKOr3Scj+7+2XEsup6Pbl8+k8XxjvNRR+f56PZljmNx38cJHDDifGS3kf/2m4TOfs15LCxxHgt/oWz/b45j4cknHcfCc6ePhTRypk+teewa5S0jFwBKV+OK9ktJKdUM+J/z2gmUUhOAelrr5yopu9BZ9hul1Is4voUsFUgEfj+9jVKqJ47ORtPT9/o6r8N4GwjG0el6U2v9oVJqNTBBa73ZWW4F0J7yaZOjWmvXC2bOcr5pkUvhke0veDI8AF93mOHR+G1Npzwav0krz3+q8mnk2YHKU0keDQ/AhqPRHo3f0suz7RBgh/3S3f1VmYFtqt/hMUqDH9eo2tp30f/mGH6+97t1XK3lW1vq/MiF1voIjushTr9+7Txlh7g8nw6c66NML+Bj1y8RcV7TcWMl++xT4XW/i8tcCCGE+P+pzncujKaU+jfQEojxdC5CCCH+YGRaBLhMOxdKqfdwfNGHq7e01h9faFut9V21k5UQQggh4DLtXGitR3o6ByGEEOIsHvjJ9brosuxcCCGEEHWSTIsAl8/3XAghhBDiMiEjF0IIIYRRZFoEkJELIYQQQhhMRi6EEEIIo8g1F4CMXAghhBDCYDJyIYQQQhhFRi4A6VwIIYQQxqnjv9d1qci0iBBCCCEMJSMXQgghhFFkWgSQkQshhBBCGExGLi6BDrrAo/G/7jDDo/EB7t35gkfjr273V4/G33CwsUfjA+Qc9uxccBurR8MD0KtZikfj7zkU6dH4AH2iTno0/pH94R6ND9CgNncuIxeAdC6EEEII48g3dAIyLSKEEEIIg8nIhRBCCGEUmRYBZORCCCGEEAaTkQshhBDCKPIlWoB0LoQQQgjjyLQIINMiQgghhDCYjFwIIYQQRpGRC0BGLoQQQghhMBm5EEIIIYwiX6IFyMiFEEIIIQwmIxdCCCGEQbRdbkUF6VwIIYQQxpELOgGZFhFCCCGEwWTkwkOueOFRgmO6Yi8q4fDYdyjcfeisMv7tW9D8jacx+VrIXbWFozMWAGAOqUfLuePxaRJJybE0Dj75GrbcAgKva0erj/6K9VgaANlLfiH5za+rnFvXvz1Mo5hOlBWVsGHsfLJ3HXFbb/az0PuDp6nXLBJts3MiYRvbZ31V9Uq4CNNnzWHtzxsJCw3hu8/m1UoMgLYzhxAR2xlbUQl7np5L/q7DZ5UJ7NCcdm+PwOxrIWPlNvZPWwhAvXZNuerVxzH7eKPLbOybsoC8bQdrlM+Nzz9MU+d7sGLcfNJ3HzmrzO2fTiIgMhhlNpO8cT9rpi80bEi2/3OP0KpvR0qLrCye8AGplcR/4JNJBEaGYPIyc3TjfpY+87GhQ8Kd//YI0bEdsRVZ2Tjmg0rb4fXzn6ZeswZom53k5VvZaVA79OnZneAxo1BmEwWLl3Dq0y/c1te7fxD+tw8Emw1bTi45M1/FlmrMT5m3nTmY+s62uPvpueRX+LvB0RaveXs4Zl8L6Su3sX/aJ468rr6Cq199DHOAL8XH0tk5/F1sp4qqlYff9d0ImzwCZTKR/++l5H7kXre+XdoTNmk4ltYtSJs8k8IVP1UrzmlN//YoITFdsBeVcHDsuxTuqvyc2PLNpzD5WshZtZXfnyk/J7aeNx6fxvUpOZ7OgWGOc6I50J+W747G0rA+ystEyrzFZHy1qkZ5XpBc0AnIyIVHBMd0wad5Q3b1GsGRyXNp+tKwSss1felJjkx6n129RuDTvCHBfbsAED3yT+St28WuXiPJW7eL6JF/OrPNqY372BM/jj3x46rVsWgY05Gg5lEsvmE8v05aQI+XhlRabt+87/nfjZNYGj+N+t3b0LBvhyrHuhh3Doxj3pwXa2Xfp0XEdsK/eRQ/9xzNvgkfctXsRystd9Xsx9g3fj4/9xyNf/MowmM6AdBmxoMceu0bfomdzMHZX9P6mQdrlE/Tvh0JaR7Fp73Hs2ryAvrMGlJpuaXD3+GL/tP4vN8U/MIDaXXrtTWKe1qrvh0Jax7FezeN5/u/LmDgi0MrLfftyHeYf/NU5sVNxj88kKtvMSY+QHRMRwJbRLHk+vFsnriAri9XnsP+uUtY2nsiy+OmEtGjDVExHWse3GQiZPxoMsdN4eQDQ/GPi8GrWVO3ItbEJNKHDift4ccpXrWWoJFP1DwujrYY0DyadT3HsHfCh1w9+7FKy109+1H2jp/Pup5jCGgeTYSzLbabM4wDL37Bhj6TOLlkE81G3la9REwmwqc+xckRUzl+12MEDOiLd4sr3IqUpaaR/syrnFpa8/+sg2O64Ns8mh03jOTwpHk0f6ny+mz+8jAOT5zLjhtG4ts8muC+nQFoOOouctftZEevUeSu20nDUY5zYoMhN1OUeJzdcePYd/cMms4YjPKWz9SXQp3rXCilnlNKTfBA3GZKqT9foEy4UupHpdQppdS71Y0V0r8Hmd/8CEDB1kTMwQF4R4a6lfGODMUc6EfB1kQAMr/5kZABPcq3X+TYPnPRj4QMMO6k3rh/Vw59s86x760HsQQH4BsZ4lbGVmTl5Pp9ANhLbWTtOoJfdJhhObjq1qk9wUGBtbLv0+oP6E7KorUA5G45gFdQAJYKf7MlMgSven7kbjkAQMqitUTe3B1w/JSAV6AfAF5B/pSczK5RPi3iu7LvW8d7cHLbQXyCAvCvkA9AqfMTqcnLjNnby7DfNGgT15Wd3zo+hZ7YloRvkD/1KolvrRDfyJ9UaDSgK0cWOXLI3JqEd5B/pe0wbf1ewNEOs3cdwd+Admi5+krKjp/AlpwCZWUUrliF743Xu5Wxbt2OLilxPN+zF3Nk/RrHBag/oBvJZ9piEl5B/udpi0kAJC9aS/2buwHg3zKa7A2OYzNzzS4a3NKjWnn4XNOW0mPJlJ1IhbIyCn5YjX8f9zooSz5J6YHDYMBoVWj/HmR8sxqAUxc4J55ynhMzvllNqPPcF9q/BxlfO7bP+Ho1oc5zJVpjDnAcm+YAX8pyTqHLbDXO97zs2vjHZajOdS4qo5S6FF3NZsB5OxdAMfAMUKPOjyUqHGty5pnXpSmZeEe5nxS9o8KwppSXsaZkYokKd6yLCKE0zfEfWGlaNt4R5Sefel3b0i5hDq0/fQbfNk2qnJt/VCiFLrkVJmfhHxV6zvLeQf40iuvMyXV7qhyrrvCJDqX4RPnfXJySiW+F/6R8o8MoTskqL5OchU+0o14Sn/mE1jMeovfW92j97MMkzXQfQq+qgKhQTrm8B6dSsqh3jvfg9s8m8ei297EWFJP0/cYaxT0tMCqMPJf4ealZBDaoPP6f/zGZcVvnYi0oZt+SXw2JD+AXFebWDotSsvCLPn87bBjXhZM/7a5xbFP9CGxpaWde29IyMNc/d+fB/7aBlGwwpu59o8MqtMWsi2qLp8sU7D9+pqMRddu1+DYKr1Ye5sgIbKnpZ17b0jLwahBRrX1dDEtUGCXJGWdeW5MzsVQ4J1oqnhNdypzrnJj68RL8Wjei87YFtF/1Br/P+Kj2f1jMbjf+cRmqE50LpdQ0pVSiUmod0Na5bLVS6k2l1GZgtFIqVim1TSm1Syn1kVLKx1nuiFJqtnP5RqVUK+fyZkqpVUqpnUqplUqpK5zLFyqlBrnEPuV8+jLQWym1XSk1trI8tdYFWut1ODoZdYfzYCnYdYgdPZ5gT9w40j7+ntYfTanVsMpsotf7I9m/YBmnjqZfeIM/qMZD4kic8Qk/dRlJ4oxPuPqNJy9Z7MUPzeajbqMwW7xofEO7Sxb3tM8feYU3uo/EbPGi2fWXPj442uF1c0dxYMEyCi5xO/Tr3w/LlW3I/2ftXHNUVbvHzKPJkHh6Lp+FuZ4fdmuZp1PyDOc5MaRPZwr2HGFb50fZFTeepjMfw1zPz8PJ/f/g8cknpVRX4H6gE458tgJbnKstWutuSilf4AAQq7VOVEr9AxgOvOksl6u1bq+UesS57FbgHeATrfUnSqm/AG8Dd54nlSnABK31rQb9XU8ATwD8NbgTw0YMp/6DcQAUbE/C0rD8E4V3dDilqVlu25emZmGJLi9jiQ7HmurotZdm5OAdGerooUeGUpqZC4Dd5cKt3FVbUbOG4RUaCFnn7/m2GdKPlg/2BSBr+yH8XXLzbxhGYWrlw/zXvvooeYdT2f/3ZeevjDqo8dB4Gj8UC0Du9oNun/B8o8PdPhnC2Z8gfRuGUZLiqJfoe286c3HnycW/cPWcyq+hOZ/2g/vR7gHHe5C24xD1XN6DetFhnDrHewBgKynl8PKttIjvwrFqfnLv9kgcne93xE/eeYggl/hBUWHkn2eqx1ZSSuLyLbSN78rhddUfOWg1JI4Wp9vhDvd26BcdRlFK5Tl0e/VR8g+lkvjhD9WO7cqenoE5MvLMa3NkBLb0szstPt27EDjkQTJGjIXS0mrHazI0nkYPxQCQd1ZbDLuotni6TGFSMlvvmwWAf4to6sd1rlZOtrQMzFHlozXmyAjKTmacZ4uqazBkgNs50adhBKc/6VkahmOtcE60VjwnupQ51zkx4r4YUt79FwAlR1IpOZqGb6tGhv4dZ7lMRxqMVhdGLnoD/9ZaF2qt84DFLutOfxxoCxzWWic6X38C3OhS7guXf69zPr8O+Nz5/FOgl9GJn4/Wer7WupvWuttdAc1I+2TpmQsts5f9Svggx0k0oEsbbHmFZ4b0TitNy8aWX0RAlzYAhA/qS84yx9BrzvJNhN/j2D78nvLlXvXLp0cCOrUGk6IsO/+CuSYuXMHSuGksjZvGsR+20GKQo6rCu7TEmldIcVrOWdt0nDQI70A/tsz4rKpVUycc/3g5v8RO5pfYyaQv3UT0PY7mFNy1NWX5hVgr/M3WtBzKThUR3LU1ANH33Ej6D5sAKEnNJvT6qwEI630NhYdSq5zPrk9W8OWAaXw5YBqHlm3hqrsd70GDzi2x5hdSWCEfb3+fM9dhKLOJZrGdyE5KqXLc0zb/I4EPB07lw4FT2b98Mx3u7g1Ao86tKM4v4lQl8eu5xG8V05mMg8nVjg+QtDCB5XFTWR43lRNLN9PsHkcO4V1aUZpfVGk7vGbyPXgH+bNtxqc1iu3Kuu83vJo0whwdBV5e+PeLofinDW5lvNu0ImTSODInTseefXZeVXHs4+X8EjuFX2KnkLZ0Mw3PtMVWF2iLrQBoeM+NpP+wGQBLRJCjkFK0GHsXxz5ZUa2cSvbsx/uKRng1ctRBwIA+FK7ZcOENq+Dkwh/YHTee3XHjyf5hIxGD+gBQ7wLnxHrOc2LEoD5kO8992cs3EXGvY/uIe8uXW0+kE9TbcbG5V0Qwfi0bUnLUmLt6xPl5fOTiAgouspw+x/PKlOHsVCmlTIClGnnVSO7KLQTHdKX9z3Mdt6KOe+fMunbL57AnfhwAv0/9oPxW1B+3krtqKwAp7/2LVvMmUP+BWEqOp3PwydcACLvlOiIfGYC22bAXWzk04vUq55a8cjuNYjty+/rXsRVZ2TB2/pl1NyfMZGncNPyiw7hmzJ3kHjjBzcsdd3IkfpzAwc9XV7NGzm3isy+zadtOcnLyiL3zIUY8+jB339bf0BgZK7YREduZG359C1uRlb2j555Z13PlK/wSOxmA3yYvoN3bIzD5epOxcjsZK7cDsG/8B7R9cQjKy4y9xMreCfMrjXOxjqzaTtOYjjyy7nVKi6ysHF++v/t/mMmXA6bh5e/DrR+Nw2zxQpkUx9fvY9dnK2sU97SkVdtp1bcTI9fOocx5K+ppjy+ZxYcDp2Lx9+G+v4/DbPFGmRRHNuxli0HxAVJWbic6thO3bHDksHFseQ7xCbNYHjcVv+gw2o25k7wDJ4hfPtOR+8fLOfT56poFt9nJef0dIt58BUxmCv63lLLDRwh8fAil+xIpXreeoFHDUP6+hM181rHJyTSyJk2vWVxOt8VO9Pr1Lcdt0aPLb7/uufJlfol1THXum/wR17w9HJOvxa0tRt11A02GxgOQtmQjyV+srl4iNjuZL71L1NyXwGQi/7tllB78nZARg7HuSaRwzQYs7drQ4I3nMAXVw/+mnthGPMKJPz1erXA5K7cQEtuFjuvfx15UwqGx5dfLX5PwOrvjxgNw5K/zaXH6VlTXc+K7jnNi5P2xlJxI58Awx7nvxJuLaPnmU7Rf+QYoxdGZn1KWdeEPXDVS29d0XCaU9nBFKKW6AAuBaymfFvkAx9TGBK31Zue0SCIQo7VOUkotBLZprd9SSh0B5mmtX1ZKPQTcp7W+TSm1GFiktf5UKTUEuENrfZdSajoQqLWerJS6E8eoiXJOz8zRWt90ETkPAbpprUddzN+4qdFdHq3kRB3gyfAA3LvzBY/GX93urx6N/5vF26PxAXJMnj3W21g9Gh6AXs2qP7pjhD2HIi9cqJa1jsq8cKFalJZeu3d/XYxrk/+lamvfhXMeN/xA8x/3Ya3lW1s8PnKhtd6qlPoK2AGkAZsqKVOslBoKLHLeObIJcP1GpVCl1E6gBHjAuewp4GOl1EQgHTh9o/yHwH+UUjuAHygfHdkJ2JzLF2qt36gsX2dnJgiwODsn8VrrvdX764UQQog/Ho93LgC01jOBmRUWv1ahzErgXFcnvaq1nlyh/O9ATCWxTgI9XRZNdi4vrax8Jds3u1AZIYQQ/09dpt9LYbS6cEGnEEIIIWpAKTVAKbVfKZWklDrrewiUUkOUUunOr1vYrpR6zGXdYKXUAedjsBH51ImRi5qojZEEpVR/4JUKiw9rre8yOpYQQog/EA/8tohSygy8B8QBx4FNSqnFlUzZf1XxWkGlVBjwLNANxw0RW5zb1uirhi/7zkVt0FovAy6/L28QQgjx/1EPIElrfQhAKfUlcAdwMdcD9gcStNZZzm0TgAGUf8VDtci0iBBCCGEUz/y2SCPgmMvr485lFd3t/Nbqb5RSp38f4mK3rRLpXAghhBAG0Xa74Q+l1BNKqc0uj+r8DO9/gWZa6w5AAo4vo6w1Mi0ihBBC1GFa6/nA+b6d7wTg+kuVjZ3LXPfh+gUnfwdmu2zbp8K2q6uZ6hkyciGEEEIYxTPTIpuA1kqp5kopC47f63L9KQ2UUtEuL28H9jmfLwPilVKhSqlQIB4DrjmUkQshhBDiMqa1LlNKjcLRKTADH2mt9yilXgA2a60XA08rpW7H8RMYWcAQ57ZZSqm/Uf4Fli+cvrizJqRzIYQQQhjFA7eiAmitlwBLKiyb4fL8r0Clv4Ogtf4I+MjIfKRzIYQQQhhFvqETkGsuhBBCCGEwGbkQQgghjGL3zLRIXSMjF0IIIYQwlIxcXALeXjaPxm9rO+XR+ACr21V6HdEl02fPSx6NH9V9tEfjA/xUFuzR+EV14KOMl69nj8UAVebR+ADFhd4ejW/TyqPxa51ccwFI50IIIYQwjofuFqlr6sBnCSGEEEL8kcjIhRBCCGEUmRYBZORCCCGEEAaTkQshhBDCIFpuRQVk5EIIIYQQBpORCyGEEMIocs0FIJ0LIYQQwjjSuQBkWkQIIYQQBpORCyGEEMIo8iVagIxcCCGEEMJgMnIhhBBCGEWuuQCkcyGEEEIYRkvnApBpESGEEEIYTEYuhBBCCKPIyAUgnQuPC7ypC42efQxlNpP55XLS5n7rtl5ZvLhizlj827eiLDuP30e9ivV4GvV6daLhlEdQ3l7o0jKSZy3k1PqdFxUzqE9nrnj+MTCbyPgigdT3/nVWzOZvjsG/Q0vKsvM5NPw1rMfTAIgaeTcRD/QDm52jMz4kb812lI83V347E2XxRpnNZC9ZT/LrX1apHtrOHEJEbGdsRSXseXou+bsOn11XHZrT7u0RmH0tZKzcxv5pCwGo164pV736OGYfb3SZjX1TFpC37WCV4p/P9FlzWPvzRsJCQ/jus3mG7ddVvRu70PDZx8FkIvurBNLnfeO2Xlm8aPz6OPyuaYktJ5+jo2ZTeiLtzHrvhvVpvfw90t76gowP/13jfHo9/zBNYzpRVlTCynHzydh95Kwyt346Cf/IYExmMykb97N2+kJDh4R7vPAwjZ05rBs7n6wKOZh9LfSZ/zRBTSOx2+wcT9jGlpe+MiS2pXsPAkc9BWYTRd9/T+EXn7ut97/nXvwG3oK22bDn5pA3+xXsJ08aErv5i38hNLYz9iIrB0a/S0Elx0JAhxa0fmskJl8L2Su3cXj6RwBcMel+wgZ0R9vtlGbkkTT6Xawnsy86dkDvrjSYPgxlNpHz9TIy5y9yW68sXjScPQHfa1phy8nnxOiXzrRDn7bNiPrbU5jr+aPtmiN/Go22llavDv72F0Jiu2AvspI05p1z1kGrN0dh8rWQs3Irh59x1EGTSfcT1r8H2O2UZuZyYPS7lFahDoQx6ty0iFLqOaXUBA/EbaaU+vMFysQppbYopXY5/42pUVCTicZ/G8ahwc/zW7+RhN5+Iz6tm7gVCbsvDlvuKfbdNIz0BYuJnjIYAFt2Hof+8iL7+z/N0XFvcsUbYy865hUvDiPx4RfY0/cpwu7ojW/rxm5FIu6Poyz3FLt7Defkh4tpPPURAHxbNybsjl7siXmKxIee54qZT4LJhC4pZf+9M9gbP5a9/ccS1KcLAV3aXHQ1RMR2wr95FD/3HM2+CR9y1exHKy131ezH2Dd+Pj/3HI1/8yjCYzoB0GbGgxx67Rt+iZ3Mwdlf0/qZBy869sW4c2Ac8+a8aOg+3ZhMNHzhSQ4PeY4D8SMJvv1GfFq5t4PQe+Ox5Z4ise8wMhb8h6gpQ9zWR09/lFNrthiSzhV9OxLcPIp/9h7P6skLuGnWkErLLRv+Dl/3n8aX/abgGx5Iy1uvNSQ+QKOYjgQ1j+JfvcazYfICrnup8hz2zPuef980if/2n0Zk9zY06tuh5sFNJgJHjyFnyiQyhwzGNzYWc9OmbkVKDxwg88knyHrsL5SsWUPgsCdrHhcIje2MX4totl73FEkT5tHylScqLdfylcdJGj+Prdc9hV+LaEJiOgNw4v3/sD1mPDv6TSQ7YQtNxt1z8cFNJqKeG8Gxx2Zw8OYnCbr1JiwV2mHIoP7Y8k5xsN9jZH38byIn/sWxwmyi4WsTSZ3xLocGDufoQ5PRZbZq1UFITBd8W0Sz7fpRHJw4lxYvV14HLV5+goMT5rLt+lH4utRB8vv/YUfsOHbETSCrqnVgBLvd+MdlqM51LiqjlLoUIyzNgPN2LoAM4DatdXtgMPBpTQL6d2pNyZEUrMdOokvLyP7vTwTHuZ+gg+OuJevbVQDkLPmZwBs6AlC05xBlaVkAFCcexeRrQVkuXE0Bp2MedcTM+s86QuLdY4bE9yBz0Y8AZH+/nsBeHZzLryXrP+vQ1jKsx9IoOZJCQKfWANgLiwFQXmaUlxn0xX+CrT+gOymL1gKQu+UAXkEBWCJD3MpYIkPwqudH7pYDAKQsWkvkzd0BRyivQD8AvIL8KTH4U0q3Tu0JDgo0dJ+u/Du2xvp7CqXOdpD737UEVWgHQXHXkvPtSgByl/5Mves7uqzrifXYSYoTjxqST/P4ruz/dh0AJ7cdxBIUgH+F9wOg9FQRACYvM2Zvryq95xdyRf+uHPzGkUP61oNYggPwq5CDrdhK6vp9ANhLbWTuOoJ/dFiNY3tfeRW25BPYUlKgrIziVavwuaGXW5nS7dugpMTxfO9eTPXr1zguQFj/7qR9vRqAU1sP4BXkj3eFv9s7MgRzPX9ObXUcC2lfryZ8gONYsDnfEwCTvw+ai39P/Dq0wfp7MqXHUqG0jLzv1xIYe51bmXr9epL7rxUA5P2wDv/rHO0woFcXSvYfpuQ3xwiDLSe/2v8phg3oTvqiNcDpOgiovA4Cy+sgfdEawgb0cMR2qQOzvw9VqAJj2LXxj8tQnehcKKWmKaUSlVLrgLbOZauVUm8qpTYDo5VSsUqpbc5Rg4+UUj7OckeUUrOdyzcqpVo5lzdTSq1SSu1USq1USl3hXL5QKTXIJfYp59OXgd5Kqe1KqUqHAbTW27TWyc6XewC/03lUh3dUOKUpGWdel6Zk4B0VfnaZZGcZmx1bfgHmUPf/6IIHXk/R7oNoa9kFY1qiw7C6xLSmZmKpcEK2RLmUsdmx5RXiFRp4/m1NJq5e9gYdd3xC3k87KNh24IK5nOYTHfp/7N13eFRV+sDx7zsz6SQhCaRQhEhzAaXzQwWkg9hFrKggVixUhRUVdMXKWldFVBRX14JlZVU6i0iRXgUh9JYE0nsmM3N+f8yQZEKAkEwIuO/nefIk995z7/vO3HsyZ845d4aCw6nFywWJqQSWySkwLpKCxLSS55kv5wAAIABJREFUMkfSCIiLAGDn0zNp9swQuq1/h2aT7mTXlC8qHPtcYCt7HSSlnngdxER5n5PsXKwRYViCA6n74CCOvum7xxwSG0HOkZLzkZuYRkhsRLllr/7sCYZueBd7bgG7f1rtsxyCYyPILZND8ElyAPAPC6Zh33YkLvu9yrEtdergOloy5OQ6dgxrnTonLR80cCD2VauqHBfAPy6KwlKPuzAxjYA472shIC4Ke2JJGXtiGv6lylww4TY6rptG3UHdOPBKxYeJbLFROLyuwxRsMd6xbTFRFCUdcy84Xbhy8rBGhOEfXx8MNJzxN+L//RaR991EZfnHRlJ4pCSPwsRUr8cH7ufJ7vU8peIfW/I/44IJt9Nh7fvUvbE7B149syFa5Rs13rgQkQ7ArUBbYCDQqdRmf2NMR+Ad4BPgFk+vgQ14qFS5TM/6fwBveNa9Dcw0xlwCfA68dZpUJgC/GmPaGmNer0Dqg4D1xpjCkzyu+0VkrYis/TZnfwUOVzmBzRpSb8LdHPzru9UWo0JcLrb1H83mTvcS0rYZgS0uOGuhGwzty85nZvJr+4fZ+cxMWr7umy7q80H0qNtJmfFDcc/R2fbjkFeY2fERrP426l/eqkZyEKuF7u88zPYZ88g5cOysxg7s0xdbixbkfnXuvIAdeOkL1nZ4kGPf/krcPQPOSkyxWgnq0JIjY19l362PE9r30uJejZpw4KV/sa7jAxz7bilxw648u8G15wI4NyZ0dgO+N8bkAYjI7FLbjje7WwB7jTE7PcszgYcpaUh8Uer38YbBpcCNnr//Cbziq4RFpBXwMtDvZGWMMdOB6QAbG11b7tVRlJSKX1zJOyK/uDoUJaWeWKaeZ73VgjU0BGd6trt8bBSNpz/JgTFvYD+QVKHc3e9ySmL6x0ZhL9UjAGBPcpcpSvTEDAvGkZ5doX2dWblkr9hCeI92FOw4eTd9g2H9aDCkNwCZG3cTWL/knUlgXJRXLwVAQWKaV29GYL1IChPdwx9xN19RPLkzefZvtHztgYo8FecMR9nrIDbqxOsgORX/uDo4vK6DLILbNif8ysuInTAUa1gIxmUwhXZSP/3pjHJofXcfWt7WE4Cjm/ZQq17J+QiJiyQ36eRDTc7CIvbNX098v/Yc+nXrGcUt7aK7+9D8DncOKRv3EFImh7yT5HDZK8PJ2pvEtg/nVTp2aa6UFCzR0cXLlrp1caaknFDOv30HQobcSdqox6CochMXAWKHDSDmDnddyNm4m4B6UWR7tgXERVKY6H0tlH0n7+5R9C4DcOy7X2n5+ZMcfPXrCuXhSErF5nUd1sGR7H1cR3IqfrF1i69DS61gnOlZOJJSyFuzFWd6FgC5v6wlsFVT8lZuqlDs2KEDiLmjDwA5m3YRUK9Oqecg6oTHZ09Mxb/U9REQF4U9yft/Bnieg88mcnCqbyb6qoqr8Z6L08itYDlzkr/L48DzuEXEAvifSUIi0gD4HrjLGFOlWxLyNiUQEF8P/4YxiJ+NiGu6kbXAu3s1a+FqIge5543WHng52Z47QqxhIVz48TMkvvwpuWu3Vzhm7qYEAuPj8G8YjfjZiLyuKxkLvLuzMxasJmqw+598xFWXkb18S/H6yOu6Iv42/BtGExgfR+7GBGyRYVjDQgCQQH/CurWlYNfhU+Zx6OP5/NZ7PL/1Hs+xOWuIG9wdgPAOzXBk52E/muFV3n40A0dOPuEd3HM84gZ359jcNQAUJqUTcVlLACK7tSZvT8UaWueKvM0JBDSuh18D93UQfk13shZ6n5OshauoPcj9AhR+5eXkrHRfB3tunsCObveyo9u9pMyYzbF3Z51xwwJg68yFfD1gIl8PmMjeeetoMcg9xyCmXRPs2XnklTkftuCA4nkYYrXQqHdb0nclnnHc0v6YuZDZ/SYyu99EDsxbR5Ob3DnUbd8Ee1Ye+WVyAGj3xE34hQaxetJnVYpdWtEff2Ct3wBLbCzYbAT26kXhiuVeZWxNmxE6ZiwZE/+KyTgxrzOR9PFcNvV5nE19Hidt7mqib+4BQK327rpQVOZxFx3NwJmTR6327roQfXMP0ua560JgfGxxuagBncg/TT0sLX/LTvw91yF+NsKu6k72ot+8yuQsWkX4je5GQNiAruT95r4Oc35dT2CLxkhgAFgtBHdqjX1XxecAJX0yl019x7knYc5ZTd3BV5z+OcgueQ7qDr6CtLnHn4O44nKR/c/sOfAFY4zPf85H50LPxVLgExF5EXc+1wDvlymzA2gsIk2NMbuAO4FfSm2/BfeciVuAlZ51K3APt/wTuAP41bN+H9AB+Bq4FvDzrM8GTjlrT0RqAz8BE4wxy09VtkKcLg498z4XfjoZsVpI+3ohBQkHiR1zO3mbd5G1cDWpXy2g0etj+Msv7+PIyGb/I68CUOfuq/BvHEfsY7cQ+9gtAOy+cxKO1MzTxjzw9Ac0/3wSWKykfrWQgp0HqTfuNnI37SJzwRpSvlxI/JujaL3sPZwZ2ewe8XcACnYeJP0/y2m1+B/gdLL/qengcuEXE0H86yPBakFESPtxOZmL1lb4aUhZuIE6vdtx+ao3cebb2TbyveJtXRa9zG+9xwPwx/iPaPXWCCyBfqQs2kjKoo0AbB/7Pi2eH4rYrLgK7WwbN73CsSvi8UkvsWbDZjIysuh9/RBGDL+TQdf0910Ap4sjk6YR/+mz7ltRZy2kMOEA0aPvIH9LAtkLV5P+1QIavj6G5v99H2dmDgce9VlH3An2L97IBb3acMeyv+PIt7N4bMnzefPcKXw9YCJ+wQEMnDEGq78NLMLhFdv5/bNFPsvh0KKN1O/VhhuX/x1nvp1lY0pyuHb+FGb3m0hwXCRtRl5PRsJhrp3nvptn+8cLSPhiSdWCu5xkv/UGEa9MBYuFgjk/49y3j5Bh9+DY8QeFK1ZQ68EHkaAgwic/694l+SgZTz1ZtbhA+sL1RPRuT/vf/oErv5Bdo0qGO9ssfJVNfR4HYM+ED2nquRU1Y/EG0hdtAKDRxCEENa0HLkPhoWPsfuIM6oLTRdKz79FwxvPuW1G/mY991wHqjBxCwZYEchavImPWPOpNHUeThR+6b0Ud/bL78WflkDrje+K/ewNjDLm/rCVnyZrKPQeL1lO7d3var3wHZ34hu0a/U/IcLJjKpr7umwn3/PUDmnluRU1fvIGMxetLnoMm9TCe52DP+LIvJ+pskHOhVSQiE3HffXEUOACsB64Gxhlj1nrK9Aam4m6ArAEeMsYUisg+3MMnVwKFwG3GmF0i0gj4GKgDHAOGGWMOiEgM8AMQBMwFHjbG1BIRP2AeEAV8Ut68CxF5CvgrUHq2Yj9jzNGyZUs72bDI2eJw1nwHVXpRpee9+kSP31+s0fh/dBpZo/EBfnWE12j84HPgjrormx+s0fi7tvvmrpKqiAzNq9H46TlBNRof4LLEb6W6jp11Xz+f/78P+2B+teVbXc6FnguMMVOAKWVWTy1TZhHQ7iSHeNUYM75M+f3ACZ9DYYxJBrqUWjXes76ovPJl9n0eqMYPPFBKKXVeO08nYPpazb+lVUoppdSfyjnRc1EVxpjGvj6miPTHfTdIaXuNMTf4OpZSSqk/D/1WVLfzvnFRHYwx83DPv1BKKaXUGdLGhVJKKeUr2nMBaONCKaWU8p1z4K6oc4FO6FRKKaWUT2nPhVJKKeUjOqHTTXsulFJKKeVT2nOhlFJK+Yr2XADauFBKKaV8Ryd0AjosopRSSikf054LpZRSykd0Qqeb9lwopZRSyqe050IppZTyFZ1zAWjj4qxwuaRG4zdsmlGj8QFW7m5Qo/FjO42s0fgXrXmzRuMD1L9vWI3GP/p7SI3GB9i6LbamU6hxDoe1RuOHBRXWaHx1duiwiFJKKeUjxmV8/lMRIjJARHaIyC4RmVDO9jEisk1ENovIIhFpVGqbU0Q2en5m++J50J4LpZRSyldqYFhERKzAO0Bf4BCwRkRmG2O2lSq2AehojMkTkYeAV4BbPNvyjTFtfZmT9lwopZRS57fOwC5jzB5jjB34EriudAFjzH+NMXmexd+Aah2r1saFUkop5SPG5fufCqgPHCy1fMiz7mSGA3NKLQeKyFoR+U1Erj/jB10OHRZRSimlzmEicj9wf6lV040x0yt5rCFAR+CKUqsbGWMOi8iFwGIR2WKM2V35jLVxoZRSSvlONcy58DQkTtWYOAw0LLXcwLPOi4j0ASYCVxhjim/bMcYc9vzeIyJLgHZAlRoXOiyilFJK+UgNDYusAZqJSLyI+AO3Al53fYhIO+B94FpjzNFS6yNEJMDzdx3gcqD0RNBK0Z4LpZRS6jxmjHGIyCPAPMAKzDDG/C4izwFrjTGzgVeBWsAsEQE4YIy5FvgL8L6IuHB3OLxU5i6TStHGhVJKKeUrNfQJncaYn4Gfy6x7ptTffU6y3wrgYl/no8MiSimllPIp7blQSimlfKSCcyT+9LRxoZRSSvmINi7cdFhEKaWUUj6lPRdKKaWUj2jPhZs2LmpYWI92NJh8H1gtpH6xgOR3v/XaLv42Gr8xmqCLm+BMz2bviFexHzqKtXYoF74/nuA2TUmdtZhDT1fqw9q8+HfuTOgjj4DVSv5PP5H3r395bQ8ePJigq67COJ24MjLIeuUVXMnJVY5bVvdn76RRr7Y48gtZOGY6x7buO6HMtf98gpDocMRq5cjqHfzy1CcV/vbAsmp1b0+9SfeBxUL6Vws4Nu0br+3ib6PB38cQ1LoJzoxsDjzyCkWHi28Tx69eXZrNf4ejb35BygffVyqHU3nqhddYunw1kRG1+fdn03x+/LL82nUmePijYLFQuPAnCr7zvg4C+l9LwJU3gMuJKcgn992puA7tr3LckG4diJ74AGK1kDFrHmnTZ3ltFz8bca+OI7BVU5wZ2RwZ9aL7PNisxE0ZSUDLpojNQua/F5P2/teVyqH5lKFE9W6HM7+Q7Y+9R/aWvSeUCb0knpZvjcAS6E/qog3snPgJALVaNeKiV+/DEuCHcTjZMeEjsjac+ecQ1WQOla0LfvWjab7wXQr3uD+3KW/DDo489e4ZP/bjOcQ9c787h6/nk1JeDlPHENjafR0cfPTl4hyaLXivOIf8jTs48tQ7lcpBVZ0Oi9Qki4WGzz/ArrueZXuvR4i4rhuBzRp6FYm6tS+OjBy2dXuQox/Opv6TdwNgCu0cmfo5h5//xGe5hI4cScb48aTefTeBvXphbdTIq0hRQgKpDzxA2vDhFP7yC6EPPOCb2KU06tmG2vGx/LPbWBaP/4geLwwtt9ych97mi/4T+VefCQRFhdL06v+rXECLhXrPPcjeoZNJ6Pcw4dd2J6Cp9zmIuLkfzswcdvZ8gJSPfiB2gndOcU8NJ+eXdZWLXwHXD+zLtNeer7bje7FYCL5/FNl/e4LMx+7Gv2tvLA28r4PCpQvJGjWMrDH3UvD9FwQPe9gncWMmjeDQfc+wZ+CDhF19Bf5NvM9D+OD+ODNz2NP3XtI++Z66j98DQNiAboi/H/uuGcG+G0YSccuV+NWPPuMUonq3JSg+lpVdRvLHuA9o8crwcsu1eOVeto+dzsouIwmKjyWql/vLJJs+cwd7p37D6t7j2fPK1zR9+o7zK4cq1gX7/iR2XTWSXVeNrHTDAouFes8+xL5hk9jVfwTh11xRfg5ZuST0up/UGT8QO947h91XP8buqx+ruYaFEd//nIf+tI0LEVkiIh3PoHxbERlYgXI5VcusREjbZhTuS8J+IBlT5CB99q+E9+vsVaZ2v/8j7ZvFAKT/tJzQyy8BwJVfSO6a7bgK7T7Jxe+ii3AePowzMREcDgoWLybg8su9yhRt3AiF7k+MLdq2DUvduj6JXdqF/Tqw/dtlACRv2E1AWAjB0bVPKFeUkw+AxWbF6mcDU7lei+A2zbDvT6TooPscZP5nKWF9vRsqYX3/j4xvFwGQOWc5tS5rU2pbF+wHkynYeaBS8SuiY9uLCQ8Lrbbjl2Zr9hdciYdxJbuvA/uyxfh37updKD+v+E8JCPJJ3MBLmmPff4Sig0lQ5CDrp6XU6nOpV5lavbuQ+f1CALLnLiP4Uvd5MMZgCQoEqwUJ9McUOXDm5J0Q43TqDuhE0qylAGStS8AWFoJ/mWvPP7o2tlpBZK1LACBp1lLqXtnJvdGANdT9fNjCgilMTj+vcqhqXfCFoDbNKSydw49LCe3bxatMaJ8upBfnsIwQH+egfONP27iohLbAaRsXvuQXG4X9SErxclFiKn6xUWXKRJaUcbpwZudijfD9C42lbl1cx44VL7uOHcN6isZD0FVXYV+92ud5hMRGkHMktXg5JzGNWrER5Za99rMnGL7hXey5Bez6qXK52GKjKEosdQ6SyjkHMVHYE8uegzAswYHUfXAQR9/8olKxz0USWQdnSsmQjyv1GJaoOieUC7jyesLf+xdBdz9I3odvVjmuX0wUjqSS8+BISsEv5sTz4Ej0XKNOF67sPKwRYWTPW4Yrv4Cmyz+n6ZKZpM74Flfmmb8HCIiLoOBwybVXmJhKQFxkmTKRFCamlZQ5kkZAnPv63Pn0TJo9M4TL179D00l3snvKmV8XNZlDVeoCgH/DGJr++AbxX75IcKeWFY7rdfzYKIoSS/4PORLLvw6KyrkOjufQ5D9vEv/FiwR3alWpHKqqhj7++5xzXjUuRKSxiGwXkQ9E5HcRmS8ip3rrdKeIbBSRrSLS2XOMziKyUkQ2iMgKEWnh+Sz254BbPOVvEZFaIvKxiGwRkc0iMqhUHlNEZJPn62ljqvlhn3MC+/bF1qIFuV9+WaN5zB7yCjM6PoLV30aDy8/+P5LoUbeTMuMHXHkFZz12TSuc828yH7qd/E/fJ2jwXTWaS9AlLTBOF7u6DmF3r2FEDrsRv4axZz2PBkP7svOZmSxv/zAJz8zkL68/+D+Tg+NYGn9cfg+7rh5F4vMf0vCNcVhq+aZX60xy2NF1GLuvGUnilA9p+PrZzwHAuMTnP+ej86px4dEMeMcY0wrIAAadomywMaYtMAKY4Vn3B9DNGNMOeAZ4wRhj9/z9lTGmrTHmK+BpINMYc7Ex5hJgsWf/EOA3Y0wbYClwX3mBReR+EVkrImu/y9lXbnJFSan41yt5V+gXF0VRUmqZMmklZawWrKEhONOzT/GQK8d17JjXMIelbl2cpXoyjvPv0IGQIUPIePJJKCrySeyL7+7DrXOncOvcKeQdzaBWvZJ3KrXiIslJOnnXrrOwiL3z13Nhv/aViu1ISsUvrtQ5iC3nHCSn4h9X9hxkEdy2ObEThtLi1w+pc8+11B0xmKi7rqpUHucKk5aCtU7JfAVLVF1cqSknLW9ftgi/ssMmlVCUnIottuQ82GLrUJR84nmwxXmuUasFS2gwzvQswq7pQe6v68DhxJmWSf76bQS2blahuA2G9aPzopfpvOhlCpMzCKxfcu0FxEV59RAAFCamefUkBNSLpDDRfX3G3XwFxzw9aEdn/0ZYuybnTQ5Qtbpg7A6cGe7/SwVbd2M/kERAfP0Kxy4+flIqfnEl/4dsceVfB37lXAfl5eBfiRyUb5yPjYu9xpiNnr/XAY1PUfYLAGPMUiBMRGoD4bi/uGUr8Dpwsre8fYDiGUHGmOOvcHbgx9PFN8ZMN8Z0NMZ0vLFW+SnmbkogoHEc/g2jET8bEdd2I3OBd/d+xoLVRN7UC4CIqy4ne/nmUzzcyivasQNrgwZYYmPBZiOwVy8KV6zwKmNr2pTQMWPIePJJTEaGz2JvmbmQLwdM5MsBE9kzbx1/GeR+sYpp1wR7dh55R71j+QUHFM/DEKuFxr3bkr4rsVKx8zYnENC4Hn4NYhA/G+HXdCdrofc5yFq4itqDegMQfuXl5Kx0n4M9N09gR7d72dHtXlJmzObYu7NI/fSnSuVxrnAk/IElrgGWaPd14N+1F0VrlnuVscSV/MP263AprsRDVY5bsGUn/p7zgJ+NsKu6k7PoN68yOYtXEX6D++sRQgd0Jc9zHoqOHCW4i3vcXYICCGp7EfY9BysU99DH81ndezyre4/n2Jw1xA7uDkBYh2Y4svOwl7n27EczcOTkE9bB3XiJHdydY3PXAFCYlE7ty9zDARHdWpO3J+m8yQGqVheskWFgcb+c+DWMIaBxPewHKh77uPzNO71zuLo72QtXeZXJXrSKiOIcupJ7khz8G9ejqBI5VJUOi7idj7eiFpb62wmcqt+r7Cw/A/wN+K8x5gYRaQwsOcP4RcYUzx50UpXn0Oni4NPTafrZZMRqIfWrRRTsPEjc2NvJ27yLzAWrSf1yAY3fGE3LX6fhzMhm78NTi3dvtWI61tBgxM9G7f7/x647JlOQULF/qifm4iT7zTeJePVVsFgomDMH5759hAwbhmPHDgpXrKDWQw8hQUGEP/ssAK7kZDImTqz0wy/PvsUbadSrDXct+ztF+XYWjS25xfbWuVP4csBEbMEBXD1jDFZ/G2IRDq3YzpbPFlUuoNPFkUnTiP/0Wfetb7MWUphwgOjRd5C/JYHshatJ/2oBDV8fQ/P/vo8zM4cDj77io0dbMY9Peok1GzaTkZFF7+uHMGL4nQy6pn/1BHM5yfvgDUInTXXfirroZ5wH9xF02z04dv1B0ZoVBA68EdslHcDpwOTkkPvWi1WP63SR/Nx7NPzoebBayPxmPvZdB6jz2BAKtiaQs3gVmbPmEffqOC5c8CHOzGyOjH4ZgPTPfyTuxdHE//QeiJD57QIKd+w74xRSF26gTu92XLrqTVz5draNfK94W+dFL7O693gAdoz/yHMbqB+pizaSusj9Xmf72Pdp/vxQxGbFVWjnj3Fnfnt4jeZQhboQ0rk1MaPvwDgc4DIcfuodnJWY94LTxZHJ02g88znEYiF91gJ3DqM8OSxaTfpX82nw2liaLZ6OMzOHg4+9XJxD9Kg7MA4nuFwcqWwOyifEVHKWfU3wNAZ+NMa09iyPA2oZYyaXU3YJ8Icx5kER6Qq8Z4y5WES+Bz4zxnwrIpOBocaYxp45FdcaY+727P8SEGiMGeVZjjDGpItIjjGmlmfdTcDVxpihp8p7fcPravRJrt8ksybDA/D17gY1Gr+HrWafg4vWVH3SY1Vl3zesRuMf/T2kRuMDHM48O3fdnMuig8/8ThpfEqn515zWe36stokMhy/t5fMHWH/l4vNu4sX5OCxyJgpEZAMwDTh+w/grwIue9aV7Hf4LtDw+oRN4HojwTAbdBPQ8m4krpZQ6/+iwiNt5NSxijNkHtC61PPUUZXucZP1KoHmpVU951qcBncoUv7uc/WuV+vsb4JuyZZRSSqn/ZedV40IppZQ6l52vt4762nnfuBCRd4DLy6x+0xjzcU3ko5RSSv2vO+8bF8YYH3yxgVJKKVV159E9EtXqvG9cKKWUUucKHRZx+7PfLaKUUkqps0x7LpRSSikf0Z4LN+25UEoppZRPac+FUkop5SM6odNNey6UUkop5VPac6GUUkr5iM65cNPGhVJKKeUjxmjjAnRYRCmllFI+pj0XSimllI+cr99i6mvauDgLatfOr9H4AfVrvoMqY2/NTqH+1RFeo/Hr3zesRuMDhH5Qs1+3E/jFSb/E+KyZNPVIjcZ/r316jcYHmL6+YY3G71GUV6Px1dmhjQullFLKR1w65wLQxoVSSinlMzqh063m+8uVUkop9aeiPRdKKaWUj+jnXLhpz4VSSimlfEp7LpRSSikf0e8WcdPGhVJKKeUjOizipsMiSimllPIp7blQSimlfEQ/58JNey6UUkop5VPac6GUUkr5iH6Ilps2LpRSSikf0btF3HRYRCmllFI+pT0XSimllI/ohE437blQSimllE9pz8U5JOjyjkSNfwixWsj6bi6ZH33ltT2ww8VEPfEg/s0v5OgTL5C74Fef52C7pBNBdz4CFgv2JT9T+J8vvLb7976GgL7XgcuFKcgn76PXcB3e79Mc+k++i6Y921CUb2f2uPdJ2rrvhDK3zXyC0OjaWGxWDqzewZynP8a4fDfY2fXZO2nUqy2O/EIWjZlOSjk5XP3PJwiODsditZK4egdLn/rEJzn4tetM8PBHwWKhcOFPFHz3L6/tAf2vJeDKG8DlxBTkk/vuVFyHfHsOynrqhddYunw1kRG1+fdn06o1FsDy/am8+utOXMZwfct63NOh8Qll5ickM231HkSE5lG1eLF/a5/mMHTyvbTr2YHC/ELeG/cWe7fuOaGM1c/GPc/dT8surTAuw5dTP2f1nJU+iX8uXAd9Jt9Jk55tKcov5Kdx00kupx7cPPMJakWHIzYrh1bvYP7TVa8Hjf42nIhe7XHmF7J79D/I23Licx9y8YU0eeNRLIH+pC9ez/6nPwLggqfvIqJvR1x2B4X7k9k9+m2cWXlVyudM6IRON+25OFdYLNSZ+AhJIyZy8Lr7qHVlD/wuvMCriCPxKMeenkrOz4urJwexEDR0JLmvTCD7iWH4X9oLS/1GXkXsKxaRPeFesp+8n4IfvyLojod8mkLTnm2IjI/lnSvG8tNfP2Lg88PKLfftw28z/conmdZ3PMFRobS86v98lsMFPdsQHh/L593GsmT8R1zxwtByy8176G2+7j+RL/tMIDAqlCZX+yAHi4Xg+0eR/bcnyHzsbvy79sbSwPscFC5dSNaoYWSNuZeC778geNjDVY97GtcP7Mu0156v9jgATpfhpV928I9r2vLt7V2YuzOZ3Wk5XmX2Z+QxY90+PhnUkW9v78Lj3Zr7NIe2PTsQGx/HyCse4oO/vsvw5x8st9yNj9xEVmoGo3s+zNg+j7L9t62+SeAcuA4u7NmGiPhY3r9iLHP/+hH9nx9abrl/P/w2M66cyEd9JxAcFcpFVayLtXu1Jyg+jo2XP8zeJ6Zx4Yv3l1su/qUH2PP4e2y8/GGC4uOo3bMdAJlLN7Gp5yi29BlDwZ4j1H90UJXyOV+IyAAR2SEiu0RkQjnbA0TkK8/Rh/VPAAAgAElEQVT2VSLSuNS2v3rW7xCR/r7Ix6eNCxFpLCJVql0i0kNELvNVTp5jThaRcb48pq8FXNyCogNHcBxKAoeD3Dm/ENLT+2lwHEnGvnNvtU1Htja5CFfyYVzHEsHpwP7bYvw6lDkV+SXvACQgEPBtLs37dmDzt+4emcMbdhEYFkyt6NonlLPn5ANgsVmx+tl8+pTE9+vAjm+XAZC8YTf+YSEEl5NDUZkcfJGErdlfcCUexpWcCA4H9mWL8e/c1buQ1zkIqnLMiujY9mLCw0LPSqytyVk0DA+iQXgQflYL/ZvFsGRPileZ738/zM0XNyAs0A+AyGB/n+bQqW9nln67BICEDTsJCQuhdnTECeV63NyHf7/zLQDGGLLTs30S/1y4Dpr17cBWTz04smE3AWEhhFSoLlatHkT078yxb5YAkLN+J9bwEPzKPPd+0RFYQ4PIWb8TgGPfLCFigLtRk/nLJnC6AMhetxP/uKgq5XOmjPH9z+mIiBV4B7gSaAncJiItyxQbDqQbY5oCrwMve/ZtCdwKtAIGAO96jlcl5+KwSA8gB1hRw3mcVbboOjiSjhUvO5KPEXDJRWc1B0tkHVypR4uXXWkp2Jr85YRy/n2vI+DKwYjNRs6UsT7NITQ2kqwjqcXLWUlphMZEkHM044Syt386nnptm7B7ySa2/7zKZzmExEaQUyqH3MQ0QmIjyCsnh6s/e4LoNk04sGQTu39aXeXYElkHZ0qpc5B6DFvzE89BwJXXE3jtzWDzI/uZUVWOey45mltATGhg8XJMrQC2Jmd5ldmf4X5hHfrNWlzG8EDnC7m8ke9eRCJiI0k9UtKgSU1KJTImkoyj6cXrgsNCALh53O206tKa5P1JzHhmOpkpmVWOfy5cB6GxEWSXqgfZnrqYW049uPnTJ4rr4o6fq1YP/GMjsZd67u1HUvGPjaSo1HPvHxuJPTH1hDJlRd/Wi9QfllcpnzNVQxM6OwO7jDF7AETkS+A6YFupMtcBkz1/fwP8Q0TEs/5LY0whsFdEdnmOV6XxveoYFrGJyOcisl1EvhGRYBHpICK/iMg6EZknInEAIvKYiGwTkc0i8qWnm+ZBYLSIbBSRbmUPLiLhIrJfRCye5RAROSgifiJyn4isEZFNIvKtiARXJOGT7SciMSLyvWf9puM9KiJylyfnTSLyz5Mc834RWSsia79IO1SZ5/GcZV/wA9ljhpD/5XQCrx9SY3n8666Xeb3Tw1j9bTS+rFWN5PDjkFeY2fERrP426l9+9nIonPNvMh+6nfxP3ydo8F1nLe65wukyHMjM54Mb2vNi/9b87b/byS4sOqs5WK0W6tSrw851fzDhqrHsXL+DIRPLH8arLufKdfD1Xa/wdqdHsPnbaFRDdbGseo8NwjhcpHy3tKZTqbLSryeen7JjRfWBg6WWD3nWlVvGGOMAMoGoCu57xqqj56IFMNwYs1xEZgAPAzcA1xljjonILcAU4B5gAhBvjCkUkdrGmAwRmQbkGGOmlndwY0ymiGwErgD+C1wNzDPGFInId8aYDwBE5Hnc3UBvVyDnk+33FvCLMeYGTzdRLRFpBTwFXGaMSRGRE5vL7jynA9MB9lzc77QdW46jKdhi6xYv22Lq4kxOPcUevudKS8ESFV28bImsgyv92EnLF638L8HDRsH7VYvb8a6+tLu1JwBHNu8hrF7JO9Cw2Eiyk9NPtivOwiJ2zl9Hi34d2Lus8iNyre/uQ8vb3Dkc3bSHWqVyCImLJDfp1Dnsm7+e+H7tOfRr1cbcTVoK1jqlzkFUXVypKSctb1+2iOAHRlcp5rkmOiSQ5OyC4uXknELqhgR4l6kVyMUxYfhZLdQPC6JR7WAOZOTTKsav0nH73XUlvW/tB8DuzQlE1atTvC0qNoq05DSv8tnp2RTkFbB6zm8A/PbTCnre0qfS8Uurqeug/V19aOOpi4mb9xBaqh6EVqAuJsxfT7N+7dl3hnUxZugAou/oC0DOxl34l3ru/etFYU/yfu7tSWlewx1ly9S9uScRfTqy/ZZJZ5SHL1THhM7Sryfni+rouThojDneD/UZ0B9oDSzwNAqeAhp4tm8GPheRIYDjDGJ8Bdzi+ftWzzJAaxH5VUS2AHfgHkOqiJPt1wt4D8AY4zTGZHrWzTLGpHjWp5V3wDNVuHUHfo3qY6sfCzYbIVdeQe4S38w6ryjnnj+wxNbHUjcWrDb8u/SiaJ13DpaYkgatrW0XnEmHqxx37acL+GDgk3ww8El2zF/LJYPcHVb12zWlIDv/hCERv+CA4nkYYrXQtFc7UnYfqVIOW2cu5OsBE/l6wET2zltHi0Hu8e2Ydk2wZ+edMCRiCw4onochVguNerclfVdilXIAcCT8gSWuAZZo93Xg37UXRWu8u3UtcSXnwK/DpbgS/1w9Y61iQjmQmcfhrHyKnC7mJSTTI76OV5meF9Zl7WH3C116vp39GXnUD6vavIP5n85h/MDRjB84mjXzV9F9UA8AmrVrTl52rteQyHHrF66h5aXuu1RaX34JhxMOnlCmMmrqOlj/6UI+HjiRjwdOJGH+Olp76kG9dk0ozM47YUjELzigeB6GWC006dWW1N1nXg+SP5nLlr5j2dJ3LOlzV1P3ph4A1GrfHGdWnteQCEDR0XSc2fnUau+eyFv3ph6kz3MPx4T3aEfciOvZMfRFXPn2M87lPHUYaFhquYFnXbllRMQGhAOpFdz3jFVHz0XZd+nZwO/GmEvLKXsV0B24BpgoIhdXMMZs4AVPr0EH4PjtE58A1xtjNonIUNzzNyqisvv5jtNFygv/IHbaC4jVQvb38yjavZ+Ih++i8Ped5C35jYBWzYl5cxKW0FCCr+hCxIg7OXRD+TOpK8XlIv+TtwkZ/zJYrNh/mYPr8D4CBw3FsXcnjvUrCOh3PbbWHcDpwJWbTd60l30XH9i1eCNNe7bl4aWv4fDcinrcfT+/wAcDn8Q/OIBbPhyD1d8PsQj7Vm5j3WeLfJbD/sUbuaBXG+5Y9ncc+XYWjy15w3Dz3Cl8PWAifsEBDJwxBqu/DSzC4RXb+d0XObic5H3wBqGTprpvQVz0M86D+wi67R4cu/6gaM0KAgfeiO0S9zkwOTnkvvVi1eOexuOTXmLNhs1kZGTR+/ohjBh+J4Ou8cmk8hPYLBbGd2/BiB824DJwXcs4mkTV4t1Vu2kZHUaP+LpcdkEkKw+kcuPnK7GKMOqyptQOqnyvRVkbFq+jXc8OvLl0GnbPrajHvfzz64wf6O4l+PylT3nk9VHc/cxwstKyvMpVyTlwHexevJELe7bhgaV/pyjfzs/jSurBsJ+n8PFAdz246UN3PRCLcGDldjZUsR5kLFpH7d7tabviXVyeW1GPu3jB39nS1z3Pa+9fpxffiprx3/VkLF4PQPyUe5EAP/7ylbvXImfdTvZOqGL36hmooTkXa4BmIhKPu2FwK3B7mTKzgbtxz6W4CVhsjDEiMhv4l4i8BtQDmgFVnkAmVZ3Z63Uw95yJvbiHDFaKyIdAAnAfcKdnnR/QHNgOXGCM2edZtx/3LNfhQJgx5pT9WSIyCygAso0xIzzrUjzHSAd+Bg4bY4aKyGROMdRyiv2+BH4zxrxxfFgEd6vue+BSY0yqiEServeiIsMi1SnykjPpFKoeby+Lq9H4Ua6avff81o6+eUdbFaEffFyj8Yu+KLf6nVXDplath6uq3mt/8mGFs2X6+oanL1SNehSdvc+cOJkuR76rtn8Iv9W70ef/7yuSr4gMBN4ArMAMY8wUEXkOWGuMmS0igcA/gXZAGnBrqQmgE3FPVXAAo4wxc6qac3X0XOwAHvbMt9iGe+7CPOAtEQn3xHwD2Al85lknwFueORf/Ab4RkeuAR40xJ/ukqK+AWXj3MjwNrAKOeX5X9N65k+03EpguIsMBJ/CQp4E0BfhFRJzABmBoBeMopZRSPmeM+Rn3m+PS654p9XcBMPgk+07BPRfSZ3zauDDG7APKu39yI+7hj7K6ll1hjNkJXFKBWN/gbpSUXvcenjkSZdZPPs2xTrZfMu7bdMqunwnMPF2OSiml/rfod4u46Sd0KqWUUsqnzsUP0SrmGQcq240zy9OFU5njvQNcXmb1m8aYmh2MVkop9aeg3y3idk43Lnw9DmSMqf4vYVBKKfU/y1XTCZwjdFhEKaWUUj51TvdcKKWUUucTgw6LgPZcKKWUUsrHtOdCKaWU8hFXjX5k4rlDey6UUkop5VPac6GUUkr5iEvnXADauFBKKaV8Rid0uumwiFJKKaV8SnsulFJKKR/RD9Fy054LpZRSSvmU9lycBXm5/jUa33+Xo0bjAzS312z8/BpuRh/9PaRmEwACv5hao/H9bhtXo/EBvh3brUbjv7L/LzUaH6BRUc3eK2mz/Lnf2+ucCzdtXCillFI+8uduOlWcDosopZRSyqe050IppZTyEe25cNOeC6WUUkr5lPZcKKWUUj6iEzrdtHGhlFJK+YhL2xaADosopZRSyse050IppZTyEf3iMjftuVBKKaWUT2nPhVJKKeUjNfv5p+cO7blQSimllE9pz4VSSinlI/ohWm7auFBKKaV8xCU6oRN0WEQppZRSPqY9FzWsVvf2xD1zP1gspH89n5Rp33htF38bDaaOIbB1U5wZ2Rx89GWKDh/Fr340zRa8R+GewwDkb9zBkafeqVIuAV06UXvMI4jFQu7sn8n+9AvvXG+7iZDrBmIcTlwZmaQ//yrOpOQqxSxPu7/dRVzvNjjz7awe9T7pW/Z5bbcG+XPZ9Meo1TgG43RxZP56Nr/wlc/id37uThr0aosjv5Blo6eTtrVM/EB/ekx/jLBG0bicLg4t2MC6F6sWP6RbB6InPoBYLWTMmkfa9Fle28XPRtyr4whs5b4Ojox6kaLDR8FmJW7KSAJaNkVsFjL/vZi097+uUi7L96fy6q87cRnD9S3rcU+HxieUmZ+QzLTVexARmkfV4sX+rasU83SeeuE1li5fTWREbf792bRqjXUyLVo04aMPXqddu9Y8/czLvPb6+9UaL/CyTkSOGwFWCznfzyHrky+9tge0v5iIsSPwb3YhKX99nrxFv/o8h/Z/u4t6vdx18bfR5dfFy99/jFBPXTy8YD2bzrAuhvVoxwXP3gtWCylfLCDpne+8tou/jfg3RhF8SRMc6dnseWgq9kNHAYh9eBB1busDThcHnvmArF82luxosdDy56nYk1LZNXRKpR5/ZeiETjftuahJFgv1nn2IfcMmsav/CMKvuYKApg29ikTc3A9nVi4Jve4ndcYPxI4fWrzNvj+J3Vc/xu6rH6tywwKLhYjHR5IyagJJtw4jqF8vbPGNvIoU7dzF0bsf4uiQ+8hfvJTwR+6vWsxyxPVqQ+iFsfx82VjWPv4RHV4aVm65He/9zJxujzO/75PU6dyc2F5tfBK/fq82hMXH8l3Xsawc/xGXvji03HK/T/uJ7694gv/0n0h0p+bU73lJ5YNaLMRMGsGh+55hz8AHCbv6CvybeF8H4YP748zMYU/fe0n75HvqPn4PAGEDuiH+fuy7ZgT7bhhJxC1X4lc/utKpOF2Gl37ZwT+uacu3t3dh7s5kdqfleJXZn5HHjHX7+GRQR769vQuPd2te6XgVdf3Avkx77flqj3MqaWkZjBr9dLU3KgCwWIgc/yhHH32SI4OGEzKgJ37xF3gVcSQeJXXyK+TOXVwtKcT1akNofCw/Xj6W1U98RMcXy6+Lf0z7mZ+6P87cfk9Sp1Nz4nqeQV20WLjg+QfYeedz/N7zUSKv60ZgswZeRerc2hdHZg5buz5E8gezafDkXQAENmtA5HVd+b3Xo+wc8iwXTHkQLCUvaTHDryZ/16Ezf+DKJ85640JEeojIZacpM1lExlXy+JXe9xTHbCwiW315TICgNs0p3J9I0cFkTJGDzB+XEtq3i1eZ0D5dSP92EQCZc5YRcplvXkTL8m95EY5Dh3EeSQSHg/wFiwnq7n2aCtdtxBQWAmDfug1rdF2f51F/QAf2zXK/A0tdvwu/sGACo2t7lXHm2zm6YhsAriIn6Vv2ERwX6ZP4F/TvwO5vlgFwbP1u/MNDCCobv8BO0ortxfFTqxg/8JLm2PcfoehgEhQ5yPppKbX6XOpVplbvLmR+vxCA7LnLCL7UfR0YY7AEBYLVggT6Y4ocOHPyKp3L1uQsGoYH0SA8CD+rhf7NYliyJ8WrzPe/H+bmixsQFugHQGSwf6XjVVTHthcTHhZa7XFO5dixVNau20RRUVG1x/Jv3QLHoSM4DrvrY+68JQT1uNyrjDMxmaKEveCqnimEDfp3YN83JXXRP9z3dTGkbTMK9yViP+D+H5j2wzJq9/s/rzK1+3UmddZ/AUj/aQWhXS/xrP8/0n5YhrE7sB88SuG+RELaNgPALy6K8N4dSfnXgso9+CpwVcPP+agmei56AKdsXNQEETnrQ0R+sVEUJR4rXnYkpuAXE+VdJqZUGacLV3Ye1ogwAPwbxtDkP28S/8WLBHdqVaVcrNF1cCYfLV52Hk3BWvfkjYeQawdSsHJ1lWKWJyg2krwjqcXL+YlpBMVFnLS8X1gw9fq2J/lX37T9gmMjyC0VPzcxjeDYk8f3DwumYd92JC77vdIx/WKicCSVvIA7ksq/DhzlXAfZ85bhyi+g6fLPabpkJqkzvsWV6d3TcCaO5hYQExpYvBxTK4BjuYVeZfZn5HEgI4+h36zlrllrWL4/texhVBXZ6tbBkVS6Ph7DGh11ij18Lyg20qsu5B05dV3wCwumft/2JC2reF30j4vEnlhy7duTUvEv0zjxjy1VxunCmZWHLSL0lPs2nDycQ1Nmgjn7gxQu8f3P+chnjQsR+beIrBOR30Xkfs+6ASKyXkQ2icgiEWkMPAiMFpGNItKtAsdtIiJzPcf+VUQu8qy/RkRWicgGEVkoIjHl7HufiMwRkVdFZFSp9VNEZKSnF+VXEZkNbBMRq6fsGhHZLCIPlHPMoSLyj1LLP4pIjzN/xqrGcSyNHV2HsfuakSRO+ZCGr4/DUivorMQOHtAHv780J/sz381zqAyxWrj0vUdI+GgeuQeOnX6Haojf/Z2H2T5jHjk1EB8g6JIWGKeLXV2HsLvXMCKH3Yhfw9hqjel0GQ5k5vPBDe15sX9r/vbf7WQXVv+7eXXuEquFy959hJ01VBdLC+/dEUdKJnlbdtdoHv/rfPlu/R5jTJqIBAFrROQH4AOguzFmr4hEerZPA3KMMVMreNzpwIPGmAQR+T/gXaAXsAzoYowxInIv8AQw9vhOIvII0Be4HogDvgPeEBELcCvQGbgYaA+09uR4P5BpjOkkIgHAchGZTyXm6HiOdT/AM1EXMzjsghPKFCWl4hdX0jtgi6tDUbL3u8CiZHcZR1IqWC1YQoNxpmcB4LRnA1CwdTf2A0n4x9enYMuuM03VfayjKVhjSsbqrdF1cB478Z9EQKf2hA69g2MPjQYfdQ83HdqXC+/oCUDapj0E1yt5hxYUF0l+Ynq5+3V8dTjZe5LY+cHcKsW/6O4+NPfET9m4h5BS8UPiIslLKj/+Za8MJ2tvEts+nFel+EXJqdhi6xQv22LLvw5scXVxJHtfB2GP9SD313XgcOJMyyR//TYCWzdzD7FUQnRIIMnZBcXLyTmF1A0J8C5TK5CLY8Lws1qoHxZEo9rBHMjIp1WMX6VinsseevBuhg+/A4Brrr2TxETfT2Auj+NYCrbY0vWxLs6j1d9D1GxoX5p46kKqpy4c7xsIrnfyutD51eFk701ix4dnVhftiWn4x5Vc+/6xUdgT07zLJLnLFCW6r31rWDCO9OyT7lu7Xydq9+tEeK8OWAL8sIQGE//WKPY+9sYZ5VZZ+t0ibr4cFnlMRDYBvwENcb+wLjXG7AUwxqSdaufyiEgt3EMos0RkI/A+7oYCQANgnohsAR4HSo8L3AVcCdxkjCk0xuwDUkWkHdAP2GCMOV5TVx/P0bPtLk+sVUAU0OxM8wYwxkw3xnQ0xnQsr2EBkL95JwGN6+HXIAbxsxF+dXeyF67yKpO9aBURg3oDEH5lV3JXbgbAGhlWPHnJr2EM/o3rUXSgci8oAPbtf2BrWB9rXCzYbAT17UX+0pVeZfyaNyViwhhSH38KV3pGpWOVteuTBczv+yTz+z7J4TlraTzY3aEV1b4pRdn5FBw9MVbr8YPxCwtmwzP/rHL8P2YuZHa/iczuN5ED89bR5KauANRt3wR7Vh755cRv98RN+IUGsXrSZ1WOX7BlJ/6e6wA/G2FXdSdn0W9eZXIWryL8hj4AhA7oSp7nOig6cpTgLu75FxIUQFDbi7DvOVjpXFrFhHIgM4/DWfkUOV3MS0imR3wdrzI9L6zL2sPuF5n0fDv7M/KoH3Z2es3OtvemzaRjp3507NTvrDUsAOy/78DWsD62eu76GNK/B/m/rKj2uAmfLGBu3yeZ2/dJDs9dS+ObStXFrPLr4sVPDMYvNJj1laiLuZsSCIyPw79hNOJnI/K6rmQs8B5uzViwmqjB7gZPxFWXkb18S/H6yOu6Iv42/BtGExgfR+7GBA6/9BmbO93LlkvvZ8/Dfyd7+eaz1rBQJXzSc+EZFugDXGqMyRORJcBG4KIqHtoCZBhj2paz7W3gNWPMbE/8yaW2bQHa4m6AHG84fAgMBWKBGaXK5pZ+KMCjxhivt6Ke4ZzjHHg3ygKpLKeLI5On0Xjmc4jFQvqsBRQmHCB61B3kb0kge9Fq0r+aT4PXxtJs8XScmTkcfOxlAEI6tyZ61B0YhxNcLo489Q7OKoy143SRMfVt6rz1MmKxkvufOTj27iPs/qHYt++k4NcVhD/6ABIcSOQLk9y7JB0l9fGnKh+zHImLNhLXuy1XrXwNR76d1aNLZub3W/AC8/s+SVBcJK1GXU9WwmH6zXffYrbr4/ns+deSKsc/tGgj9Xu14cblf8eZb2fZmOnF266dP4XZ/SYSHBdJm5HXk5FwmGvnue9g2P7xAhK+qGR8p4vk596j4UfPg9VC5jfzse86QJ3HhlCwNYGcxavInDWPuFfHceGCD3FmZnNktPs6SP/8R+JeHE38T++BCJnfLqBwx75KP36bxcL47i0Y8cMGXAauaxlHk6havLtqNy2jw+gRX5fLLohk5YFUbvx8JVYRRl3WlNpB1dtr8fikl1izYTMZGVn0vn4II4bfyaBr+ldrzLJiYuqyauUcwsJq4XK5eOzR+7i4TQ+ys6tQ707G6SLt5beJfuclsFjImT2Xoj37CX/wbuzbdpK/dCX+LVtQ9++TsYTVIqj7pYQ/eDeJg+/1WQpHPHXx6hWv4cy3s6pUXRyw4AXmeupi61HXk5lwmAGeurjzTOqi08WBpz+g+eeTwGIl9auFFOw8SL1xt5G7aReZC9aQ8uVC4t8cRetl7+HMyGb3iL8DULDzIOn/WU6rxf8Ap5P9T02vtsmtZ0JvRXUT44MJLyJyHXCvMeYaz5yIjcCdwGucOCwyFggzxkw6xfEm4xk6EZEVwOvGmFkiIsAlxphNIrLBE3OdiHwMxBtjehzfF3cPyntAf2PMERHxx93o8AOaGWOcnkbJOGPM1Z649wMDgcHGmCIRaQ4cBuoCPxpjWotIV+AVoCtQH/gduNYYs+Rkj2frhVfX6PVWu27l7x7wleUH4k5fqBrlW2q2q7JLyBl33PncBY82rtH4frf59CauSgmqd9ppXtVqd+u/1Gh8gBVJJ0xPO6uaWXJPX6iadTz072r7h/Bp/SE+/39/1+HPzruxFl8Ni8wFbCKyHXgJ9wv7MdxDI995hkuOz/77D3BDRSd0AncAwz3H+B24zrN+Mu7hknVAStmdjDHLgHHATyJSxxhjB/4LfG2McZ4k1ofANmC959bT9zmxd2c57t6QbcBbwPoKPAallFLqf4ZPhkWMMYW45ziUZ06ZsjuBU37ikDFmcqm/9wIDyinzA/DDafadB8wD8Ezk7AIMLrV9CbCk1LILeNLzU1om0NpTxuBu8CillFJean5g5tzwP/EJnSLSEtgFLDLGJNR0PkoppdSfWY1+t4iITKRUT4LHLGOMTz8I3hizDbjQl8dUSimlytIJnW412rjwNCLO3jfKKKWUUqra6beiKqWUUj5yvn5ct69p40IppZTyEZ3Q6fY/MaFTKaWU+l8kIpEiskBEEjy/T/j2ORFpKyIrPd8NtllEbim17RMR2ev5+IiNIlLeh1qeQBsXSimllI+cg1+5PgH3nZLNgEWe5bLygLuMMa1wf/TDGyJSu9T2x40xbT0/GysSVBsXSiml1J/XdcBMz98zcX+ZpxdjzM7jH9NgjDkCHMX9ydSVpo0LpZRSykeM+P6nimKMMYmev5OAU37+u4h0BvyB0t9ZP8UzXPK65xvDT0sndCqllFI+Uh0TOj3fe3V/qVXTjTHTS21fiPtLOcuaWHrBGGNE5KQfxSEiccA/gbs9n1gN8FfcjRJ/YDowHnjudDlr40IppZQ6h3kaEtNPsb3PybaJSLKIxBljEj2Nh6MnKRcG/ARMNMb8VurYx3s9Cj1fElqhbyDUYRGllFLKR87BCZ2zgbs9f99NOd/J5fnW8O+BT40x35TZFuf5Lbjna2ytSFBtXCillFJ/Xi8BfUUkAejjWUZEOorIh54yNwPdgaHl3HL6uYhsAbYAdYDnKxJU3F/yqarT0tjBNfokJ4t/TYYH4LLGiacvVI1sgc4ajb912/+zd9/xUVVpA8d/ZyY9pBeSAEKoikgJBEGxkIQilnVVXF0LVXovwguKuHZEsYOoiK5l7buuCFIFaYIEEKSFXpKQ3kifOe8fdwgzKUCSCQH3+fKZD3PnnnufZ27LmXPOnamsO/TSWuhRVK/xv0naWq/xAQoSf6nX+EvaPVGv8QG6Nq/fc/HUMf8LF6pj0ae+q7Pv0XyzycNOv96PPfHJFfe9nzLmQgghhHAS+fpvg3SLCCGEEMKppOVCCCGEcMlOfNwAACAASURBVBL5bRGDtFwIIYQQwqmk5UIIIYRwEmm5MEjLhRBCCCGcSlouhBBCCCeRL3cwSOVCCCGEcBK5FdUg3SJCCCGEcCppuRBCCCGcRAZ0GqTlQgghhBBOJS0XQgghhJPIgE6DVC6EEEIIJ7FK9QKQbhEhhBBCOJm0XAghhBBOIgM6DVK5uAy0eHYQgbFRWAqKODD+bfJ2HalQpkH75rR5fTQmDzcyVsVz6IkPAWg6pT9hD8VRkp4DwJEXPiNz1fZa5dPxmUcJj+1AaUExWye8S9auow7zzZ5udF84Du9mDdEWK0nL49n1/Be1inmWe7do/CaMQZlNnPn+R/L++bnD/AYP3IfXXf3AYsGSlU3Wcy9jST7tlNgAbtFd8RkzFswmCpYsIf/zzxzme/W/H89+t6MtFqzZWeTMeQnraefEb/3cQIJiO2EpKGLvuPnkVnIc+LSPpO0bozB5uJG+ajsHZi4GoMG1Tbn65ccwubuiSy3sn/4BOdsP1TiXgbOH0qlnZ4oKipg/5Q2O7D5coYzZ1YXB/xhG227Xoq2af839lC1LN9U45oW0adOCD96bR6dO7Xhy1ku8Ou/dOotVmSeef5V1G7YQGODPvz9ZcEliXvfsozSM7YiloJj48QvILncuAlwz/X6a9L8JN39vfmgx2Gmx3a83zkXMZvL/u6TCuej9QH+87jTORWtWNlnPz6nVuXjVP4bgF9MZa0ERRya+SX4lx5zXdc2JnDcOk4cb2au3cXzWBwCY/RvQYv5k3JuEUnQihUMj5mLJPnMu1w4tueb7Fzk06hUyl9TdMSrOkW6RehYQ2wnP5uFs7T6WhCnv0vKlxyot1/KlxzgweQFbu4/Fs3k4ATEdy+adWvgD8XFTiY+bWuuKRVhMBxo0D2PpDZPZNvUDol4cVGm5/fN/5KebprKi1wyCurYmLKZDreICYDLhP3k86ZOmc/rBQXj1isGlWVOHIsUHDpI6aCQpjzxG4ep1+I4eVvu4dvF9xk8ga/rjpA8cgEdsLOamjvFLEhJIHzGMjKGDKVq7Fp/hI5wSOii2I56RYWzqNp59U96jzZwhlZZrM2coeycvZFO38XhGhhFkOw5aznqII3O/ZkvsNA7P+ZKWTz5U41w69uxMWGQ4428ZyXv/9w5Dnq38Pd4z5j5y0rOY2HM0k+PGsnfz7hrHvBgZGVlMmPjkJa9UnHV3v14sePXZSxavYWxHGjQPY2X3SeyY8j4dXqq84pC8PJ61tz3p3OAmE35TxpM+eTopfx+IZ1xshXOx5EACaYNHkProUArWrMV31PAah/OLicI9MoJdPUZxdNp8mr5Q+bqavjCCo4+/w64eo3CPjMCvZxQA4aPvIWf9Lnb1GE3O+l2Ej77H4b00nvko2Wt31Di/6tB18LgS/WkrF0qpW5VSNzhpXbOVUlOcsa7ygvtEc/rLtQDkxifg4uuNW6i/Qxm3UH9cGniSG58AwOkv1xLct2tdpENE384c++oXADLiD+Lm64VHuXwsBcWkbtwDgC6xkLXrKJ7hgbWO7db2akpPnsKSmASlpeSvXI3HzY67sDh+B7qoyHj+xx7MoSG1jnuW69XXYEk8hSXJiF+4ejXuN/ZwKFOyYzvY4pfs2YMpxDnxQ/pGk/zVOgBytp3/OMjZZhwHyV+tI+S2aGOmBrOPJwAuvl4Unc6scS7Rvbqy7pufAUjYfgBvX2/8QwMqlLv1/jj+/fY3Rnityc3MrXHMi5Gams5v23ZSUlJSp3Gq0qXjdfj5+lyyeGF9OnP8S+NczIw/iKuvF+7ljomz84pSspwa27Xt1ZSeTCw7FwtWrsbjphsdyjjzXPTv05X0r9cAcCb+AGY/b1zLHXOuoQGYfTw5E38AgPSv1+Bvuw769+lK+lfG8ulfrcG/7/VlyzUc3I/MJZsoTc+ucX7VYa2Dx5XoT1u5AG4FLrpyoZSqly4it/BAihLTy6aLktJxK/eH2i08kKKkqstEDO5L1Oq5tJ43Ehc/71rl4xkWSL5dPvlJGXiGV/zDcparrxfhvaJI+aX2n1pNIcFYUlLKpi0paZjP88fb685+FG3aUuu4ZfGDg7HaxbempmIODq6yvGe/fhT/+qtTYruHB1B4ynEfu5c7DtzDAylKyjhXJjEDd9u+OfDkR7Sa9TA3xr9Ny6ce4dBzjk3Y1REQFkh6YlrZdHpyOoENHXPx8jWOs/un/J0Xl7zCxHem4hfsV+OYoiLP8AAKEs/t78ILnIvOZA4JxnLa7lxMTcUcUvW54H1HPwo31/xccAsLotjuulOSlI5rmOMx5xoWSLHddbA4KR23sCBjXrA/JSlGhbokJRPXYP+yZfz7diPl42U1zk3UzBVXuVBK/VsptU0p9YdSapjttb5KqXil1E6l1CqlVDNgBDBRKbVDKXVTFetarJRaoJT6FZijlGqhlFpmW/8vSqmrK1nmZ6VUF9vzYKXU0bp6rxcjcfFytlw/lvjYqRSfzqL57EcvWWxlNnH9/DEc/OAnzhxPvWRxATz7xOF2dWtyP3XOWI/q8ojrhUubNpz54l/1Er+8xgN7cWDWR2yIGk3CrI+4Zp5zumuqYjabCI4I5sC2fUy/fTIH4vfz8MzKu9DEn5tnnzhcr25DXj2di5XSRmfCVU8P4eTzH5dNXwpW5fzHlehKHNA5WGudoZTyBLYqpf4DvAfcrLU+opQKtM1fAORpredeYH2NgRu01hal1CpghNY6QSl1PfAOEFOTJG0Vn2EAk32iuMuredm88EF9CH8oDoDcHQdxjwgqm+ceHkSx3adTgOKkDNzDKy9TknauqS/p05W0++f0aufaYmAvmj/UE4CMnYfxigji7OcDr/BACpIqb2Lv/PIQ8g4nk/Cecz4VWFPTMIeGlk2bQ4OxpFastLhHR+Ez8CHSRk0EJzaRW9PSMNnFN4WEYElLq1DOLaoz3g8/QsaEcbWK33hQbyIejgUgZ8chPBoFcXZvuocHObRSABQlZTi0ZrhHBFJk2zfh999SNrgz5fvNXPNq9fq/ez96G7EP9Abg0O8JBEWc+5QaFBZExmnHXHIzcynML2TL0s0AbF6ykZ5/i6tWzIsxcsQAhgwxxo/cedcjJCU5b/Du5ShyUC+a2c7FzB2H8Yw4t789znMuOpslNQ1zQ7tzMSQES2ol50KXKBoMeJj00ROqfS6EDriNkId6AXBmx0Hc7K6DruFBlCQ7HnMlyRm42V0H3cKDKE42rlQlaVm4hgYYrRahAZTYukC827egxTuTAXAJ9MEvpjO61FKtPEXNXHEtF8A4pdROYDPQBOMP+Dqt9REArXXG+RauxFe2ikUDjG6Ur5RSO4B3gfCaJqm1Xqi17qK17mJfsQBI+vCnsgGY6cu20vD+WwDwiWpFaW4+xeX6T4tTsijNK8AnqhUADe+/hbSftgI49MsH39aVM/tOVDvXQ4tXsKLXDFb0msGppb/RtL/R0BMY1ZKS3AIKK+nPvXZaf1x9vdgx65/VjleV4r37cGnSCHN4GLi44BUXQ+EvjiO7XVu3xP/xSaRPfQJrpnP7mUv27cPcqDGmMCO+R0wMRRs3OJRxadkKn0mTyZr5f+is2sU/+eFytsROY0vsNFKXbiWs/80A+HY+/3Hg29k4DsL630zqMuM4KErOxP+GtgAE3NSO/MPJ1cpl+cdLmdZvItP6TWTr8l+5+d5bAWjVqTX5uWfISqn4Ry1+5Vbadm8HQLsb23MqofrH3oXMX/ARXaJ70yW695++YgFw5MMVrImbwZq4GSQt+42r7jfOxYColpTmFjh9bEVVSvbuw6XxuXPRMy6GwvUbHcq4tG6J/7RJZDw+s0bnYspHS/mj9yT+6D2JzJ9+Jeg+o1LlHdUaS05+WTdHWU4pmVhyC/COag1A0H09yfrJ6BbNWr6VoP7G8kH9z73+e/cR/N5tOL93G07mkk0cm/Fu2by6YkU7/XEluqJaLpRStwJxQHetdb5S6mdgB1Ch+6Iazt6vZAKytNYdz1cYKOVcpcyjFnEByFgZT2BsJ6I3v4m1oJj9E94umxe18mXi46YCcHD6e+duRV29o+yukMgnH6FBu2ZorSk6kUrC1NqNpE9etYPw2I7ctulVLAXFbJ14bn29VjzPil4z8AwPpO2Eu8lJOEWv5c8Z+X24nCOf/Vyr2FisZL3yJsGvvQQmM2d+WErpkaP4PDaQkr0HKFy/Ed8xw1FeHgQ+95SxyOkUMh5/onZxz7JayH3jNQLmzAWTicKlP2I5ehTvQYMp3b+Poo0baTBiBMrTE7/ZTxuLnE4h64kZtQ6dvnI7wbGd6P7r61gLitkzfn7ZvK6rXmJL7DQA9k/7wHYrqivpq3aQvsoYAb938ru0fnYgysWMtaiYfVMW1jiX7au30alnZ15ft4Bi262oZ7304zym9ZsIwKcvfsyYeRMYMGsIORk5DuXqQsOGIfy6aSm+vg2wWq2MG/sY13W4ldzcvDqNe9bUp15k6/bfycrKIfbuhxk15BHuvbNPncU7vXIHDWM70mvzPEoLitg+4dy52HPl86yJM467a598kMZ/vQGzpxt94t/k2Gc/s2/uN7ULbrGS/eobBM2bA2YT+WfPxaGDKN63n6L1G/EbbZwLgc/ONhY5fZqMaTU7F7NXbcMvpjPXbZhv3Io66c2yedcuf5U/ek8C4NiMd8/diromnuzV8QAkvf0tLRdMIeTBWIpOpnJoxIUarEVdU/oS9kXVllLqL8BQrfWdtvEQO4BHgFep2C0yGfDVWj91nvUtBn7QWn9tm94IzNNaf6WUUkB7rfVOpdRsbF0sSqn3gW1a6/lKqQnABK11s/PlvS6sf71u5NPKrT7DA3BDs6R6je/iUb9Nobv3hNVrfICFHkX1Gv+bpK31Gh+gIPGXeo2/pJ2TKsK10LV5/Z6Lp45VvOPlUos+9V2djWSY2ezvTr/eP3f0sytu5MWV1i2yDHBRSu0FXsToGknF6Br51tZdcnZU0X+Bv55vQGclHgKG2NbzB/CXSsrMBUYqpbYDVQ+fFkII8T9HbkU1XFHdIlrrIuC2KmYvLVf2AND+AusbWG76CNC3knKz7Z7vK7fe+v8oIoQQQlxGrqjKhRBCCHE5u1IHYDrb/0TlQik1E+hf7uWvtNbP1Uc+QgghxJ/Z/0TlwlaJkIqEEEKIOiXtFob/icqFEEIIcSlcqQMwne1Ku1tECCGEEJc5abkQQgghnEQGdBqk5UIIIYQQTiUtF0IIIYSTSLuFQSoXQgghhJPIgE6DdIsIIYQQwqmk5UIIIYRwEi0dI4C0XAghhBDCyaTlQgghhHASGXNhkMrFJVCozfUav4VrXr3GB/jjcGi9xvdWpfUa/3IwPyqzXuPPOXZNvcYHWNKufn/E+Pbdz9ZrfIDbO42q1/hmU2G9xodyP6Et6oRULoQQQggnkS/RMkjlQgghhHASqVoYZECnEEIIIZxKWi6EEEIIJ5FuEYO0XAghhBDCqaRyIYQQQjiJtQ4etaGUClRKrVBKJdj+D6iinEUptcP2+N7u9Uil1K9KqYNKqS+UUm4XE1cqF0IIIYST6Dr4V0vTgVVa61bAKtt0ZQq01h1tj7vsXn8JmKe1bglkAkMuJqhULoQQQog/r78AH9mefwTcfbELKqUUEAN8Xd3lpXIhhBBCOMnl1i0CNNRaJ9meJwMNqyjnoZT6TSm1WSl1tgIRBGRprc9+C+FJoNHFBJW7RYQQQojLmFJqGDDM7qWFWuuFdvNXAmGVLDrTfkJrrZVSVfWzNNVan1JKNQdWK6V2Adk1zVkqF0IIIYST1MWvotoqEgvPMz+uqnlKqdNKqXCtdZJSKhxIqWIdp2z/H1ZK/Qx0Ar4B/JVSLrbWi8bAqYvJWbpFhBBCCCe5DLtFvgcG2J4PAP5TvoBSKkAp5W57HgzcCOzRWmtgDXDf+ZavjFQuhBBCiD+vF4FeSqkEIM42jVKqi1LqfVuZa4DflFI7MSoTL2qt99jmTQMmKaUOYozB+OBigkq3iBBCCOEkVn15fUOn1jodiK3k9d+AobbnG4Hrqlj+MNC1unGlcnEZaPPcAEJiO2EpKGL3uPnk7jpaoYxP+0javTESs4cbqau2s3+mcWdRg7ZX0fbloZi9PSg8kcrvI9/Ckldw0bF9b+1E49mPgdlE+ucrOP3ONw7zlZsLzV6biOd1LbBk5nJk1MsUn0zB7O9D83en4dWhJelfrebkk1V2B1722wAg8tnBBMR2wlpQTML4tziz60iFMt7tm9Pq9dGYPNzIXLWdI08sAuCqxx8gsG802mqlJC2Hg+Pfovh09X/evPVzAwmybYO94+aTW0kOPu0jafvGKEwebqSv2s6BmYuNbXBtU65++TFM7q7oUgv7p39AzvZD1c4BwLVTV7yGjAWTiaKVSyj89jOH+e597sL9tr+C1YIuLODMO3OxnjxWo1hV8bghmsApo8BsIu+7peQs/pdjDlHXETB5FG6tmpP2f8+Sv+oXp8YHuO7ZR2kY2xFLQTHx4xeQXckxec30+2nS/ybc/L35ocVgp+dg74nnX2Xdhi0EBvjz708W1Gmss0Y9PZLomGiKCoqYO+kVDu4+WKGMi6sLY54ZRfvu7dFWzYdzFrN+6Qan5TDi6RFlObwy6RUO7a54XLu4ujDqmVFc1/06tFXz0ZyP2ODEHET1SbdIPQuO7Yh3ZDjru01gz5T3aDtnaKXl2s4Zwp7JC1nfbQLekeEEx3QE4NpXh5Pw7OdsuvVxTv+4lWaj77z44CYTTZ4dzsFHn2ZvzBgC/nITHq2aOBQJeqAXpVl57LlpBCnvf0+jGUbXnS4qJnHup5x6dnGN3re9et0GQEBsJzybhxPffSwHpyygxUvDKi3X4qXHODh5AfHdx+LZPBz/mE4AnHrnP+yImczOuKlkrthGk0n9qxUfICi2I56RYWzqNp59U96jzZzKv6emzZyh7J28kE3dxuMZGUaQbRu0nPUQR+Z+zZbYaRye8yUtn3yo2jkAYDLhNWwCuc88Tva4Abj1iMXUuKlDkaJ1K8mZMIicSUMp/O5zvAaNrlms8+QQOG0sKWNnkHjvELz79sQ18iqHIqVJKaTPnsOZZaudG9umYWxHGjQPY2X3SeyY8j4dXqq84pC8PJ61tz1ZJzmUd3e/Xix49dlLEgsgumc0jSIjGHTTYF6b9jrjnh9TabkHxz5AVno2g28ZytCYYfy+eZdTc4iIjGDITUN4Y9objKkihwfGPkBWehaP3fIYw2OGs8uJOVSXroPHleiyqFwopSYopbzspn9USvlfotg/K6W6XIpYlQnp24XEr9YBkL3tIC6+XriFOr51t1B/XBp4kr3N+NSQ+NU6Qm4zUvZqEU7mpr0ApK/dRcPbL771yrtjK4qOJlN8/DS6pJTM73/Br7fj8v69ryfja+MCnrlkAz43tgfAWlDEma17sRYV1+BdO6rPbQAQ2CealC9/BiAvPgEXXy9cy8V3DfXH3MCLvPgEAFK+/JmgvtEADq0kJi/3Go0WD+kbTbJtG+RsS8DF17vKbZCzzcgh+at1hNxm5IAGs48nAC6+XhTVoOUEwKXVNViTTmE9nQSlpRSvX41b1x6OhQryy54qd88axTkft3ZtKD2ZSOkpI4czP/2M5603OpSxJJ2mJOEIWJ0w3K0SYX06c/xLozUkM/4grr5euIdWvCRlxh+kKCWrTnIor0vH6/Dz9bkksQBu6N2dFd+sAmDf9n14+zYgMDSwQrm+f+vDv94yWpa01uRk5jgth269u7HKLocGvg0ICK347dW9/9abL976ok5yqC4r2umPK9FlUbkAJgBllQutdT+t9aU5Y+uZR3gghafSy6YLkzLwCA+sWCYp41yZxHNlzuw/WfZHNuzO6/FoFHTRsV3DgihOTCubLklKxzUsqFyZwHNlLFYsuWcwBzj3Alef2wDALTyIosRz8YuSMnAPd1yHe3gQxUnnyhQnZeBmV+aq6Q/SZdsCQu69ieNzvqhWfGP9AQ7boCgpHfdy28A9PJAiu21QlJiBe7hxoT3w5Ee0mvUwN8a/TcunHuHQc59XOwcAFRiMJe3cnWrW9FRMQcEV873tbvzmf4bngBHkv/96jWJVxSUkmNLkczlYUlIxh1Zvn9aWZ3gABYl2x1tSBp7hlf4kw59WUFgQqYmpZdNpSakElbs+ePt6AzBg6gDe/vEtnpg/E/9g530uDAoLIs3uGpWWlEZwmOPxeDaHR6c+yps/vsmM+TOcmoOomTqrXCilJimldtseE5RSzZRS+5RSnyql9iqlvlZKeSmlxgERwBql1BrbskeVUsF2yyxWSh2wLRunlNpg+xGWKj+iKqW6KqU2KaW2K6U2KqXa2F73VEr9y5bDd4Cn3TLzbd9Q9odS6mm7148qpV6w/aDLb0qpKKXUT0qpQ0qpEXW1DS/G7gkLaDKwN92WP4+5gSfW4tILL/Qnczlsg+Mvfs5vnUeQ+s0vhA/ue8njNx7YiwOzPmJD1GgSZn3ENfPq9rAsWvpvskf+nYKP38Wz/6N1GktcvsxmMyERIez5bQ+j+41hb/xehj3xWL3ksPe3vYztN5a98XsZ+kTlXauXwmX42yL1ok4GdCqlOgODgOsBBfwKrAXaAEO01huUUouAUVrruUqpSUBPrXVaJatrCfQHBgNbgb8DPYC7gBlU/T3n+4CbtNalSqk44HngXmAkkK+1vkYp1R6It1tmptY6QyllBlYppdprrX+3zTuute6olJoHLMa4D9gD2A1UGF1l/41q43260M+zRdm8JoN60+jhGABydhxy+KRd/hM6VPwk7xFxrkz+wUTi//Y8AF7Nwwnp1amKzVFRSXI6bhHnPgW4hgdRkpxerkwGbhHBxutmE2YfbyyZuRcdoyr1vQ3CBvWl4UPGAOq8HYdwjwji7LsyWggct0NRUrpDS4VbeKBDS8ZZqd/+QttPZ3Di5S8vmEPjQb2JeNjI4ew2OPt1eO7hQQ6tFEYOGQ6tGe4RgRQlGd0f4fffUja4M+X7zVzz6vALxq+MzkjDHBxaNm0KCsGaXtlpaShevwqv4RNrFKsqpalpuISdy8EcGoIlpeK2drbIQb1o9lBPADJ3HMYzwu54Cw+kIKlmXU1XkjsH3Em/B43K8f6dBwiJCCmbFxweQnq560NOZg6F+YVlAzjX/bCOPn/rU6sc7hhwB31tORzYeYBgu2tUcHgwacmOx+PZHM4O4Pzlh19qnYOovbpquegBfKe1PqO1zgO+BW4CTmitzw7h/cRW7kKOaK13aa2twB8Yv+6mgV1As/Ms5wd8pZTaDcwDrrW9frMtNraKw+92y9yvlIoHttvKt7Wbd/YnaHcBv2qtc7XWqUBRZeNDtNYLtdZdtNZd7CsWACc+XM7m2Olsjp1OytLfiOh/s5Fw55aU5uZTXK4Ptzgli9K8Avw6twQgov/NpC77DQC3YF+jkFI0n/hXTny08jybxNGZnQm4NwvHrUkoytWFgLtuInvFFocyWSu2EHifUQkIuP1Gcjf8Xtmqqq2+t0Hyh8vYGTeVnXFTyVi2hdD7bwWgQVQrSnPzKSkXvyQlC0tePg2iWgEQev+tZPy0FQCPyHPfuhvUN5qCgxf1BXac/HA5W2KnsSV2GqlLtxJm2wa+nVuddxv4djZyCOt/M6nLjByKkjPxv8E4XANuakf+4eSLyqG80oR9mMIbYwoNAxcX3HrEULLVcdS9KfzcTwu4du6ONelkjWJVpfiP/bg0aYRLhJGDd59bKVi70akxKnPkwxWsiZvBmrgZJC37javuvwmAgKiWlOYWXLKxFfXpvx/9l5F9RzOy72g2/rSJXvcald+rO13NmdwzZKRkVFhm88rNdOhujMXq2KMTxxOO1yqHHz76gTF9xzCm7xg2/bSJ2HI5ZKZUrOT9uvJX2pfl0LHWOdTGZfglWvXiUt+KWr5952Lae4rsnlvtpq2cP/9ngDVa678qpZoBP58viFIqEpgCRGutM5VSizFaJsrnYZ/DxeRxXmkrtxMc25Eev76OpaCIP8afawTptupFNscav467d9oi2r0xEpOHG2mrdpC2agcAYX+9kSaDegOQ8uMWEj8/79t0ZLFy4smFtPxkNspsIv2LVRQeOEH45L+T//tBsldsIf1fK2j22kTa/rIAS1YuR0bPLVv82o0LMft4oVxd8O9zPQcfmk1hwokraxsAmSvjCYiNImrzW1gLijg44Z2yeR1WvszOuKkAHJ7+Pi1tt6Jmrd5O5qrtADSd+TCeLSPAqik6mcqhx6t/W276yu0Ex3ai+6+vYy0oZs/4+WXzuq56iS2x0wDYP+0D262orqSv2kG6bRvsnfwurZ8diHIxYy0qZt+UGt4abLWQ/95r+Dw117gVddWPWE4cxfPBwZQe3EfJ1o149LsHl/adwVKKzsvjzBsv1CxWVSxWMl56k9C3XwSTibzvl1Fy+Bh+IwZQvOcABes24da2DSGvzMbk2wDPm7vjN2IASf2d1xR+euUOGsZ2pNfmeZQWFLF9wrtl83qufJ41cTMAuPbJB2n81xswe7rRJ/5Njn32M/vmflPFWmtn6lMvsnX772Rl5RB798OMGvII995Zd5/Qt6zeQteYaBavX2Tcijr51bJ585e9zci+xl1C7z+/iGmvT2XE7BFkp2c5lKutrau3Eh0TzaL1iygsKGTe5Hll895a9hZj+hp3jyx6fhFTXp/C8NnDyU7P5lUn5iBqRuk6+MIPpVQURtdBN851izyC0QVxg9Z6k+2bwfZqrV+x/UDKXVrrI7bljwJdgAbAD1rrdrbXF9umv7ZVGMrmVZLDd8AnWutvlFKzgYFa62a2Lpi2WuuhSql2wA5bniXAxxjfpx6C0aIxTWu9+Gw+Wus0pdRA2/Mx9rlW0aUDwPKGD9Rrp1mwW/W+86EupBU7/66C6vBW9TsWpVCb6zU+QKcbataa4Sy5x1zrNT7A9sTQCxeqQ7fvVhFwZgAAIABJREFUvnS3klaZQ6dR9RrfjKrX+ABLTyytsyT6N/2L06/3Xx37T/1vtGqqk24RrXU8RuViC0bF4n0gE9gPjFZK7QUCgLMfzxYCy84O6HSSOcALSqntOLYszAca2HL4B7DNlvNOjO6QfcBngHwDixBCiGqRAZ2GOusW0Vq/CpS1TdlaGkq11g9XUvZN4E276Wa2p2lAO7vXB9o9P2o/r5J1bgJa2730hO31AuCBKpYZWMXrzeyeL8aoOFWYJ4QQQgj5+m8hhBDCaa7UAZjOdskqFxdqaagppdQgYHy5lzdorZ38ncRCCCGEuBhXfMuF1vpD4MP6zkMIIYSoi5skrkRXfOVCCCGEuFxcqb8F4myXy2+LCCGEEOJPQlouhBBCCCeRAZ0GabkQQgghhFNJy4UQQgjhJFfql145m1QuhBBCCCeRAZ0G6RYRQgghhFNJy4UQQgjhJPI9FwZpuRBCCCGEU0nLhRBCCOEkciuqQSoXl0DbZin1Gn/FyYh6jQ9wa9jpeo1fmO9ar/FLS831Gh9gYXyTeo3ftKT+m4tvaZ5Yr/Fv7zSqXuMDLNn+Tr3G/7TDrHqNLy4NqVwIIYQQTiK3ohqkciGEEEI4idyKapABnUIIIYRwKmm5EEIIIZxEbkU1SMuFEEIIIZxKWi6EEEIIJ5ExFwapXAghhBBOIneLGKRbRAghhBBOJS0XQgghhJNYZUAnIC0XQgghhHAyabkQQgghnETaLQxSuRBCCCGcRO4WMUi3iBBCCCGcSlouhBBCCCeRlguDtFwIIYQQwqmk5eIy4t4tGv9JY1AmE2e+/5Hcjz93mN/gwfvw/ks/dKkFa1Y2mc++jCX5tNPzuP4fj9A4piOlBUWsn7iQ9N1HHeabPdzouXAcPk1D0RYrJ1ZsZ9sLXzgltucNXQicNgplMpH73VKyFzmu1yPqOgIfH4lbq+akTHuO/JW/1Dqm902dafjEcJTZRNaXP5G+8CuH+crNhYg5U/Bo1xJLVi6nxr9AyakUANzbNCPsmbGYG3ihrZqj94xHF5dUO4cGN0cR8dRjYDKR+cUKUhd8XSGHxq9MwrNdCyxZuRwfM4eSUym4Ngql9cp3KDp8CoD87ftJfOKdGm6Jc+JmP0KLnh0pKShiyZSFnC53DADc/9HjNAj1Q7mYObllP8ufXIy2Ou9TW9QzjxIR0wFLQTGbJ75L5i7HHMyebtz47jh8mjVEW6ycWhHPzuedcxy6Xx+N34QxYDaT/98l5P3T8Vz0fqA/Xnf2A4txLmY9P6dOzsVRT48kOiaaooIi5k56hYO7D1Yo4+LqwphnRtG+e3u0VfPhnMWsX7rB6bk88fyrrNuwhcAAf/79yQKnr78qXctdjzIquR7dunAcvk1DsVqsnHTi9agm5LdFDNJycbkwmQiYOp60CdNJfmAQnr1jcIls6lCk5MBBUgaMJOXhxyhYvQ6/McOcnkbjmA74RobxTY/JbJz2Ad1fGFhpud0LlvDdLY/zfZ+ZhEa3plHP9rUPbjIRNGMsp0fN4ORfh+Ldtyeuza9yKFKanELqky+Tt3R17ePZYobNHsWJobM4dNsIfO+4BbeWTRyK+N/XB0tOHofihpLx4XeETh1szDCbiJg7leRZb3G430iOPzwNXWqpUQ4R/xjBkYGzSeg9Gr+7bsa9XA4B9/fGkp3HgZ7DSfvgP4RNH1g2r/hYMgdvH8/B28c7pWLRvGcHAiLDePeWySz7vw/o8+zASsv9e/SbLLptJh/0mo5XkA9X3359rWOfFR7TAZ/IMH64cTJbHv+ALi8MqrTcvgU/suTmqSzrPYPg6NaE9+xQ++AmE35TxpM+eTopfx+IZ1wsLs3Kn4sJpA0eQeqjQylYsxbfUcNrH7ec6J7RNIqMYNBNg3lt2uuMe35MpeUeHPsAWenZDL5lKENjhvH75l1OzwXg7n69WPDqs3Wy7qo0sl2Pvu0xmU3nuR79Ybse/deZ1yNRK06vXCilJiilvOymf1RK+Ts7zp+NW9urKT15CktiEpSWUrBiNZ433+BQpmjbDnRREQDFu/dgDg1xeh5X9enMwa/XA5Aafwg3P288Qx13n6WwmOSNewGwlljI2HUU7/DAWsd2b9eGkhOJlJ5KhtJSziz7Ga9bHbdBaeJpShKOgJM+IXu2b03xsURKTiRDSSk5S9bhE9vdoUyDuG5kf7sSgJxl6/HqbvwB8+4RRdH+IxTtOwKAJSsXrNZq5+DVoRXFx5IoOXEaXVJK9n/X4dvL8Q+1b6/ryfpmFQDZSzfQ4AYn/BGtQqtendn9jXEMJG4/hLuvN96hFU/h4rwCAEwuZsyuLk79xNa4T2eOfm20SqXHH8TNzwuP8sdhQTEpG/cAxnGYuesoXk44Dl3bXk3pycRz5+LK1XjcdKNDmeJ4u3Pxj7o5F2/o3Z0Vtn2+b/s+vH0bEBha8f31/Vsf/vXWvwDjU3NOZo7TcwHo0vE6/Hx96mTdVbmqT2cOVfN6lO6k46CmrGinP65EddFyMQEoq1xorftprbOctXKlVJ135VyKGOWZQ4OxnE4pm7akpGEOqfqC5X1XPwo3bXF6Hl5hAZxJTC+bPpOUgVdYQJXl3Xy9aNKrE4nr/6h1bHNoMJbk1LJpS0oaLg2Da73e83EJC6I0Ka1suiQ5DZeGQY5lGgZRcjYvixVrXj7mAF/cIhuBhiaLniHy328Q+Nh9Nc6hxCGHdFzDHHNwbRhE8dkyFiuW3DOYA3wBcGvSkJY/vEbkv17AK7ptjXKw5xMWQK7dMZCbnIFPw8qPgfs/fpxx8e9QdKaQ/T8673j0DAt0OA7zE89/HLr6etGoVxTJ63fXOrY5pNy5mJqKOaTq49D7jn4Ubv611nHLCwoLIjXx3PmQlpRKULnjwtvXG4ABUwfw9o9v8cT8mfgH/3k+y9X0epTkhOtRTek6+HcluqjKhVJqklJqt+0xQSnVTCm1Tyn1qVJqr1Lqa6WUl1JqHBABrFFKrbEte1QpFWy3zGKl1AHbsnFKqQ1KqQSlVNfzxJ+tlPqnUmoD8E/b9EdKqV+UUseUUvcopeYopXYppZYppVxty72olNqjlPpdKTXX9tpipdQCpdRvtjzusL0+UCn1vVJqNbBKKRWolPq3bdnNSqn25XLZZMv7sdrsgJrw6huH6zWtyf2k/voVAZTZxC1vj2bPop/IO5564QX+ZJTZjGfntiROfpmjD0zFp1f3slaNS6U0NYN9Nw7m4B0TSHr2fZq8NgVTA89LFv/LR+fwZvQYXNxcaHrDtZcsrj1lNnHDO2M48MFPnLnEx6Fnnzhcr25D3qf1cy6azWZCIkLY89seRvcbw974vQx74pJfki4Lymzi5rdHs/d/9Hp0ubngJ3SlVGdgEHA9oIBfgbVAG2CI1nqDUmoRMEprPVcpNQnoqbVOq2R1LYH+wGBgK/B3oAdwFzADuPs8qbQFemitC5RSs4EWQE/b65uAe7XWjyulvgNuV0r9AvwVuFprrct1zTQDutrWsUYp1dL2ehTQXmudoZR6E9iutb5bKRUDfAx0tJVrD3QDvIHtSqklWuvEctttGDAM4MVmbXgoNOI8b83WUtEwtGzaHBqMJbXiCeIeHYXPwIdIHTkRSqo/cLAyVw+Io/VDPQFI23EY74hzn468wwPJT86sdLkb5gwh50gye97/ySl5WFLSMIeda60xhwZTerqyw8h5SpPTcQk/96nUNSyY0tPpjmVOp+MaFkJpcjqYTZgaeGHJzKE0OY38rbux2Jqhz6z9DY9rW5K/aWe1c3B1yCGIkmTHHEpOp+MWHlyWg9nHuyyupTgXgMLdhyg+nox7ZCMKdlUc+Hc+UY/G0eEB4xhI+v0wPnbHgE9YILmnKz8GACxFJSQsj6dV7yiO1qLloNXAXrSwHYfptuPw7N73iqj6OOz68hByjySz//1lNY5tz5Ja7lwMCcGSWvE4dOsSRYMBD5M+eoLTzsU7B9xJvwf7ArB/5wFCIs6dD8HhIaSXOy5yMnMozC8sG8C57od19PlbH6fkUl8ul+tRTcmATsPFtFz0AL7TWp/RWucB3wI3ASe01meHJH9iK3chR7TWu7TWVuAPYJU29sQujD/45/O91rrAbnqp1rrEtqwZOHtlObuubKAQ+EApdQ+Qb7fsl1prq9Y6ATgMXG17fYXWOsPuff8TQGu9GghSSvna5v1Ha11gq0CtwaioONBaL9Rad9Fad7lQxQKgeO8+XJo0whweBi4uePaKoWDdJocyrq1bEjB9EulTn8Ca6bSeJvZ9tJLve8/k+94zOf7TNlreZ+zKkKgWFOfkU5BSMVbU4/fh5uPJr0994rQ8iv7Yj+tVjXBpZGwD7763kr9204UXrIWCXQdwaxaBa+OG4OqC7+03k7tqs0OZvFW/4ndPHAC+fXuQv/l34/Vf4vFo0wzl4Q5mE17R7Sg+eLzaOeT/noC7LQfl6oLfnTeTs9KxiyFn5a/43xsLgN9tN5K3ycjBHOgLJuM0dm3SEPdmERQfT652DvEfr+TDfjP5sN9MEpZvo929xjEQ0akFRbn5nCl3DLh6uZeNw1BmEy1iOpJ+KKnace0lLF7Bsl4zWNZrBqeW/Uaz+24CICiqJSU5BRRWchxe93h/XH28iJ/1z1rFtleydx8uje3OxbgYCtdvdCjj0rol/tMmkfH4TKeei//96L+M7DuakX1Hs/GnTfSy7fOrO13NmdwzZKRkVFhm88rNdOhuDGDs2KMTxxOqfwxeTspfj1pcxPWo0+P34erjyRYnXo/+LGyt8CtsLe0rlFIV+pWUUj2VUjvsHoVKqbtt8xYrpY7YzetYMUpFtRlbUL56djHVtSK751a7aetF5HKmsnVpra1KqRJ9rrpoBVy01qW2rpZY4D5gDBBzgdzLx6hKTd77+VmsZM19k+A3XkKZzJz571JKjxzFd9hAivceoPCXjfiNHY7y8iDw+aeMRZJTSJ/6RK1D2zu5ageNYzpw74ZXsBQU88ukhWXz7lr+HN/3nolXeCAdxt9NVsIp7vrJGD2+98MVJHz+c+2CW6ykv/AWYfNfAJOJ3H//RMmhY/iPGkDxHwfIX7sJt2tb03DebEy+DfC6pRuWUY9y6p5aNANbrCQ/PZ8mi541bkX9ejnFB48TPP5hCnclkLf6V7K++omIuVNosfJ941bUiS8BYM3JI33Rd0R++xpaa86s/Y28n7fWKIfEpxYQ+fHTxq2oX62kKOE4oRMfomBXArkrt5D5xQqazJtE6zXvYsnO4/jYOQB4d21Hw4kPoUtLwao59cTbWLLzar49gEOrd9C8ZweGr3uFkoJifpxy7hgY9ONzfNhvJq5e7tz3/iTMbi4ok+L4pr1s/2RVreLaS1y1g/DYjtyx8VUsBcX8OvHdsnl9VzzPsl4z8AwPpN2Eu8lOOEXf5c8BcODD5Rz+7OfaBbdYyX71DYLmzQGzifwfjHPRZ+ggivftp2j9RvxGj0B5ehL47GxjkdOnyZjm3HNxy+otdI2JZvH6RcatqJNfLZs3f9nbjOw7GoD3n1/EtNenMmL2CLLTsxzKOdPUp15k6/bfycrKIfbuhxk15BHuvbNuW0lOrtpBo5gO3GO7Hq2/lNejGroMB2BOx/gg/6JSarptepp9Aa31Gmwt80qpQOAgsNyuyFStteP98RegLtSEo5SKAhZjdAOc7RZ5BIgHbtBab1JKvQ/s1Vq/opTaBdyltT5iW/4o0AVoAPygtW5ne32xbfprpVQz+3mV5DAbyNNaz61iOk9r3cB+HrAA8NJapyil/IDDWusgW9xQ4A4gEqOLpyXwANBFaz3Gtp43gFSt9TNKqVuBeVrrTrb1341dtwjQrXy3iL2T18fU69G24uSFW07q2q3Bzv8OgOoozHet1/ilpeZ6jQ+wxOpXr/GbltT/RfeWZlWeppfEwBPu9RofYMn22t+uXBufdphVr/EBBp76RNXVujuF3ej0A3178oYa56uU2g/cqrVOUkqFAz9rrducp/ww4Bat9UO26cXY/lZXJ+4FWy601vG2lZ9tp30fyAT2A6Nt4y32APNt8xcCy5RSiVrrntVJxsl8gP8opTwwKkWT7OYdx3g/vsAIrXWhUhX23WxgkVLqd4wulQF2837H6A4JBp45X8VCCCGEqEcNtdZn+yyTgYYXKP8AUL756zml1CxgFTBda11UcTFHF9UtorV+1T6YraWhVGv9cCVl3wTetJtuZnuaBrSze32g3fOj9vMqWefsC0w3qGJeVXegrNRajyi3jsUYLTRnpzOoeoDp71rrR6vKVwghxP+muugWsb9BwGah1nqh3fyVQFgli860n7Dd3FBlgraWjesA+1Gx/4dRKXHDaDyYBvzjQjnL138LIYQQlzFbRWLheebHVTVPKXVaKRVu1y2SUlVZ4H6MGzjKbn+ya/UoUkp9CEy5mJxrVLm4UEtDTSmlBgHjy728QWs92lkx7FtMarj8bOdkIoQQ4s/mMvzSq+8xuvVftP3/n/OUfRCjpaKMXcVEYbTmX9T95pdVy4XW+kPgw/rOQwghhKgJ6+X3PRcvAl8qpYYAxzBaJ1BKdcEYczjUNt0MaIJxk4O9T5VSIRhjF3cAI7gIl1XlQgghhBDOo7VOx/hKhvKv/wYMtZs+CjSqpFxM+dcuhlQuhBBCCCe5DLtF6oX85LoQQgghnEpaLoQQQggnuQzHXNQLabkQQgghhFNJy4UQQgjhJDLmwiCVCyGEEMJJpFvEIN0iQgghhHAqabkQQgghnES6RQzSciGEEEIIp5KWi0vg8LGgeo3f75oT9Rof4Oj++t0GFq3qNb6v5wV/objO3VqSX6/xXUzWeo0PcOqYf73GN5sK6zU+wKcdZtVr/Id2XvAHNa9oMubCIJULIYQQwkmkW8Qg3SJCCCGEcCppuRBCCCGcROv67/67HEjLhRBCCCGcSlouhBBCCCexypgLQCoXQgghhNNouVsEkG4RIYQQQjiZtFwIIYQQTiLdIgZpuRBCCCGEU0nLhRBCCOEkMubCIC0XQgghhHAqabkQQgghnER+W8QglQshhBDCSeS3RQzSLSKEEEIIp5KWi8tAi2cHERgbhaWgiAPj3yZv15EKZRq0b06b10dj8nAjY1U8h574EICmU/oT9lAcJek5ABx54TMyV22vUR5u0V3xGTMWzCYKliwh//PPHOZ79b8fz363oy0WrNlZ5Mx5Cevp0zWKBdD0mSH4x0RhLSji0MS3yN91uEIZr+ua0+K1sZg83MhaHc+xJz8AwOzfgFYLJuPeOISik6kkDJ+LJfsMZh8vWrw1HreIEJSLiaQF35P2xeoL5hL5zGD8Y6OwFhRzcMKbnKlkH3i3b07L18YYuayK58iTiwBo8vgDBPbpClYrJenZJIx/i5LTmdXaFg1ujiJ81jAwmcj8cjlpC752mK/cXGg8dxIe7VpiycrlxNiXKDmVgmujUFqtmE/R4VMAFOzYT+ITb1cr9llNnxlCQIxxHFa1P7zt9kem3f646slHCejVBWtxKUXHTnNo4ptYci78E+++t3biqqeHgtlE2ucrSH772wrvO/K1CXi1b0FpZi6HR86l+GQKAGGj7yX4wTiwWDk+6z1y1u44t6DJRNsf51KcnM7Bgc+dN4er/jEEv5jOWAuKODLxTfJ3V34cRs4bh8nDjezV2zg+69xx2GL+ZNybhFJ0IoVDI4zjsGx7dWjJNd+/yKFRr5C5ZNMFt0d5I54eQXRMNEUFRbwy6RUO7T5UoYyLqwujnhnFdd2vQ1s1H835iA1LN1Q7VmW6/uMRGsd0pLSgiPUTF5Kx+6jDfLOHG7cuHIdv01CsFisnV2xn2wtfOCV2ZZ54/lXWbdhCYIA///5kQZ3FqQ0Z0GmQlot6FhDbCc/m4WztPpaEKe/S8qXHKi3X8qXHODB5AVu7j8WzeTgBMR3L5p1a+APxcVOJj5ta44oFJhM+4yeQNf1x0gcOwCM2FnPTpg5FShISSB8xjIyhgylauxaf4SNqFgvwi4nCIzKcnTeO5sjjC4h8YVil5SJfHM6RqfPZeeNoPCLD8evZCYCIMX8le/3v7Owxhuz1vxMx5h4AGg68jYIDJ9ndaxJ7751F01kDUK7nr0P7x0Th0Tyc7TeM4dDU+TR/sfJcmr84jENT5rP9hjF4NA/HP8bIJfGd/7AzdhI7e00hY8U2mkzqX72NYTIR8fRIjg56ioN9RuF35y24t2ziUCTg/t5Ycs6QEDOM9EX/IWzawLJ5xceSOXTHOA7dMa7GFQv/mCg8I8PZYdsfzc+zPw5Pnc+OG0fjGRmOv21/ZK/byc6eE9gVN4nCw4k0GnvvRb3vq54dzoFH/sEfPccS+Jeb8GjV2KFI8AO9KM3OY3ePkZx+73saz3gUAI9WjQn8Sw/+iBnLgYef5qrnRoDp3OWs4ZA7KDh48oIp+MVE4R4Zwa4eozg6bT5NXxheabmmL4zg6OPvsKvHKNwjI/DrGQVA+Oh7yFm/i109RpOzfhfho+9xeH+NZz5Ktn2lpxqie0YTERnBkJuG8Ma0Nxjz/JhKyz0w9gGy0rN47JbHGB4znF2bd9UoXnmNYjrgGxnGtz0ms2naB3R/YWCl5f5YsITvbnmc//aZSWh0axr1bO+U+JW5u18vFrz6bJ2tXzjPFVW5UEpNUEp52U3/qJTyr8d8blVK/VCbdQT3ieb0l2sByI1PwMXXG7dQx7fkFuqPSwNPcuMTADj95VqC+3atTdgKXK++BkviKSxJSVBaSuHq1bjf2MOhTMmO7VBUZDzfswdTSEiN4wX06Ura1z8DkBd/ALOfN66hAY45hQZg9vEkL/4AAGlf/0xA3+vPLf+lsXzalz8TcHZ7aI3Z2xMAs7cHpVl56FLLeXMJ7BtN6ldrbbkY+8C13D5wDfXH7ONFnm0fpH61lkBbTEteQVk5s5c71e1y9ezQmqJjSZScOI0uKSX7h3X49OrmUMYnrhuZ36wCIHvperxv6FC9IBcQ0KcrqdXcH6l2+yN77U6wGL8GmbvtAG7hQReM6d2xFUVHkyg+brzvjP+sx7/39Q5l/Ht3Jf2rNQBkLtmIT4/2ttevJ+M/69HFpRSfSKHoaBLeHVsZeYYH4RfbhbTPVlwwB/8+XUn/2lj/mQu87zO2953+9Rr8bfvev8+5/NK/WoN/33P5Nxzcj8wlmyhNz75gHpXp1rsbq2z7fN/2fTTwbUBAudwAev+tN1+8ZbQWaK3JycypUbzyrurTmUNfrwcgNf4Qbn7eeJY7LyyFxSRv3AuAtcRC+q6jeIUHOiV+Zbp0vA4/X586W78zWNFOf1yJrqjKBTABKKtcaK37aa2z6jGfWnMLD6QoMb1suigpHbdyJ6dbeCBFSVWXiRjcl6jVc2k9byQuft41ysMUHIw1JaVs2pqaijk4uMrynv36UfzrrzWKBeAWFkhRYlrZdHFiOm5hgRXKFNu9b/syrsH+lKQYXQ8lKZm4BhsXveQPf8SzVSM6bf+A61bP49isRXCBZsryuRjb1/GPo1t4EMXl95NdvldN/zudf3uXkHtu5vjL/7qobXCWa1gQJUmpZdOlSWm4NnSM79rQrozFijU3H3OAr5Fbk4a0+O/rRH7+Al7R11Yr9lluYYEU12J/2At9MIas1fEXjhkeSHGSXczkSo79MLsyFiuWnHxcAnzOu2yT2UM4+dxHF9zvxvod92tJUjqu5d6Ta/n3nZSOW5ixf6o6Dl3DAvHv242Uj5ddMIeqBIUFkWa3T9KS0ggOczwnvX2N8/3RqY/y5o9vMmP+DPyDnfN5yyssgDN22+ZMUgZeYRUrN2e5+XrRpFcnktb/4ZT4VyqttdMfV6J6r1wopSYppXbbHhOUUs2UUvuUUp8qpfYqpb5WSnkppcYBEcAapdQa27JHlVLBdsssVkodsC0bp5TaoJRKUEpV+TFfKXWLUmqH7bFdKeWjlDIppd6xrXOFrYXkPlv5vrbX44F7qlrvpZK4eDlbrh9LfOxUik9n0Xz2o3Ue0yOuFy5t2nDmi+r9Ea1TthPQ/9ZOnPnjKNs7DWFXr8k0fW4o5gaedR7++Iufsa3LcFK/XUf4oNvqPN5ZpakZ7O8xiEN3jifpufdpMm8KpkvwfqsSMe5edKmVtG/X1Ut8v9gulKZlk7+r4tiES8J2HF719BBOPv/xRVVwasNsNhMSEcLe3/Yytt9Y9sbvZegTQ+s0ZmWU2cTNb49m76KfyDueeuEFxJ9evQ7oVEp1BgYB1wMK+BVYC7QBhmitNyilFgGjtNZzlVKTgJ5a67RKVtcS6A8MBrYCfwd6AHcBM4C7q0hjCjDaFqsBUIhRaWgGtAVCgb3AIqWUB/AeEAMcBKocuaSUGgYMA5jsE8VdXs3L5oUP6kP4Q3EA5O44iHvEuU+p7uFBFCdlOKyrOCkD9/DKy5SknWtyTfp0Je3+Ob2qlM7LmpaGKTS0bNoUEoIlreJmdovqjPfDj5AxYRyUlFQrRsOBfQl5qBcAZ3YcxD0imLyz640Ioji53PtOznBoQbAvU5KWhWtogPFpMTSAElvTc/DfYkh6yxgUWHQ0maLjKXi0bETxdsc/NmED+9LQtg/ydhq55NrmGds33aF8cVI6buX3U7l8AVK//YW2n8zkxNyLH9RWkpyOa/i5LiaX8GBKTjvGLzltlClNTgezCZOPFxZb87el2Mi8cPchio8n4xbZiMJdBy8Yt+HAvoTa9kfejoO4RZz7VFzd/QEQcn9PAuK6sPdvT13U+y5OysAt3C5mWCXHfrJRpiTJeN9mXy9KM3OrXNa/dzT+vaPxi+mMyd0Vk48XkW9M4Mi418rKhg64zeE4tN+vruFBlJR73yXl33d4EMXJxv6p6jj0bt+CFu9MBsAl0Ae/mM5G99yK81e67hhwB30f7AvAgZ0HCLbbJ8HhwaQlO56T/9/emcdbVVb///1BIExFRZA0TZA0M5xICs1yyqFyqqQy7dtubwxTAAAgAElEQVTkV/2WRqENZn0tv42Wmmm/FM0hbTBLTUlBHHLAARIVxCEcUctQA0RkEPj8/nj2ufdwuRN0z7P35a7363Ve9+5nn3M/65x97t5rP2s9a70y9xUWv7a4KYHzjvF3cMDHD2hXoz22+/T72fbIvQF46YEnWa/us1lvswG89kLricq7n/55XnnqBR6+cOIaa68tRJ2LRNkzF3sAV9teaPtV4CrgvcCztmvpzpcXz+uIp2zPsL0CmAnc7DSfNIPkKLTFZODMYmZkI9vLCr0rba+w/QJwa/Hc7QqdWcXfvrytP2p7nO1dbe9a71gA/PPiiU0JmC9PmMrgj+0JwAYjtmHZgtdYOmflSM/SOfNY9uoiNhiRYsqDP7YnL02cCrBSfsbAD7yLhY8+295n1CavP/oo67x5C3q96U3Quzf99tmHJXetnHHe+63bsMHYE5l3ysl43upHo/51yQQe2u9EHtrvROZOmMLAw/cCYP0R27L8ldeappebbJozl+ULFrH+iG3T+zt8L+ZOnALA3BunMvBj6fUDP9Y8vvT5F+n/3hSX7z1wQ9YdtjlLZq+6ouWFSybw4H4npSTMG6YwaPSehS3pGLze4hi8Pmceyxe8xvrFMRg0ek/+PSEdg35DN2t63oADRrLo8edX63NZNP3vvGHI5vTZYjDq05sND3ofC25aOeS04OZ72fij+wKw4Qf2YOHd0wFYZ0D/pkTGPlsOpu+QzXl99gud0v3XJROYsd+JzCiOx6DVPB6D6o7HhnvtwmZfOIzHPvNDVixa2in9hQ/Oot/Qzei75aaoT28GHLoH8yZNWek58yZNYZPR6WK38Yd2Z8HkGU3jAw7dA/XtTd8tN6Xf0M1Y+MAsnv/R5UwfeTQzdjuGJ794BgsmT1/JsQCYc+kNzNx/LDP3H8vcifeyyeHp76/Xwfter3jfmxy+N/OK9z3vxqlN9m0yunl8+m7HMX3UsUwfdSxz/3I3z3zz/KZ97TH+0vEcf+DxHH/g8dw98W72LY75drtsx8IFC5k7Z9WL+7033cuOu6Xv/M577MzsWbM71GmLRy+9iWv3P4Vr9z+F2RPvY9jh6dQ7aMQwlr7yGovmrPp/v8vXDqfPBusy5dQ2T4dBD6SqS1Fbun6dcQWX1P2+om57Be28T9s/kvQX4IPAZElr7vavAf++aRoD9t2Fkfecw4pFS3nsy83Z/iNu+gnT3v9VAB7/xgXNS1FveaBpVcjQb3+K9YcPwTZLnn2RWV89f80MWbGcBT//GRuf/lPo1YvFN1zP8qefZr3Pfo5ljz3KkrvuYv3jjkPrrsuG3/luesm/5jDvW99cI7l5N9/HRvuOYKe7/h8rFi3hya+c27Rv+KQzeGi/dNf39Mnj2Lq2FPXWacwvYvn/PPcq3nreSWz6iX1Z8vyLzDr2DACe/9mVDPvZCexw81kgMfv7l7Hs3wtIE2OtM/fmaWy07whG3P0Lli9awuNfaT4GO036KQ/udxIAT558AdsUS1Hn3nJ/U17BVqccxbrDNscrzJLnXuTJr6/mMVi+gn985zyGXHoa6tWLuVdOYsms2Wz65SNZNGMWC26ewtwrbmSLM09km1vGsXz+qzz7pR8DsN67hrPpl49Md8UrVvCPb/2C5fNf7UBwVWrHY+fieDxRdzx2mHQGM4rj8dTJ45qXBt86rekzGPr9o9Eb+vD2K9Ksxav3/Z2nvtHB57B8BbO/fQHb/uZU6LUOL19xE4v//iybn3QECx98nPmTpvLS729i6NlfZvidv2T5vAU88YV0nBf//VnmXjeZd9xyLixfzjPfGgcrVqz2+55/831suM872WHyL9NS1LHnNO17x41nMnP/sQA8883zm5ei1n8Pf5G+h4OO2Jclz73IE8f9dLVtaIupt0xl5D4juejOi1i8aDFnnXhW075zJ5zL8Qem1SMX/eAiTjr7JI79zrHMf3k+Z554ZpfoP3fzA7x5n534yOQzWL5oKXeOHde075Abv8+1+5/CGzcbwE5jDmPerOc5ZGJaxfHIxZOY9bu/dokNLfnqqT9i6v3TmTfvFfY97Ci+8PlP8dGDs56yO6S75kh0NSrzg5A0ArgEGEVzWORTwDRgd9t3S7oQeMT2GZJmAIfYfqp4/dPArsD6wHjbw4vxS4rtP0oaUr+vFRuG2X6i+P2PpNmIPsCnSSGVQaSwyDHAeODvpNDME5J+B2xg+6D23uftbxpd6rftbW+f0/GTGszTj3W8eqCRLHfbzkUO+q+7pOMnNZhXF/ctVb93r9W/+Hc1Lvl78L+9FpeqD/DxFeX+Lx754Gml6gP0Gbh1w74IG64/rMvP9/NffaLcL+4aUOrMhe1phSNQmy+8EJgLPAZ8sci3eBj4ZbF/HDBB0j9s791FZnxZ0t6kGY6ZwA3A68C+hfazJGdnvu3FRS7FXyS9BtwBVHtdVBAEQRBkpvSwiO0zgaZ5vGKmYZnto1p57jnAOXXbQ4pfXwKG141/pu73p+v3tfI3T2htXNJJtl+VtAnJ+ZlRPH8CKfciCIIgCFYiwiKJ0p2LCjO+KNDVF/i/IrEzCIIgCIIOqJxz0dFMw5oi6bPAmBbDk21/sQ079upqG4IgCIK1m1iKmqicc9EobF8MXFy2HUEQBEGwttNjnIsgCIIgaDTupr1AuppwLoIgCIKgi4iwSKLsCp1BEARBEKxlxMxFEARBEHQRsRQ1ETMXQRAEQRB0KTFzEQRBEARdRCR0JsK5CIIgCIIuIsIiiQiLBEEQBMFaiqTRkmZKWiFp13aed6CkxyQ9LukbdeNDJd1bjF8hqVMdEMO5CIIgCIIuwnaXP/5DHgI+Atze1hMkrQP8AvgAsD1whKTti90/Bs6y/VZSY9HPd0Y0nIsgCIIgWEux/Yjtxzp42ruAx20/aXsp8HvgUEkC9gH+WDzvUuCwzuiGcxEEQRAEXYQb8MjAm4Fn67afK8Y2AebZXtZivEMioTMD73vhSv0nr5d0jO1xXWVPGTYMLlm/KyjbhrL1q2BD2fr/qQ03lKzfFZStXxUb2mLZ0uf/o/N9a0g6Bjimbmhc/fuXdBPwplZeeortP3e1PZ0hZi66B8d0/JSGU7YNZetD+TaUrQ/l21C2PpRvQ0/Xh2rYkA3b42zvWvcY12L/+20Pb+XRWcfieWDLuu0tirGXgY0k9W4x3iHhXARBEARBz2YqsE2xMqQv8AngWqds0luBw4vnfRrolMMSzkUQBEEQrKVI+rCk54DdgL9ImliMby7peoAip+J4YCLwCPAH2zOLP/F1YKykx0k5GL/qjG7kXHQPqhBbLNuGsvWhfBvK1ofybShbH8q3oafrQzVs6BbYvhq4upXxfwAfrNu+Hri+lec9SVpNslooqokFQRAEQdCVRFgkCIIgCIIuJZyLIAiCIAi6lHAugiAIgiDoUiKhM+hWSNrO9qMZ9frYfr3F2EDbL+Wyoacj6X2tjdtus1fC2oqk/tSdt23/O6P2m0iJfQam2n4hl3bQ/YiEzm6GpBm2d2iwxpbAT0hlXm8AflK7wEq6xnanass3yLbZtt+SQWdv4DKgHzANOMb208W+abZHNNqGQmsQ8N/AEFa+qHwuh35hw6XAGNvziu2NgTNy2SDpurrNfqQL3H2298mhX9jwFK1UYra9dSb9Y4HvAovr7HBG/aOB/wVuAQTsCZxm+6IM2tfRThVs24c02oZg9YmZiwoi6SNt7aL1Eq9dzUXAn4B7SB3wbpN0sO2Xga0aLS7p523tAjZqtH7B6cABtmdKOhyYJOlTtu8p7MjFn4E7gJuA5Rl169mx5lgA2J4raZdc4rYPrt8unN+f5dIvqG9V3Q8YDQzIqH8SMLzEGbOvArsU5wAkbQLcRTpXNJqfFj8/Qjr/XV5sHwH8K4N+sAaEc1FNrgB+Q+veer8M+oNsn1f8foKko4DbJR3Shk1dzWeBE4Elrew7IoM+QN9aERnbf5T0CHCVpK+TrZcQAG+0/fWMeq3RS9LGtucCSBpAueeO54C35xSsXVTr+Jmk+0h38zl4Angtk1ZrvAwsqNteUIw1HNu3AUg6w3a9k3edpL/lsCFYfcK5qCbTgZ/afqjlDknvz6DfR1I/24sBbF8u6QVS9bb1MuhPBR6yfVfLHZK+k0Ef4HVJb6rFlYsZjH2B8cCwTDYAjJf0waLATVmcAdwt6cpiezTw/Vziks6h2aHrBexMClVlQ1J9GKwXaSYj5/nzZOAuSfdS53Tb/lIm/ceBeyX9mXQsDgWmSxpb2HFmBhvWk7R1UdQJSUPJcz4K1oDIuaggkt4LPGN7div7drXdUG9d0leAabU7hrrxXYDTbe/XYP0BwGLbpd2pFU7ci7YfbDG+IXC87YZeXCUtIJ3ERTqBLgFeL7Ztu38j9VuxZ3ugluNwi+2HM2p/um5zGfC07cm59Asbbm1pA+kG4LFM+lOAO4EZwIrauO1LM+mf2t5+29/NYMOBpMqcT5L+D7YCjrU9sdHaweoTzkVFkbQO8CXbZ/VE/c4g6U+2P9rTbWg0kkYBM20vKLb7A2+3fW+5lvUcJN1vO1ueSzt2rA9g+9WS9N8AbFdsPmq7tdBpUAHCuagwkqbYXu2a7muLfkdU4YTbaBskfZg0UzC/2N4I2Mv2NY3SbMWG+4ERRYdEJPUC/tboFTOSZtB6fktt9mbHRuoXNoxtb3+mcACSfkCaLbmOlcMiWZaiShpOWj1VS2J9CfivuuZWOWxoLdF9PjDD9pxcdgSdI3Iuqs1kSeeSEjwX1gZt54o3l63fEVXwjBttw6lF46EkZs8rpqizORekm5Cm92l7haQc546DMmh0xAZlG1BQS2Q+uW7MQJalqKRwxFjbtwJI2gu4ANg9kz6klWu70bwcdi/gPmCopNNsX5bRlqADwrmoNjsXP0+rGzPNse+1XT9ovYpu7v/bJyV9Cfhlsf0FUty7odh+pva7pK2AbWzfJGldMn0GOXIJOoPtoSWbsF7NsQCw/VdJuZMpe5PCcf8CkDQY+DXwbuB20sxKUBHCuagwtvfuyfqdIGe9ibZotA1/k3Qm8Iti+4uku7WcHAf8HPgWybm8GTgml7ik/y70BpBW6mwBnAfsm9GGbUnO1WDbwyXtCBxi+3sZbRgObE/dcnTbv84k/6Skb9N8AT+KDA5mC7asORYFc4qxf0t6va0XBeUQvUUqjKTBkn4l6YZie3tJn+9B+mM6GGt4/YcK2HACsJQUmvo9qULjFxqsuRK259j+hO1NbQ+2/cnMMe4vAu8BXinsmQVsmlEfUgjgZNKKHWxPBz6RS7wIhZ1TPPYmFXnLWZnyc8Ag4CpSgb2BxVhO/ippvKRPFyuIri3G1gPmdfDaIDOR0Flhiov6xcAptncq4tz3N7r8d4X0VymznTuJs2wbJI22fWVHYw22oR8p3v0OVr5rzlX++17b76597sX3cFqOhM46G6baHll/7CU9YHvnjl7bRfozgJ1I/387FSGByxu9LLzQXge4qeyZTEkiVencoxiaDPzJcRGrJDFzUW0G2v4Dxbp228vIWwK6FH1JRyj1Exgq6dq6x61Aruz40m0oOLmTY43kMlLZ5QOA20hhiQXtvqJruU3SN4F1Je0HXElaNZGTlyQNo0jgVSoJ/8+M+otsrwCWFUuB5wBb5hC2vRxYUdR4KZM3AtfY/gopLLaUCO1Xljgw1WahUg3/2gltFGnp1dqufxfpxD2QVB2yxgJS9dIclGqDpA8AHwTerJV7rfQnFXHKyVttj5Z0qO1LJf2W1O8kF18HjiYVkDoWuB64MKM+pNDMOGA7Sc8DTwFHZtT/W7EM+QJSzs2rwN0Z9V8FZkiaxMorx3JVCIWUtPlepcZ5E4C/AR8n73EIOkmERSqMpHeSEumGAw+RYp6HF/HetV6/JyNpJ9JqndNYuX/FAuDWWp+PTLZMsf0uSbeT8j1eAKY4Q0fOYkp+pu3tOnxyY234se2Tivh+r1pBsZLsGQL0z/l/qJWrpDaRq0JoYcM02yMknQCsa/v0nKGpYPUI56LiFPHlt5FWJTzmovV5T9BXcwlsgL5AH2BhztLXZdsgqU/uY96KDUeTkvh2AC4B1ge+bfv8TPp/Bk5orRx+LiTdY3tUCbrtFirLWXNGUl9SdUyTzgVLc2kX+veTnNuzgM879fuZkSsHLFg9IixSYZS6Lv4K+F3OO9Wq6NtuKmBUJHMdCmQ9wVfAhiGSfsiqSxBzFU/Cdi0EcTutFG2S9OkG38FuDMxU6q9RPyWfc7XE/ZKuJeV71NtwVYN1ayG5fqRmaQ+SHP0dSWGB3RqsD4CkDwLnk7qzipSLdKztG3LoF4wh5RtdXTgWWwO3dvCaoCRi5qLCSHorqf34x0knkouBG3NlR5et34ZNa33J7xZadwKnku7WDiYdj162c7X67pDWVtR08d/fs7Vxt2is10gkXdy6CdlWzFxFqtY6o9geDnzH9uGZ9B8FDrL9eLE9DPhLmeGqlkg6x/YJZdsRJMK56AYo9XI4iFTEZznpIn92xr4Cpehr5V4CtTbXe9rOcrdWBRsk3Wf7nfXTv7WxHPqdodHOVhFjv7yM2bPOIulk2z9s4N+fafsdHY01UH+q7ZF12yLl3Yxs52VZabSTG6weERapOEqVAD9LWjnwJ+A3pHXet9Bcnntt1T+47vdam+tDG6xZNRuWFM7dLEnHA8+Tch6qRKPvUAYDUyVNAy4CJlawtsFooGHOBTBd0oXA5cX2keRbOQVptcr1wB9Ix3s06Zh8BLKEh4JuRsxcVJgi52EeKe/hT65rLyzpKtutdQlca/QDkDQSeATYCPg/YEPgdNv3lGpYHTnCRMWd8v4kR3dX0kXuV7afaKRuZ8kwe9MP+B/gfcXQ7cAvbS9ulGYL/dbCQjWyhYfaI2YuqkU4FxVG0ta2c9fvr5L+FqRyx+8phu4Axth+rifZUNjRn3QSL20JZFtIOtf28Rl0diI5FweSEvlGAZNsf63R2h0RF7byqUI+VtBMOBcVR9KHWLXs8mltv2Lt0S8K9vyWlZslHZmj5HFVbJC0KynHpbZqZT7wOdsNb14maWx7+22f2WgbCjvGAP8FvEQqnnWN7ddr4SLbw3LY0R4ZZi62IYVdSlk1JOl04HvAIlIBqx2Br9i+vN0XZkTSZ2xfUrYdQSLKf1cYSeeRVmqcQFr+NRrYqqfoA4NsX2x7WfG4hFTIKydl23AR8AXbQ2wPIVWKbG+KuivZoINHLjYHPmL7ANtXFo7FAKdy2AflMEDSezoYa3Svl4tJCdXLSI3Lfk1z/kUO9rf9Cunzfhp4K/DVjPpI2lXS1ZKmSZouaYakpryTcCyqRSR0Vpvdbe8oabrt70o6A8i5rrxs/ZclHQX8rtg+Ang5o34VbFhuu6nUtu07JWUp/237uzl0OsEOpERWACRtBowH3mn7kUw2nAO0DHs0jdn+QYP117V9syTZfgb4TpETlWtJcu1a8SHgStvzUxpMVn5DcmhmUPQ7CqpLOBfVZlHx8zVJm5Muapv1IP3PkU7gZxXbk0kx95yUYkNdZcbbJJ1Pcm5Mmkn6a6P1W9hSaldU4GrgSqVmYVuSWm2flENY0m7A7sCgFmGi/sA6OWwoKHvV0Pii1sUi4H8kDQKyJJPW8aLtazNrBmtIOBfVZrxSs6KfANNIF5ecDZtK1S/u0HJWYaySDWe02D617vfciVKXAY+SuqKeRloGmWvGANsXFKWnrwGGAMfaviuTfF/SRbw3K4eCXgGyFLAqGEPqCvol0qqhvYFW+300AtvfKPIu5tteLmkh+ZeFn1osx70ZaFq5Fstgq0kkdHYTJL0B6Gc7Z1fUUvWL8r5nk1YFmNQF8is5V7BUwYb2yFB6uylZsQiP7SipD3CHG9xro8VMgUhJndOB+yFfQmlhy1aFo1lJGl2dUql524dIzl3TTWnmY3A5qbfJTJrDIpVYBhusSsxcVJAWVSFb7mu4p162fh2/BX4BfLjY/gQpPPDuTPpVsaE9xgCN7kxZa5w2ryg7/QKwaYM1YdWk0avaGM/BhZJG254HoNT2+/e2DyjBltZYJeG0i7mOFAYpM99hpO23laQdrCbhXFSTg9vZZ5pPsmurfo032r6sbvtySVkz1CtiQ3vkyKobV1xMv03Kd1i/+L2hVCihFGBgzbEAsD1XUg4HqypsYXvHkm24S9L2th8u2Y6gE4RzUUFsdyphsFFT4mXr13GDpG8Av6c5mfF6SQMAnKe3ShVsaI8ccc2LbS8HbqOVrqiNpkge/BqrJpTuk9GMFZLe4qLtu6Qh5M99KZMbJO1v+8YSbRgFPCDpKVLOhUhhkbKdnqAVIueiG1N2VcBG6xcnkbZwjgJCVbChPTKV3p5NKpx0BXCLM580JN1YaJ8EHEdKZHzR9tcz2nAgMI7kYAl4L3CM7Ym5bGiPDEW8Pkyqq9GLFCarXdj7N0qzFRtarbFT5VyYnkzMXHRvsi80z6lve2gj/353sKFIpP0oqybS1aqkTs5gxnak4klfBC6SdB0p3+DODNoAm9j+laQxTm3Wb5M0NZM2ALYnFNVSjyEllF5D81LtKnB2g//+mcBuwIwSnMv+RQGvypW+D9omnIvuTdnTTg3VL1Yl1Ddr+itwvu3X23zR2mfDn0klv++jbvldjRw9PWy/RmoU9oci9+Js0h18rjoPtc/6n0U5+n8AAzJpAyDpaFLy7BbAA6Qp+ruBLKGZwrE5hVQhtzctQgIZqlM+CzyU27Eo+C3Jub2PdM6pv6kxJYTqgo6JsEg3puxGPRmmYi8E+tC8GuJTpIqVRzdKs2o2SHrI9vAcWh3YsScp3+RA4G/AFbb/lEn7IFLDuC1JBc36A9/NWVBJ0gxgJHCP7Z0lbQf8wJk6A0t6jFaqU+YKCUi6hHQRv4GVa0xkW4oadC9i5qLClD0lXrY+aenZTnXbt0h6sMGaVbPhLkk72J6RUXMlJD1NCgX8Afiq7YU59W2PL36dTyoeVQaLbS+WhKQ32H5UUs5lkWVXp3yqePQtHtmRdLPtfTsaC6pBOBfVpuwp8bL1l0saZvsJaCpotbzBmlWzYQ/gMyVnyO9YxLxbRdLJtn/YKHFJ25Kadg22PVzSjsAhtr/XKM1WeK6oVnsNMEnSXCBnImFp1SmLAlrb2j6y0Vpt6PcjVScdWITlamGR/sCby7Ap6JgIi1SYsqfEK6C/D3AJ8CTphLIV8Fnbt/YUG7pDhnyGVUO3kUIC59fCcGV+N4sQ0YbABNtLM2mWWp1S0p3APrnebwvtMcCXSd1x/1G36xXgAtvn5rYp6JiYuag2ZU+Jl6Zf3C3tBGwD1KafH7O9ygzK2mxDlZyIdmj0qqU32p6ilbtwZukM2xrFipXclF2d8klgsqRrgaawWI6cC9tnA2dLOsH2OY3WC7qGcC6qTdlT4qXpOzVHOsL2WaR+Etmpgg3dhEZPf74kaVhNR6k76j8brFk1yq5O+UTx6EU55dchlWAfSzovmZTke57t3N1Zg04QYZEKU/aUeAX0zyKt1LiCle+WpuXQr4oNVSfDqqGtSQWsdgfmkhILj7L9dKM0q4akR4BhpPdeueqUjW6cVmj8gVTr4vJi6JPARrZHN1I3WDPCuQgqi6RaXkPtS1o7oWYr+1wFG8pG0ntsT25rTNI3bf8ggx3rAb1s97hiSmU7+h2Ro1qwpIdtb9/RWFANIiwSVA41t9oeT+tFc3qEDRXiHKDlhaNprFGOhVZuuV4/TqG71tdYiOqUKzFN0ijb9wBIejep5kpQQcK5CKpILab7NlLhoj+TLu4HA1N6kA2lImk3UihiUIsLfX/yVOcsK7ZfJaI6ZTPvJOWezCa9962Ax4oCZ5UJEQWJCIsElUXS7cCHatPgkjYA/mL7fe2/cu2yoSyKJZd7kZqFnVe3awFwne1ZZdjVkkbX2Qg6JlMDva2AjUlN4wBuB+bV9lclRBQkYuYiqDKDgfp19UuLsZ5mQynUNQm7pHbiltQLWL+9ololMBpYq52LblCdstGN0wAOA44GriLN4FxGqnMRy1MrSDgXQZX5NTBF0tXF9mGkglY9zYay+aGk40iVSacC/SWdbfsnJdtVo+zuwA2jKtUpK9A4DeDzwKha+XlJPyY1jwvnooJEWCSoNJJGUDcNavv+nmhDmUh6oGjWdSQpifMbwH1ViXHnWKlQFlWpTll247TChhmkYmKLi+1+wFTbO+SyIeg8MXMRVJqinkSpNSWqYEPJ9Clazx8GnGv7dUlVuitZa2cuKlSdsuzGaQAXA/e2mEX8VYn2BO0QzkUQBB1xPvA08CBwe5FYly3noqM6G8CVuWwpkbKrU5bWOK1O60xJfyV9BpB6/PSoWcTuRIRFgiBYbST1tp2lv0drYY+1ORTSGmVXpyy7cVrQ/YiZiyAI2kXSYOAHwOa2PyBpe2A3GjwlXYE6G1VieItKlLdKytlnpOzGaUE3o1fZBgRBUHkuASaSkgoB/k5KMmw0fYH1STdBG9Q9XgEOz6BfJaZJGlXbKKE65V2FUxkEnSLCIkEQtIukqbZH1hdKqq0gyaS/VU8vkFQ0LnsbsFJ1SlLr+YZXp6x647SgekRYJAiCjlgoaROaW56PAuZn1L9Q0mjb8wr9jYHf2z4gow1lcyDtVKfMpB8EnSaciyAIOmIscC2wtaTJwCDyhiUG1hwLANtzJW2aUb8KlFKdMhqnBWtKOBdBEHTEw8DVwGuki8w1pLyLXKyQ9BbbswEkDaHndaYtqzplNE4L1ohwLoIg6Ihfk5Ioa63VP0m6c86yDJJUdvpOSbeRLm7vBY7JpF0VRCq/XmM5GYqH2T6o+Dm00VrB2kU4F0EQdESpyyBtTyh6WxwD3E+aOVmUS78ilFqdshs0TgsqRjgXQRB0xDRJo2zfA/mXQUo6GhgDbAE8AIwihQT2yWVD2ZRVnbIqjdOC7kc4F0EQtErRKMpAH1Kdg/plkI9mNGUMMBK4x1SNpGYAAAFZSURBVPbekrajOUTTYyipx82xNDdOq9d+BcjSNC3onkSdiyAIWqXoIdImuWpP1NXZeAB4t+0lkmbafkcO/QAq0Dgt6GbEzEUQBK1SocJVz0naiJRrMUnSXKAqtvUUym6cFnQzYuYiCIJug6Q9gQ2BCbaXlm1PT6HsxmlB9yOciyAIgqBdJD3cYsVQq2NBUCMalwVBEAQdUXbjtKCbETMXQRAEQbuU3Tgt6H6EcxEEQRC0S7FyqM3GaRVK/g0qQoRFgiAIgo44jFTyfSCpcd1lwCG2nwnHImiNmLkIgiAI2kXSdGC3usZp6wF3RzgkaIuYuQiCIAg6opTGaUH3JYpoBUEQBB1RauO0oPsRYZEgCIKgQySNoLlx2h05GqcF3ZdwLoIgCIIg6FIi5yIIgiAIgi4lnIsgCIIgCLqUcC6CIAiCIOhSwrkIgiAIgqBLCeciCIIgCIIu5f8DJrgziwpejoMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE5IfK0tInVd"
      },
      "source": [
        "*Correlation matrix is useful, but it has it's limits.(I did not normalize the values, so it might not be the most accurate, but I think we can get some useful information even in this form as well.)*\n",
        "\n",
        "*Im not gonna go into detail about all of this matrix, I just want to focus on how best_val_acc correlates to the other variables. The higher the absolute value of the correlation coefficient , the bigger the correlation is between the two variables.*\n",
        "\n",
        "*From this we can conclude that relu impacts the validation accuracy in a negative way, meaning that it lowers the accuracy. Meanwhile leakyrelu increases it. We will see this being true later on the plots as well.*\n",
        "\n",
        "*Similarly we can see that adam improves our model, sgd does not really matter (does not move the model in a negative or positive way significantly), while rmsprop hinders us.*\n",
        "\n",
        "*N_batch size has 0.3 correlation, so it seems that the higher the batch size the better.Dropouts have negative correlations, so we probably want a low number there. N_layer1 and n_layer2 have positive values, so probably the higher these numbers are the better.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "7xzRfWyYfIWu",
        "outputId": "21f071c2-2425-4705-fc86-150f2884436e"
      },
      "source": [
        "plt.scatter(df['n_batch'],df['best_val_acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6d6cd0ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwYn3t5nUlU7"
      },
      "source": [
        "Okay, so our assumption that we want the batch size to be as big as possible turns out to be true. We can see that on average with n_batch=256 our worst accuracy is higher than that of the lower batch sizes, and our max potential (the best accuracy we can achieve with this batch size) is also better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "m8E7LthOisit",
        "outputId": "59df4986-811d-4bbc-ac1c-868e14a6b475"
      },
      "source": [
        "plt.scatter(df['act_relu'],df['best_val_acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6dc2b4b080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARtElEQVR4nO3df2zcd33H8dcrV2czW4dh8STiZk2ZgjdDGWFeC0Lix6hwy7bUUtGUTNWo1K2CrRsSk7Vajaq28AdgjT8mRRoRqsZWkRaqzDJqkLXRVtXQEurObU3KvIWuJLlUw0DdTerROpf3/riLdzHn+Hvnr7/n+/j5kCzd933f3vf9qZ2Xv/58fzkiBADofts63QAAIB8EOgAkgkAHgEQQ6ACQCAIdABJxRac2vGPHjti9e3enNg8AXenpp5/+UUT0N3uvY4G+e/duzczMdGrzANCVbP9gtfeYcgGARBDoAJAIAh0AEkGgA0AiCHQASETHznJpx+RsWRPT8zq3WNHOvl6NjQxqdO9Ap9sCgE2hawJ9crassUee1VK1dnfI8mJFY488K0mEOgCoi6Zc7vvGyeUwv2ipGrrvGyc71BEAbC5dE+gvv7rUUh0AtpquCXQAwOUR6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQAS0TV3WwSAbndwck5HTpxRNUIlWweu36XPjl6b2+cT6ABQgIOTc3rw+Onl5WrE8nJeoc6UCwAU4MiJMy3V20GgA0ABqhEt1duRKdBt32h73vYp23c1ef822wu2n6l//XFuHQJAAkp2S/V2rBnotkuSDkm6SdKQpAO2h5qs+nBEvKv+9eXcOgSABBy4fldL9XZk2UO/TtKpiHghIl6X9JCkm3PrAAC2gOGr36xtK3bGt7lWz0uWQB+Q1Dhrf7ZeW+kW28/ZfsR20185tu+wPWN7ZmFhoY12AaA7TUzP68KK6fILUavnJa+Dot+QtDsi3inpnyR9pdlKEXE4IoYjYri/vz+nTQPA5ndusdJSvR1ZAr0sqXGP+6p6bVlE/DgiXqsvflnSb+XTHgCkYWdfb0v1dmQJ9Kck7bF9je3tkvZLmmpcwfZbGhb3Sfpebh0CQALGRgbV21O6pNbbU9LYyGBu21jzStGIOG/7TknTkkqSHoiIk7bvlzQTEVOS/sL2PknnJf1E0m25dQgACRjdWzv0ODE9r3OLFe3s69XYyOByPQ+ZLv2PiGOSjq2o3dPwelzSeG5dAQBaxr1cAKAAk7NljR+dU2WpKkkqL1Y0fnROknLbS+fSfwAowMT0/HKYX1RZqm7K0xYBAJexWU5bBACs02Y5bREAsE4f+vXmF1OuVm8HgQ4ABXj835vf7mS1ejsIdAAoAHPoAJAI5tABIBHMoQNAIh7+zumW6u0g0AGgAEsXWqu3g0AHgEQQ6ACQCAIdABJBoANAIgh0ACjANrdWb2sb+X0UAGA1733rm1uqt4NAB4ACPP/S/7ZUbweBDgAFePnVpZbq7SDQASARBDoAFKCvt6elejsIdAAowO/95ltaqreDQAeAAjz63Est1dtBoANAATgoCgDIrGsCfbVGu2YAALY0Doo2eOMbmg96tToAbCb37nu7elZc59+zzbp339tz28YVuX3SBiti/gkANsro3gFJ0sT0vM4tVrSzr1djI4PL9Tx0TaCXbFUjmtYBoBuM7h3INcBX6ppAbxbml6sDwGZzcHJOR06cUTVCJVsHrt+lz45em9vnd80c+kBfb0t1ANhMDk7O6cHjp5d3QqsRevD4aR2cnMttG10T6GMjg+rtKV1S6+0paWxksEMdAUB2R06caanejq6ZcinigAIAbJQipo27Zg8dAHB5XbOHPjlb1vjROVWWqpKk8mJF40drc0/spQNAF+2hT0zPL4f5RZWlqiam5zvUEQBkV8SJHZkC3faNtudtn7J912XWu8V22B7OrcO6c4uVluoAsJmMjQw2vVI0zxM71gx02yVJhyTdJGlI0gHbQ03Wu1LSpySdyK27BjtX+S22Wh0ANp2V10HmfF1klj306ySdiogXIuJ1SQ9JurnJep+R9HlJP82xv2VF/HYDgI0yMT2vpeqlZ7QsVSPXaeMsgT4gqfFEybP12jLb75a0KyIevdwH2b7D9oztmYWFhZab3ejfbgCwUYqYNl73QVHb2yR9UdJfrrVuRByOiOGIGO7v729pO0X8dgOAjdK3yp1hV6u3I0uglyXtali+ql676EpJ75D0hO0XJb1H0lTeB0Y5KAqgm612/VCet6PKEuhPSdpj+xrb2yXtlzT1/83EKxGxIyJ2R8RuSccl7YuImfza5KAogO72SqX5rb5Xq7djzUCPiPOS7pQ0Lel7kr4WESdt3297X26drIF7uQDoZkVMuWS6UjQijkk6tqJ2zyrrfnD9bf0s7uUCoJsVMeXSNZf+Sxt/c3gA2CibYsoFALB+RRwHJNABoABjI4PqKa24OLJU8KX/AICcrJwvz/kJmgQ6ABRgYnpeSxdWXBx5ofhL/wEA69QVl/4DANbGQVEASEQRF0d21XnoANCtirg4kkAHgIJs9MWRTLkAQCIIdABIBFMuAFCQg5NzOnLijKoRKtk6cP0ufXb02tw+n0AHgAIcnJzTg8dPLy9XI5aX8wp1plwAoABHTpxpqd4OAh0AClBd5cbnq9XbQaADQAFKdkv1dhDoAFCAA9fvaqneDg6KAkABLh743MizXBx5PtCuBcPDwzEzM9ORbQNAt7L9dEQMN3uPKRcASARTLgBQkMnZMjfnAoBuNzlb1vjROVWWqpKk8mJF40fnJCm3UGfKBQAKMDE9vxzmF1WWqjyCDgC6DY+gA4BE8Ag6AEgEj6ADgETwCDoASAiPoAMAZEKgA0AiCHQASASBDgCJINABIBEEOgAkIlOg277R9rztU7bvavL+J2zP2X7G9r/YHsq/VQDA5awZ6LZLkg5JuknSkKQDTQL7qxFxbUS8S9IXJH0x904BAJeVZQ/9OkmnIuKFiHhd0kOSbm5cISL+p2HxFyR15jFIALCFZblSdEDSmYbls5KuX7mS7T+T9GlJ2yX9Ti7dAQAyy+2gaEQciohfk/RXkg42W8f2HbZnbM8sLCzktWkAgLIFelnSroblq+q11TwkabTZGxFxOCKGI2K4v78/e5cAgDVlCfSnJO2xfY3t7ZL2S5pqXMH2nobF35X0n/m1CADIYs059Ig4b/tOSdOSSpIeiIiTtu+XNBMRU5LutH2DpCVJL0v6+EY2DQD4WZlunxsRxyQdW1G7p+H1p3LuCwDQIq4UBYBEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARGS6UhQAsH6Ts2VNTM/r3GJFO/t6NTYyqNG9A7l9PoEOAAWYnC1r/OicKktVSVJ5saLxo3OSlFuoM+UCAAWYmJ5fDvOLKktVTUzP57YNAh0ACnBusdJSvR0EOgAUYGdfb0v1dhDoAFCAsZFB9faULqn19pQ0NjKY2zY4KAoABbh44JOzXAAgAaN7B3IN8JWYcgGARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASkSnQbd9oe972Kdt3NXn/07aft/2c7W/Zvjr/VgEAl7NmoNsuSTok6SZJQ5IO2B5asdqspOGIeKekRyR9Ie9GAQCXl2UP/TpJpyLihYh4XdJDkm5uXCEiHo+IV+uLxyVdlW+bAIC1ZAn0AUlnGpbP1muruV3SN5u9YfsO2zO2ZxYWFrJ3CQBY0xV5fpjtWyUNS/pAs/cj4rCkw5I0PDwceW4bADa7ydmyJqbndW6xop19vRobGdTo3svtH7cmS6CXJe1qWL6qXruE7Rsk3S3pAxHxWj7tAUAaJmfLGj86p8pSVZJUXqxo/OicJOUW6lmmXJ6StMf2Nba3S9ovaapxBdt7JX1J0r6I+GEunQFAQiam55fD/KLKUlUT0/O5bWPNQI+I85LulDQt6XuSvhYRJ23fb3vfxV4l/aKkr9t+xvbUKh8HAFvSucVKS/V2ZJpDj4hjko6tqN3T8PqG3DoCgATt7OtVuUl47+zrzW0bXCkKAAUYGxlUb0/pklpvT0ljI4O5bSPXs1wAAM1dPPDZ6bNcAAA5GN07kGuAr8SUCwAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJCJToNu+0fa87VO272ry/vtt/5vt87Y/ln+bAND9JmfLet/nHtM1dz2q933uMU3OlnP9/DUD3XZJ0iFJN0kaknTA9tCK1U5Luk3SV3PtDgASMTlb1vjROZUXKwpJ5cWKxo/O5RrqWfbQr5N0KiJeiIjXJT0k6ebGFSLixYh4TtKF3DoDgIRMTM+rslS9pFZZqmpiej63bWQJ9AFJZxqWz9ZrLbN9h+0Z2zMLCwvtfAQAdKVzi5WW6u0o9KBoRByOiOGIGO7v7y9y0wDQUTv7eluqtyNLoJcl7WpYvqpeAwBkNDYyqN6e0iW13p6SxkYGc9vGFRnWeUrSHtvXqBbk+yX9YW4dAMAWMLq3NlM9MT2vc4sV7ezr1djI4HI9D2sGekSct32npGlJJUkPRMRJ2/dLmomIKdu/LekfJb1J0u/bvi8i3p5blwCQgNG9A7kG+EpZ9tAVEcckHVtRu6fh9VOqTcUAADqEK0UBIBEEOgAkgkAHgEQQ6ACQCEdEZzZsL0j6QZv/+Q5JP8qxnW7AmLcGxrw1rGfMV0dE0yszOxbo62F7JiKGO91HkRjz1sCYt4aNGjNTLgCQCAIdABLRrYF+uNMNdABj3hoY89awIWPuyjl0AMDP6tY9dADACgQ6ACRiUwd6hodT/5zth+vvn7C9u/gu85VhzJ+2/bzt52x/y/bVnegzT2uNuWG9W2yH7a4/xS3LmG3/Qf17fdJ21z+vN8PP9q/aftz2bP3n+6Od6DMvth+w/UPb313lfdv+m/r/j+dsv3vdG42ITfml2q16vy/prZK2S3pW0tCKdf5U0t/WX++X9HCn+y5gzB+S9Ib6609uhTHX17tS0pOSjksa7nTfBXyf90ialfSm+vKvdLrvAsZ8WNIn66+HJL3Y6b7XOeb3S3q3pO+u8v5HJX1TkiW9R9KJ9W5zM++hr/lw6vryV+qvH5H0YdsusMe8ZXkg9+MR8Wp98bi6/7bFWb7PkvQZSZ+X9NMim9sgWcb8J5IORcTLkhQRPyy4x7xlGXNI+qX66zdKOldgf7mLiCcl/eQyq9ws6e+j5rikPttvWc82N3OgZ3k49fI6EXFe0iuSfrmQ7jZGqw/kvl213/DdbM0x1/8U3RURjxbZ2AbK8n1+m6S32f627eO2byysu42RZcz3SrrV9lnVnr/w58W01jGt/ntfU6YHXGDzsX2rpGFJH+h0LxvJ9jZJX5R0W4dbKdoVqk27fFC1v8KetH1tRCx2tKuNdUDS30XEX9t+r6R/sP2OiLjQ6ca6xWbeQ8/ycOrldWxfodqfaT8upLuNkemB3LZvkHS3pH0R8VpBvW2UtcZ8paR3SHrC9ouqzTVOdfmB0Szf57OSpiJiKSL+S9J/qBbw3SrLmG+X9DVJioh/lfTzqt3EKlWZ/r23YjMH+vLDqW1vV+2g59SKdaYkfbz++mOSHov60YYuteaYbe+V9CXVwrzb51WlNcYcEa9ExI6I2B0Ru1U7brAvImY6024usvxsT6q2dy7bO1SbgnmhyCZzlmXMpyV9WJJs/4Zqgb5QaJfFmpL0R/WzXd4j6ZWIeGldn9jpI8FrHCX+qGp7Jt+XdHe9dr9q/6Cl2jf865JOSfqOpLd2uucCxvzPkv5b0jP1r6lO97zRY16x7hPq8rNcMn6frdpU0/OS5iTt73TPBYx5SNK3VTsD5hlJH+l0z+sc7xFJL0laUu0vrtslfULSJxq+x4fq/z/m8vi55tJ/AEjEZp5yAQC0gEAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4Aifg/te7VKduvl+EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewd68NJaVfwe"
      },
      "source": [
        "This one is pretty straight-forward. Leakyrelu (the only other option) outperforms relu in every metric. If act_relu=1 (x axis) we use relu, otherwise we use leakyrelu. On the y-axis the accuracy can be seen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvZ_HuQTf5Em",
        "outputId": "1578b445-8f2e-4ddb-a586-605169b87835"
      },
      "source": [
        "for hyperparam in ['n_layer1', 'n_layer2', 'dropout_1', 'dropout_2', 'n_batch']:\n",
        "  ax1 = df.plot(kind='scatter', x=hyperparam, y='best_val_acc')\n",
        "  best10.plot(kind='scatter', x=hyperparam, y='best_val_acc', color='red', ax=ax1)\n",
        "  worst10.plot(kind='scatter', x=hyperparam, y='best_val_acc', color='yellow', ax=ax1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfzUlEQVR4nO3df3TddZ3n8ec7uUmaNqW0ScGmqaS0dDxtByoGpOI6o6u7OAr1CDIwzqqz7uF4Fo7MoYJ4ZmRX9rgueoqjY8YVHUTcQQRctbq69Ucd2XEAk2IpBKSGEmhaLW1TShPSpEne+8f9Jr1J7m1zk+8333vzeT3OCc33fb+5eX/by33fz4/v52PujoiIhKsi7QRERCRdKgQiIoFTIRARCZwKgYhI4FQIREQCl0k7geloaGjw5ubmtNMQESkrO3bsOOTuSyfGy7IQNDc3097ennYaIiJlxcxeyBdX15CISOBUCEREAqdCICISOBUCEZHAqRCIiAROhWCO63m+m90/3E7P891ppyIiJUqFYA5r+0wrteetYvl7/4za81bR/j9a005JREqQleMy1C0tLa77CE6t5/lu6lY1U+3DY7FBq6T3uS6WrGxKMTMRSYuZ7XD3lolxtQjmqO7tv6IqpwgAVPkw3dt/lVJGIlKqVAjmKrPi4iISLBWCOSqzsK6ouIiES4Vgjnp528+KiotIuFQI5ijv7S0qLoVpCq7MdSoEM9B54BgPte+l88CxtFOZpObCNxQVl/zaPtNK7ZpVLLvqcmrXaAquzE1luQx1Kbjte09y76Mvjh1/YONruX3TH6eY0XjzV64oKi6T9TzfzfrbbqJ2aBCGBgFY98mb6PnzTZqCK6k43DtA95F+mhbXUl9XE9vzqkUwDZ0Hjo0rAgD3PvJiSbUMDu3sKCouk3XteJoTFeM/K52oyNC14+mUMpKQfX/nPi69Yzt/+bXHuPSO7WzduS+251YhmIade18uKp6GP7zu/KLiMtmh+mVUjQyNi1WNDHGofllKGUmoDvcO8PHv7OL4iRGODQxx/MQIt3xnF4d7B2J5fhWCaVg8v6qoeBqeWbScey58Nw5jX/dc+G6eWbQ85czKx7zlr+Hmd95If6aaV6rn05+p5uZ33si85a9JOzUJTPeR/qLixdIYwTTsLfCXXyiehmPHT/Cpd3yEb174Ljbsf5adjX/EnvoVXHX8RNqplY11jWfwf9f/Cf/avIGmowfoXnQ2r9Qt4lONZ6SdmgRmQXUlx0+MjIsdPzHCgurKWJ4/qEIQ10BLQ4GfLRRPw2uXzAdgT/0K9tSvmBSX06uvq+HOqzdw80NP0LloCcM+wp1XXRDrIJ3IVPQNDlNTaQwMn1wbrqbS6BscPsVPTV0wheD7O/fx8e/soqqighMjI3z2yvO5YsP0ukk2rqqnssIYHjn5j1JZYWxcVR9XujP28qv5P/kXikt+V2xYzqWrGxKZqSEyVU2La7EKg5xCYBVG0+LaWJ4/iDGCuAda6utqeP/F46dhvv+NK0rqTeKVAl1AheJS2JG+QX534BhH+gbTTkUCVV9Xw2evPJ/qSqiprKC6Ej575fmxvecEUQi6j/RTVTH+UqsqKqY90HK4d4AHdoy/y/SB9u7YRvDj0LQ4fxdQobjkd9v3nuTtn3+Yjz20i7d//mFu+/6TaackgWrv6mFwGAaGRxgchvYXemJ77iAKQdPiWk6MjB9oOTEyMu1mVdyFJQmv9BdoERSIy2TlcL+IhCHp12LihcDMLjOzZ82s08xuzfP4h8zsoJntjL7+U9w5jDar5lVVsLAmw7yqihk1q5oW19J/Yvz88v4TQ7H118VhcDj/hkOF4jJZOdwvImFI+rWY6GCxmVUCrcA7gG6gzcy2uvvEWzO/7e43JJlL3IN+ZkZ2dn7ucel4z4ZG/tdjL+aNy9RsWHFmUXGRpCT9Wky6RXAx0Onue9x9ELgf2JTw70xc95F+5mXGz9+dl6ksqa6hM+dXFxWXyVafvZA3rx4/E+zfrK5n9dkLU8pIJBlJF4LlwN6c4+4oNtGVZrbLzB4ys7yropnZdWbWbmbtBw8eLDqRONfpiHvMIQnbOv5QVFwmO9w7wGPPjx+Qe/T5npKaFCBh+JfO/O95heLFKoXB4h8Aze5+PvBT4Bv5TnL3u9y9xd1bli5dWtQvSGL66NUt41efvLqlqaSmj8rMdew/yokJYyonhp2O/UdTykhC1VA3r6h4sZIuBPuA3E/4TVFsjLsfdvfRd+SvAbEvmJ/I9NH20p4++rrX5O++KBSXyTTzSkrFxlX1TByFtCgeh6QLQRtwnpmtNLNq4Bpga+4JZpa7lOMVwDNxJxHi9NEjBe4gLhSXfApNACitiQEy99XX1fCFazaMu6HsC9dsiK0XItFZQ+4+ZGY3ANuASuBud+8ws9uBdnffCnzUzK4AhoAe4ENx5zHalXPvIydn0cykK6ccxgia6/PfOFYoLpOdUZv/f49CcZEkJbncSeJjBO7+I3df4+6r3P3TUey2qAjg7p9w93XufoG7v9Xdfxt3DnF35cR9X0ISXp2wUuHp4jLZusZFVFWO//RfVWmsa1yUUkYiyQjio82p1vKe7pt3qS9G9kp//nVxCsVlsvq6Gra87wJufmjX2CKDn7uqtAq+hOP7O/dxy4TX4nQXzpwoiEKQ1Fre9XU1JfumcOz4UFFxye+KDctZu+wMdu59mQ0rztQ9BJKKw70DfOzBJ8bNYtv84BNcurohlvegIApBUmt5J7WRdBx6CqyUWSgu+SX5KUxkqk41lfkta86a8fMHUQiSWMs7zv0NkrBkQf47iAvFZbKkP4WJTF2yM9hK4YayxI0O7tZkKphfXUlNZmaDu0lvJB2H5QWKXKG4TKYbyqRUrGs8g8yEd+tMRTYehyAKAUQbuPsIw8OO+8xmzpTDfQTzq/KPfxSKSz66j0BKw+i2qTUZY35VJTUZ486ry+Q+glJxuHeAzQ/sZGgEIFsEbnpg57Sb+OVwH8FT+18pGG9ZWTpbapayxkX5b98vFBdJUlnfR1AKOva/EhWBk4ZGsvHpqK+r4eo3lPZaQyeG87d6CsVlsr7BYeZVjf9fZF5VRWwbhosUq76uhgtWnBn7e00QhSDuNWPKYavKwYmV7zRxmaxpcS3DI+PHCIZHvKRafhKWw70DPLH35djfa4LoGjqjtqqo+OmMjhEc5+Sb6ugYQam0CqonjiydJi75ufspj0VmS5JTmYN4V4i7r7ccxgiqKvP/0xaKy2TdR/qprRr/Wam2KlNSkwIkDKNTmQeGRnh1cJiBoRE2P/hEbC2DIN4VRm8oyzWTG8rino6ahBUFilKhuExWDgVfwpD0VOYgCsHYDWU5ZnpDmY/+108elZK9R14tKi6TlcPighKGfQVaoYXixQpijGD0f+hbJtwJPNMbygaGHMi2Km75zq6SuuO0JpP/foFCcclPaw1JKRgYyt97USherCAKAcQ7BzeJ1UzjpjuL45EdoHuCSqtg2Ef43FUXlNRSIhKG9QWWPi8UL1YQXUOj4pqDm9RqpnHSWvozN3oj4sCQ8+qJYQaGnJse2FlS04QlDFWZyrxLTFTF1MIPqhDEJe7B5yTU19Vw7UUrxsWuvXhFybRYykHcNyKKTFfT4loyE2b8ZSorYpu4oEIwDUkMPsftcO8A32rbOy72rV/v1afZohSaBFB6kwNkbhvdbjdXnKsZqBBMQznMJtHKmTPXuCh/YS8UF0lK3NvtThTMYHHcSn2rSq2cOXOjaw3ljgdprSFJQ9KrGQTVIkhqnY5SpJUzZ65QV18pdQFKGJoW19J/Yvw2s/0nhmJ7LQbTIoh7R7FS36Gsb3CYyvGbslFp6NNsEUa7AHM3ry+1LkAJh2Pkjk95jK37IFoEce8oVg47lC2ormTCEAHDTklNcS0HpX4HuYShY//RvCvhaomJIsS9o1g57FC2/2j+XArFZbLcO8hH7yMotYIvodCexTMW9+Jh5bEYmQaLZ6ocCr6EQXsWxyDuHcXKYfpo0i+cEJRHwZcQJL1nsZXjRhstLS3e3t4+5fMP9w5w6R3bJ00D/NXH3zajv8jDvQMlPH0Utu7cx81aJ2dGtu7cN2mxQv0dSlpm+p5jZjvcvWViPIhZQ0ktEldfV1OSBWBU6d/rUPr0dyilJKn3nCAKQTksEpeUUi9W5UB/hzLXBTFGUA6LxCWl88AxHmrfS+eBY2mnIiIlKogWwdgicTkT60ttkbgk3Pa9J7n30RfHjj+w8bXcvumPU8xIREpREC2CcpjlE7fOA8fGFQGAex95US0DEZkkiBYBhDfot3PvywXj2m5RRHIFUwggrEG/5vr5RcVFJFxBdA2FqCpTyYTxcSotvq3tQhLSqrUSpqBaBCFpWlxLVaaC4Zxps1WZ+La2C0WprzIrEofEWwRmdpmZPWtmnWZ26ynOu9LM3Mwm3fUmxQtxgDxu5bDKrEgcEm0RmFkl0Aq8A+gG2sxsq7s/PeG8hcCNwGNJ5hO3Ul9iIrQB8rglvSuUSKlIumvoYqDT3fcAmNn9wCbg6Qnn/TfgDuDmhPOJTbl0GRgHqa3ejbEGaDrt+XKSFp2TUCTdNbQc2Jtz3B3FxpjZhcAKd/8/p3oiM7vOzNrNrP3gwYPTSqant5vdB7bT09t9+pNPoVy6DNq6WqmtXs2yRZdTW72a9q7WtFMqK+pek1CkOlhsZhXAncCHTneuu98F3AXZ1UeL/V1tXa2sb9zMskwlmYph2ru20NJ8fbFPA5RHl0FPbzfrGzdTW32yOK1r3ExP7yaW1KllMFXqXpMQJN0i2AesyDluimKjFgLrgX82sy7gEmBr3APGuW+KC+e9Sm31QPSmOL2WQTl0GRzq283QyPipokMjlRzq251SRuWrvq6GC1acqSIgc1bShaANOM/MVppZNXANsHX0QXc/6u4N7t7s7s3Ao8AV7j71zQamIO43xXLoMmhYsIZMxfhF9TIVwzQsWJNSRiJSqhLtGnL3ITO7AdgGVAJ3u3uHmd0OtLv71lM/QzwaFqyhJjO+/74mMzCjN8VS7zJYUtdEe9cW1jVuZmgk2x3WsX8LLc3qFhKR8YLYoaynt5u6eSupzgyNxQaHMvQef37O95f39HZzqG83DQvWzPlrFZFTC3qHskN9u6nKVI8rBAND1Rzq2z3n3xyX1DXN+WsUkZmZ8hiBmX3DzM7MOV5sZncnk1a81F8uIlJYMYPF57v72NrG7n4EeH38KcVvSV0THfu30D9YTd9ADf2D1XTs36JPyiIiFFcIKsxs8eiBmS2hjLqWHDADsOhPERGB4t7ItwCPmNmD0fH7gE/Hn1L8Ru8jmFc1OBbTzVUiIllTbhG4+73Ae4ED0dd73f2bSSUWJ91cJSJS2JRbBGZ2CdDh7l+Kjs8wsze6e8mvGKrBYhGRwooZI/gy0Jtz3BvFSt7JweIajh2fT/9gjQaLRUQixYwRmOfcfebuI2ZWNoPFLc3X09O7aezmKt1hKyKSVcwb+R4z+ygnWwH/GdgTf0rJ0c1VIiKTFdM19BHgTWRXD+0G3ghcl0RSIiIye6bcInD3l8iuHioiInNIMbOG5gEfBtYB80bj7v4fE8grEV0H23np2MOctfAtNC+NdcsDEZGyVUzX0DeB1wD/Hvgl2U1mjiWRVBIeee5azmm4iItWbuachot45Lm/SDslEZGSUEwhWO3unwT63P0bwLvIjhOUvK6D7Vxy7v2YMfZ1ybnfoutgrPvfiIiUpWIKwYnoz5fNbD2wCDgr/pTi99Kxh4uKi4iEpJjpo3dFi879LdntJuuATyaSVczOWviWouIiIiEpZq2hr7n7EXd/2N3Pdfez3P0ro4+b2QeTSXHmmpe28Oiea3Fn7OvRPddqwFhEhHg3r78xxueK3cZV9/HCoTbant/CC4fa2LjqvrRTEhEpCXEuEVHyq/w3L21RK0BEZII4WwR++lNERKTUxFkISr5FELee3m52H9hOT2932qmIiExbnIXgVzE+V8lr62qltno1yxZdTm31atq7WtNOSURkWixnZen8J5jddKrH3f3OWDOagpaWFm9vT+9msJ7ebmqrV1NbPTAW6x+soX+wU6ubikjJMrMd7j5poHQqg8ULE8inrB3q282yTP6tL1UIRKTcnLYQuPunZiORcqKtL0VkLglq9dG4LKlror1rC+saNzM0UkmmYpiO/Vu065mIlKVgVh+NW0vz9fQPdvL7oz+gf7CTlubr005JRGRairmhbLW7v8/MNrn7N8zsPuD/JZVYOdDWlyIyFwSx+qiIiBQ2ndVHP0mZrT4qIiKFFVMIvu7uw2THB85NKB8REZllxXQNPW9md5nZvzWz4JaTEBGZq4opBK8DfgZcD3SZ2ZfM7M3JpCUiIrOlmI1pXnX3B9z9vcAG4Ayy3UQiIlLGilp0zsz+xMz+AdhB9qayq6fwM5eZ2bNm1mlmt+Z5/CNm9qSZ7TSzfzGztcXkJCIiM1PMncVdwG+AB4Cb3b1vCj9TCbQC7wC6gTYz2+ruT+ecdp+7/8/o/CuAO4HLpnwFIiIyI8XMGjrf3V8p9KCZfcLdPzMhfDHQ6e57onPuBzYBY4VgwnMuQBvciIjMqmLGCAoWgcj78sSWA3tzjruj2Dhmdr2ZPQd8FvjoVHMSEZGZK4kdyty91d1XAR8H/jbvk5tdZ2btZtZ+8ODB6f4qERGZIOk9i/cBK3KOm6JYIfcD78n75O53uXuLu7csXbp0+lmKiMg4SbcI2oDzzGylmVUD15BdnuLkD5mdl3P4LuB3MeYkIiKnMeVCYGaXnib24MTH3X0IuAHYBjwDPODuHWZ2ezRDCOAGM+sws53ATcAHi7kAERGZmdPuWTx2otnj7n7h6WKzIe09i0VEytG09yw2s43Am4ClEzayPwOozP9TIiJSLqZyH0E12SWnM4zfyP4V4KokkhIRkdkzlc3rfwn80szucfcXAMysAqibwr0FIiJS4oqZNfQZMzvDzBYATwFPm9nNCeUlIiKzpJhCsDZqAbwH+DGwEvgPiWQlIiKzpphCUGVmVWQLwVZ3P4HWBRIRKXvFFIKvAF1kF4Z72MzOITtgLCIiZWzKq4+6+xeBL+aEXjCzt8afkoiIzKZi7iw+28z+0cx+HB2vRXcBi4iUvWK6hu4hu1REY3S8G/jruBMSEZHZVUwhaHD3B4ARGFtHaDiRrCQ2Pb3d7D6wnZ7e7rRTEZESVUwh6DOzeqKZQmZ2CXA0kawkFm1drdRWr2bZosuprV5Ne1dr2imJSAkqZqvKm8guIX2umf0KWIqWmChZPb3drG/cTG31wFhsXeNmeno3saSuKcXMRKTUFNMieBr4Ltk9Bg4AXyU7TiAl6FDfboZGxq8JODRSyaE+/ZOJyHjFFIJ7gdcB/x34e2AN8M0kkpKZa1iwhkzF+CGcTMUwDQvWpJSRiJSqYrqG1rv72pzjX5jZ03EnJPFYUtdEe9cW1jVuZmikkkzFMB37t9DSrG4hERmvmBbB49EAMQBm9kZAu8OUsJbm6+kf7OT3R39A/2AnLc3Xp52SiJSgqWxM8yTZmUJVwL+a2YvR8TnAb5NNT2ZqSV2TBodF5JSm0jX07sSzEBGR1ExlY5oXZiMRERFJRzFjBCIiMgepEIiIBE6FQEQkcCoEIiKBUyEQEQmcCoGISOBUCEREAqdCICISOBUCEZHAqRCIiAROhUBEJHAqBCIigVMhEBEJnAqBiEjgVAhERAKnQiAiErjEC4GZXWZmz5pZp5ndmufxm8zsaTPbZWY/N7Nzks5JREROSrQQmFkl0Aq8E1gLXGtmayec9hugxd3PBx4CPptkTiIiMl7SLYKLgU533+Pug8D9wKbcE9z9F+7+anT4KKCd1kVEZlHShWA5sDfnuDuKFfJh4Mf5HjCz68ys3czaDx48GGOKIiJhK5nBYjP7S6AF+Fy+x939LndvcfeWpUuXzm5yZaynt5vdB7bT09uddioiUqKSLgT7gBU5x01RbBwzezvwN8AV7j6QcE7BaOtqpbZ6NcsWXU5t9Wrau1rTTklESlDShaANOM/MVppZNXANsDX3BDN7PfAVskXgpYTzCUZPbzfrGzdTWz3AwnmvUls9wLrGzWoZiMgkiRYCdx8CbgC2Ac8AD7h7h5ndbmZXRKd9DqgDHjSznWa2tcDTSREO9e1maKRyXGxopJJDfbtTykhESlUm6V/g7j8CfjQhdlvO929POocQNSxYQ6ZieFwsUzFMw4I1KWUkIqWqZAaLJV5L6pro2L+F/sEajh2fT/9gDR37t7CkTrNzRWS8xFsEkp6W5uvp6d3Eob7dNCxYQ0uzioCITKZCMMctqWtSK0BETkldQyIigVMhEBEJnAqBiEjgVAhERAKnQiAiEjgVAhGRwKkQiIgEToVARCRwKgQiIoFTIRARCZwKgYhI4FQIREQCp0IgIhI4FQIRkcCpEIiIBE6FQEQkcCoEIiKBUyEQEQmcCoGISOBUCEREAqdCICISOBUCEZHAqRCIiAROhUBEJHAqBCIigVMhEBEJnAqBiEjgVAhERAKnQiAiEjgVAhGRwKkQiIgEToVARCRwKgQiIoFLvBCY2WVm9qyZdZrZrXkef4uZPW5mQ2Z2VdL5xKmnt5vdB7bT09uddioiItOWaCEws0qgFXgnsBa41szWTjjtReBDwH1J5hK3tq5WaqtXs2zR5dRWr6a9qzXtlEREpiXpFsHFQKe773H3QeB+YFPuCe7e5e67gJGEc4lNT2836xs3U1s9wMJ5r1JbPcC6xs1qGYhIWUq6ECwH9uYcd0exopnZdWbWbmbtBw8ejCW56TrUt5uhkcpxsaGRSg717U4pIxGR6SubwWJ3v8vdW9y9ZenSpanm0rBgDZmK4XGxTMUwDQvWpJSRiMj0JV0I9gErco6bolhZW1LXRMf+LfQP1nDs+Hz6B2vo2L+FJXVNaacmIlK0TMLP3wacZ2YryRaAa4C/SPh3zoqW5uvp6d3Eob7dNCxYQ0uzioCIlKdEC4G7D5nZDcA2oBK42907zOx2oN3dt5rZRcB3gcXA5Wb2KXdfl2RecVlS16RWgIiUvaRbBLj7j4AfTYjdlvN9G9kuIxERSUHZDBaLiEgyVAhERAKnQiAiEjgVAhGRwJm7p51D0czsIPBC2nnMggbgUNpJpCjk6w/52iHs60/y2s9x90l35JZlIQiFmbW7e0vaeaQl5OsP+doh7OtP49rVNSQiEjgVAhGRwKkQlLa70k4gZSFff8jXDmFf/6xfu8YIREQCpxaBiEjgVAhERAKnQpAiM7vbzF4ys6dyYkvM7Kdm9rvoz8VR3Mzsi2bWaWa7zOzC9DKfOTNbYWa/MLOnzazDzG6M4nP++s1snpn92syeiK79U1F8pZk9Fl3jt82sOorXRMed0ePNaeYfFzOrNLPfmNkPo+Mgrt/MuszsSTPbaWbtUSzV170KQbruAS6bELsV+Lm7nwf8PDoGeCdwXvR1HfDlWcoxKUPAZndfC1wCXG9mawnj+geAt7n7BcAG4DIzuwS4A/i8u68GjgAfjs7/MHAkin8+Om8uuBF4Juc4pOt/q7tvyLlfIN3XvbvrK8UvoBl4Kuf4WWBZ9P0y4Nno+68A1+Y7by58Ad8H3hHa9QPzgceBN5K9mzQTxTcC26LvtwEbo+8z0XmWdu4zvO4msm94bwN+CFgo1w90AQ0TYqm+7tUiKD1nu/vvo+//AJwdfb8c2JtzXncUK3tRU//1wGMEcv1Rt8hO4CXgp8BzwMvuPhSdknt9Y9cePX4UqJ/djGP3d8AtwEh0XE841+/AT8xsh5ldF8VSfd0nvjGNTJ+7u5nN6fm9ZlYHfAf4a3d/xczGHpvL1+/uw8AGMzuT7A59r0s5pVljZu8GXnL3HWb2p2nnk4I3u/s+MzsL+KmZ/Tb3wTRe92oRlJ4DZrYMIPrzpSi+D1iRc15TFCtbZlZFtgj8k7v/7ygczPUDuPvLwC/IdoWcaWajH85yr2/s2qPHFwGHZznVOF0KXGFmXcD9ZLuHvkAg1+/u+6I/XyL7IeBiUn7dqxCUnq3AB6PvP0i273w0/oFoFsElwNGcpmTZsexH/38EnnH3O3MemvPXb2ZLo5YAZlZLdmzkGbIF4arotInXPvp3chWw3aMO43Lk7p9w9yZ3bwauIXs97yeA6zezBWa2cPR74N8BT5H26z7tgZOQv4BvAb8HTpDt+/sw2b7PnwO/A34GLInONaCVbF/yk0BL2vnP8NrfTLavdBewM/r6sxCuHzgf+E107U8Bt0Xxc4FfA53Ag0BNFJ8XHXdGj5+b9jXE+Hfxp8APQ7n+6BqfiL46gL+J4qm+7rXEhIhI4NQ1JCISOBUCEZHAqRCIiAROhUBEJHAqBCIigVMhEBEJnAqByBSZ2T1mdtXpz5zR73iLmT1uZkNJ/y6RUSoEIiUiWj7hReBDwH3pZiMhUSGQoJlZs5k9Y2ZfjTaJ+Um07MPpfu42M2szs6fM7K5oCYBVZvZ4zjnnjR6b2RvM7JfRipPbctaV+Wcz+7tog5Ib3b3L3XdxclVOkcSpEIhkN/1odfd1wMvAlVP4mS+5+0Xuvh6oBd7t7s8BR81sQ3TOXwFfjxbX+3vgKnd/A3A38Omc56p29xZ33xLXBYkUQ8tQi8Dz7r4z+n4H2c2CTuetZnYL2Y1llpBdN+YHwNeAvzKzm4A/J7uy5B8B68kuOQxQSXaNqVHfjuEaRKZNhUAku3XkqGGyn/ALMrN5wD+QXQBsr5n9V7ILo0F2We3/AmwHdrj7YTNrBDrcfWOBp+ybSfIiM6WuIZHijb7pH4o21hmb3ePux8lurfhl4OtR+FlgqZlthOw+DGa2bhbzFTklFQKRInl2M5mvkl1CehvQNuGUfyI72PuT6PxBssXiDjN7guyS22/K99xmdpGZdQPvA75iZh2JXIRIDi1DLRIzM/sYsMjdP5l2LiJToTECkRiZ2XeBVWS3XxQpC2oRiExgZq1k99XN9QV3/3q+80XKnQqBiEjgNFgsIhI4FQIRkcCpEIiIBE6FQEQkcP8fLEH5shJFwtEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nCHJps6WIsq"
      },
      "source": [
        "This one is really interesting. We assumed that n_layer1 should be as high as possible, but it turns out this is not the case. This just shows how important these scatterplots are, and that correlation matrices can be misleading.\n",
        "\n",
        "The best results achieved are connected to **n_layer1**=128, but we can also see why we said that the higher the number the better the accuracy in our analysis at the correlation matrix. The overall expected accuracy is much higher if we use bigger numbers, because with lowers number we have achieved some really bad results (see the yellow dots). At 256 or 512 we have no yellow dots, but also no red ! \n",
        "\n",
        "Moving on to **n_layer2**, it is a bit different. We can see that using 32 or 64 layers is not recommended, and the best results are achieved with 512 layers. However, 128 and 256 is not that far off. \n",
        "\n",
        "**Dropout_1** is just like we expected it to be, 0.1 +/- 0.05 is the optimal way, and the higher the dropout rate the worse accuracy we have. \n",
        "\n",
        "**Dropout_2** is a bit surprising, as we can have good results from 0.0 to even 0.3 !\n",
        "But my gut feeling tells me from reading the plot that we should have it around 0.1-0.2.\n",
        "\n",
        "Moving on to the **batch size**, we can conclude that 256 gives the best results, but given the correct settings in the other batch sizes (namely 64 and 128) we can produce similar accuracies. A tiny bit lower, but similar. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGqSvqBmaHSi"
      },
      "source": [
        "Conclusion: We managed to increase our model from 0.49 to 0.5424 with a little bit of tuning. None of the results from our analysis are too surprising to me, but the fact that it improved more than 5% is quite remarkable. "
      ]
    }
  ]
}